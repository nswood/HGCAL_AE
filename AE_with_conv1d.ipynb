{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d41a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from Naive_DAE import Naive_DAE, Conv_DAE\n",
    "from AE_Stats import generate_stats\n",
    "from load_data_fn import load_data\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cce9e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt,dt_loc = load_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a821e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AE_MSE(data,pred):\n",
    "    return torch.mean(torch.sum((data-pred)**2,dim=1))\n",
    "\n",
    "def weighted_AE_MSE(data, pred):\n",
    "    return torch.mean(torch.sum((data[:,0:48])**2,dim=1)*torch.sum((data-pred)**2,dim=1))\n",
    "\n",
    "def dif_weighted_AE_MSE(data, pred,alpha = 1):\n",
    "    return torch.mean(((torch.sum(data[:,0:48]**2,dim=1)**0.5)*alpha+1)*(torch.sum((data-pred)**2,dim=1)))\n",
    "\n",
    "def log_dif_weighted_AE_MSE(data, pred,alpha = 1):\n",
    "    return torch.mean(torch.log((torch.sum(data[:,0:48]**2,dim=1)**0.5)*alpha+1)*(torch.sum((data-pred)**2,dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f260d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "lr = 0.00025\n",
    "loss = dif_weighted_AE_MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe1be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_train =200000\n",
    "size_test = 40000\n",
    "train_loc = torch.unsqueeze(dt_loc[0:size_train],dim=1)\n",
    "test_loc = torch.unsqueeze(dt_loc[-size_test:],dim=1)\n",
    "# train = torch.vstack([train,largest[0:1000]] )\n",
    "train_loc=train_loc[torch.randperm(train_loc.size()[0])]\n",
    "test_loc=test_loc[torch.randperm(test_loc.size()[0])]\n",
    "train_loc_dl_flat = DataLoader(\n",
    "    TensorDataset(torch.Tensor(train_loc)),\n",
    "    batch_size=200,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loc_dl_flat = DataLoader(\n",
    "    TensorDataset(torch.Tensor(test_loc)),\n",
    "    batch_size=200,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train = torch.unsqueeze(dt[0:size_train],dim=1)\n",
    "test = torch.unsqueeze(dt[-size_test:],dim=1)\n",
    "# train = torch.vstack([train,largest[0:1000]] )\n",
    "train=train[torch.randperm(train.size()[0])]\n",
    "test=test[torch.randperm(test.size()[0])]\n",
    "train_dl_flat = DataLoader(\n",
    "    TensorDataset(torch.Tensor(train)),\n",
    "    batch_size=200,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_dl_flat = DataLoader(\n",
    "    TensorDataset(torch.Tensor(test)),\n",
    "    batch_size=200,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ebce25d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 307200000000 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m data_test \u001b[38;5;241m=\u001b[39m test\n\u001b[1;32m     32\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(model_5(data_test))\n\u001b[0;32m---> 33\u001b[0m batch_test \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(losses)\n\u001b[1;32m     35\u001b[0m running_test_loss \u001b[38;5;241m=\u001b[39m batch_test\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn [3], line 8\u001b[0m, in \u001b[0;36mdif_weighted_AE_MSE\u001b[0;34m(data, pred, alpha)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdif_weighted_AE_MSE\u001b[39m(data, pred,alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmean(((torch\u001b[38;5;241m.\u001b[39msum(data[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m48\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m*\u001b[39malpha\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m(torch\u001b[38;5;241m.\u001b[39msum((\u001b[43mdata\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mpred\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:75] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 307200000000 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "###### fine-tune autoencoder\n",
    "#batch 500\n",
    "\n",
    "\n",
    "# model_5 = Conv_DAE([48,250,100,16])\n",
    "\n",
    "optimizer = optim.Adam(model_5.parameters(), lr,weight_decay=5e-2)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor = 0.5)\n",
    "\n",
    "all_test_losses = []\n",
    "all_train_losses = []\n",
    "# train\n",
    "running_loss = float(\"inf\")\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for i, data_list in enumerate(train_dl_flat):\n",
    "        data = data_list[0]\n",
    "        v_pred = torch.squeeze(model_5(data))\n",
    "        \n",
    "        batch_loss = loss(data, v_pred,alpha = 0.05) # difference between actual and reconstructed   \n",
    "        \n",
    "        \n",
    "        all_train_losses.append(batch_loss.item())\n",
    "        losses.append(batch_loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step(batch_loss)\n",
    "    data_test = test\n",
    "    test_pred = torch.squeeze(model_5(data_test))\n",
    "    batch_test = loss(data_test, test_pred)\n",
    "    running_loss = np.mean(losses)\n",
    "    running_test_loss = batch_test.item()\n",
    "    print('Epoch {}, lr {}'.format(\n",
    "        epoch, optimizer.param_groups[0]['lr']))\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Train {running_loss}, Test {running_test_loss}\")\n",
    "generate_stats(model_5(test),test,test_loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e2b6a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 7.7088e-01, -1.5858e-01, -1.6369e-01,  ..., -1.5346e-01,\n",
       "          -1.5054e-01, -1.5277e-01],\n",
       "         [ 5.3968e-01,  2.0050e+00, -5.1730e-02,  ..., -6.5281e-02,\n",
       "           2.4527e-01,  5.7730e-01],\n",
       "         [-1.5390e-01, -1.5858e-01, -1.6369e-01,  ..., -1.5346e-01,\n",
       "           1.9093e-02, -1.5277e-01],\n",
       "         ...,\n",
       "         [-1.5390e-01, -1.5858e-01, -1.6369e-01,  ..., -1.5346e-01,\n",
       "          -1.5054e-01, -1.5277e-01],\n",
       "         [ 2.2935e-04,  7.8478e-03,  4.2519e-03,  ...,  2.5805e-01,\n",
       "          -6.5725e-02, -6.5163e-02],\n",
       "         [-1.5390e-01, -1.5858e-01, -1.6369e-01,  ..., -1.5346e-01,\n",
       "          -1.5054e-01, -1.5277e-01]])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dl_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a77f806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0151, 0.0223, 0.0231, 0.0222, 0.0217, 0.0187, 0.0321, 0.0258, 0.0185,\n",
       "        0.0195, 0.0303, 0.0226, 0.0154, 0.0217, 0.0217, 0.0157, 0.0189, 0.0117,\n",
       "        0.0219, 0.0211, 0.0213, 0.0181, 0.0141, 0.0168, 0.0205, 0.0198, 0.0367,\n",
       "        0.0188, 0.0233, 0.0146, 0.0169, 0.0259, 0.0187, 0.0234, 0.0224, 0.0181,\n",
       "        0.0209, 0.0164, 0.0244, 0.0166, 0.0176, 0.0215, 0.0199, 0.0187, 0.0245,\n",
       "        0.0285, 0.0191, 0.0198], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.squeeze(model_5(test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d5f6c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1539, -0.1586, -0.1637, -0.1626, -0.1643, -0.1584, -0.1642, -0.1666,\n",
       "         -0.1621, -0.1621, -0.1590, -0.1614, -0.1505, -0.1545, -0.1546, -0.1472,\n",
       "         -0.1641, -0.1621, -0.1568, -0.1644, -0.1612, -0.1625, -0.1638, -0.1639,\n",
       "         -0.1588, -0.1612, -0.1665, -0.1573, -0.1583, -0.1476, -0.1555, -0.1461,\n",
       "         -0.1590, -0.1623, -0.0508, -0.1612, -0.1641, -0.1585, -0.1601, -0.1620,\n",
       "         -0.1597, -0.1566, -0.1600, -0.1530, -0.1549, -0.1535, -0.1505, -0.1528]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cd3d7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_temp = torch.unsqueeze(test[0:200],dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e15944db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1539, -0.1586, -0.1637,  ..., -0.1535, -0.1505, -0.1528]],\n",
       "\n",
       "        [[-0.1539, -0.1586, -0.1637,  ..., -0.1535, -0.1505, -0.1528]],\n",
       "\n",
       "        [[-0.1539, -0.1586, -0.1637,  ..., -0.1535, -0.1505, -0.1528]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1539, -0.1031, -0.1637,  ..., -0.1535, -0.1505, -0.1528]],\n",
       "\n",
       "        [[-0.1539, -0.1586, -0.1637,  ..., -0.1535, -0.1505, -0.1528]],\n",
       "\n",
       "        [[-0.1539, -0.1586, -0.1637,  ..., -0.1535, -0.1505, -0.1528]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86fd01bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4894, 0.4871, 0.4888,  ..., 0.4036, 0.4944, 0.4924]],\n",
       "\n",
       "        [[0.4894, 0.4871, 0.4888,  ..., 0.4929, 0.4944, 0.4924]],\n",
       "\n",
       "        [[0.4894, 0.4871, 0.4888,  ..., 0.4929, 0.4944, 0.4924]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5245, 0.4762, 0.4888,  ..., 0.4929, 0.4944, 0.4924]],\n",
       "\n",
       "        [[0.4894, 0.4871, 0.4888,  ..., 0.4929, 0.4944, 0.4924]],\n",
       "\n",
       "        [[0.4894, 0.4871, 0.4888,  ..., 0.4929, 0.4944, 0.4924]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(dt_temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
