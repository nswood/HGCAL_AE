{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f5a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from Naive_DAE import Naive_DAE,Dropout_DAE\n",
    "import AE_Stats\n",
    "from load_data_fn import load_data,load_data_no_filter\n",
    "from telescope_torch import telescopeMSE2\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import importlib\n",
    "import time\n",
    "import ae_train\n",
    "from losses import *\n",
    "\n",
    "path = 'MIT_TTbar'\n",
    "prefixed = [filename for filename in os.listdir(path) if filename.startswith(\"dt_norm\")]\n",
    "\n",
    "data = []\n",
    "for p in prefixed:\n",
    "    data.append([torch.load(f'{path}/{p}'),p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80b73a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ae_train' from '/uscms_data/d3/nswood/Notebooks/AE_Dev/ae_train.py'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(ae_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f719b3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL dt_norm_3_36\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.801915490945566, Test 0.7100458145141602\n",
      "Epoch 25, lr 2.25e-05\n",
      "Epoch 25: Train 0.5547378765823, Test 0.5431606769561768\n",
      "Epoch 50, lr 5.625e-06\n",
      "Epoch 50: Train 0.5264441469340648, Test 0.5122934579849243\n",
      "Epoch 75, lr 1.40625e-06\n",
      "Epoch 75: Train 0.5250068409157417, Test 0.5104655027389526\n",
      "Epoch 100, lr 3.515625e-07\n",
      "Epoch 100: Train 0.5247798056664205, Test 0.5101989507675171\n",
      "Epoch 125, lr 8.7890625e-08\n",
      "Epoch 125: Train 0.52472857817477, Test 0.5101195573806763\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.52470656882212, Test 0.5100902915000916\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.5246970495359797, Test 0.5100803375244141\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.5246875059450329, Test 0.5100709795951843\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.5246779358309835, Test 0.5100606679916382\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.524668366584963, Test 0.5100512504577637\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.5246587915520837, Test 0.5100411176681519\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.5246492697583047, Test 0.5100314617156982\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.5246397035021613, Test 0.5100217461585999\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.5246302813870235, Test 0.5100125074386597\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.5246208243096144, Test 0.5100023746490479\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.5246113448081279, Test 0.5099929571151733\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.5246018306819367, Test 0.5099837183952332\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.5245924604074083, Test 0.5099735856056213\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.5245830100331106, Test 0.5099644660949707\n",
      "TRAINING MODEL dt_norm_3_30\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.278743945993483, Test 1.1621865034103394\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.9541307600215078, Test 0.9313613176345825\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 0.9263348311185837, Test 0.8991832137107849\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 0.9094962688162923, Test 0.8810989856719971\n",
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 0.9018432227894664, Test 0.8736462593078613\n",
      "Epoch 125, lr 1.125e-05\n",
      "Epoch 125: Train 0.899245309829712, Test 0.8714871406555176\n",
      "Epoch 150, lr 2.8125e-06\n",
      "Epoch 150: Train 0.8958817943930626, Test 0.867822527885437\n",
      "Epoch 175, lr 1.40625e-06\n",
      "Epoch 175: Train 0.8951455273665487, Test 0.8670867085456848\n",
      "Epoch 200, lr 3.515625e-07\n",
      "Epoch 200: Train 0.8946954241953791, Test 0.8666728734970093\n",
      "Epoch 225, lr 8.7890625e-08\n",
      "Epoch 225: Train 0.8945828915573657, Test 0.8665571808815002\n",
      "Epoch 250, lr 2.197265625e-08\n",
      "Epoch 250: Train 0.8945511964149773, Test 0.8665294647216797\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.8945420192554593, Test 0.8665214776992798\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.894536835886538, Test 0.8665175437927246\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.8945317271165549, Test 0.8665132522583008\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.8945266606286169, Test 0.8665088415145874\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.894521594978869, Test 0.8665053844451904\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.8945165166631341, Test 0.8665006160736084\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.8945114884525538, Test 0.8664962649345398\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.8945064196363092, Test 0.8664921522140503\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.8945015370845795, Test 0.8664880990982056\n",
      "TRAINING MODEL dt_norm_3_31\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.4252004778012632, Test 1.307650089263916\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 1.067437558993697, Test 1.0450540781021118\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 1.020172133669257, Test 0.9935067892074585\n",
      "Epoch 75, lr 1.125e-05\n",
      "Epoch 75: Train 1.0101320419460535, Test 0.9844160079956055\n",
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 1.0052692594006658, Test 0.9793410301208496\n",
      "Epoch 125, lr 1.125e-05\n",
      "Epoch 125: Train 1.0046588160097598, Test 0.9790182113647461\n",
      "Epoch 150, lr 1.125e-05\n",
      "Epoch 150: Train 1.0023226356133819, Test 0.9760039448738098\n",
      "Epoch 175, lr 1.125e-05\n",
      "Epoch 175: Train 1.0018429229035974, Test 0.9748663902282715\n",
      "Epoch 200, lr 1.125e-05\n",
      "Epoch 200: Train 1.0014751952141523, Test 0.9747810959815979\n",
      "Epoch 225, lr 2.8125e-06\n",
      "Epoch 225: Train 0.99938380792737, Test 0.972962498664856\n",
      "Epoch 250, lr 1.40625e-06\n",
      "Epoch 250: Train 0.9976926935836673, Test 0.9715389013290405\n",
      "Epoch 275, lr 3.515625e-07\n",
      "Epoch 275: Train 0.9972878243774176, Test 0.9711635112762451\n",
      "Epoch 300, lr 8.7890625e-08\n",
      "Epoch 300: Train 0.9971756622195244, Test 0.9710833430290222\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.9971366802230477, Test 0.9710522294044495\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.9971284825354815, Test 0.9710490107536316\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.9971209900453687, Test 0.9710463285446167\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.9971133571118116, Test 0.9710431098937988\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.9971060711890459, Test 0.9710409045219421\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.9970984777435661, Test 0.9710369110107422\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.997091137804091, Test 0.9710337519645691\n",
      "TRAINING MODEL dt_norm_3_33\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.085457169637084, Test 0.9980403184890747\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.8757948317565024, Test 0.8464338779449463\n",
      "Epoch 50, lr 1.125e-05\n",
      "Epoch 50: Train 0.8494733116589487, Test 0.8185259699821472\n",
      "Epoch 75, lr 1.125e-05\n",
      "Epoch 75: Train 0.8443555345758795, Test 0.8125330209732056\n",
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 0.8412621924653649, Test 0.8085016012191772\n",
      "Epoch 125, lr 5.625e-06\n",
      "Epoch 125: Train 0.8274830002337694, Test 0.7948465347290039\n",
      "Epoch 150, lr 1.40625e-06\n",
      "Epoch 150: Train 0.8239809681661427, Test 0.7913857102394104\n",
      "Epoch 175, lr 3.515625e-07\n",
      "Epoch 175: Train 0.8233107462525368, Test 0.7907431721687317\n",
      "Epoch 200, lr 8.7890625e-08\n",
      "Epoch 200: Train 0.8231493258848787, Test 0.7905912399291992\n",
      "Epoch 225, lr 2.197265625e-08\n",
      "Epoch 225: Train 0.8231013156473637, Test 0.7905486822128296\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.8230838155373931, Test 0.7905343770980835\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.8230702831409872, Test 0.7905238270759583\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.8230569556355476, Test 0.7905128002166748\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.8230435347184539, Test 0.7905020713806152\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.8230302213691175, Test 0.7904911041259766\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.8230169391259551, Test 0.7904805541038513\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.8230035967193544, Test 0.7904700040817261\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.8229904118925333, Test 0.7904595732688904\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.8229773066937923, Test 0.790448784828186\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.8229641856625676, Test 0.7904385328292847\n",
      "TRAINING MODEL dt_norm_3_35\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.8084661384113133, Test 0.7241879105567932\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.6293029394000769, Test 0.6167135834693909\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 0.616702142637223, Test 0.6049344539642334\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 0.6112434178590774, Test 0.5967963337898254\n",
      "Epoch 100, lr 2.25e-05\n",
      "Epoch 100: Train 0.6061978949233889, Test 0.5923784971237183\n",
      "Epoch 125, lr 1.125e-05\n",
      "Epoch 125: Train 0.6034567561931908, Test 0.589560866355896\n",
      "Epoch 150, lr 2.8125e-06\n",
      "Epoch 150: Train 0.6017048769630492, Test 0.5876298546791077\n",
      "Epoch 175, lr 7.03125e-07\n",
      "Epoch 175: Train 0.6012859142385423, Test 0.5871787071228027\n",
      "Epoch 200, lr 1.7578125e-07\n",
      "Epoch 200: Train 0.6011808621697128, Test 0.5870591402053833\n",
      "Epoch 225, lr 4.39453125e-08\n",
      "Epoch 225: Train 0.6011527811177075, Test 0.5870316624641418\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.6011437349021435, Test 0.5870230197906494\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.6011402697302402, Test 0.5870198011398315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.60113704232499, Test 0.5870168805122375\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.6011338939890265, Test 0.5870136618614197\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.601130713429302, Test 0.587010383605957\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.6011275270953774, Test 0.5870072245597839\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.6011243684217333, Test 0.587004542350769\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.6011211320757865, Test 0.5870012044906616\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.6011180127039552, Test 0.5869983434677124\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.6011148940771818, Test 0.5869953036308289\n",
      "TRAINING MODEL dt_norm_3_37\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.5259784735598654, Test 0.44669631123542786\n",
      "Epoch 25, lr 2.25e-05\n",
      "Epoch 25: Train 0.3884624759168745, Test 0.37923920154571533\n",
      "Epoch 50, lr 5.625e-06\n",
      "Epoch 50: Train 0.3906969049441739, Test 0.3812101185321808\n",
      "Epoch 75, lr 1.40625e-06\n",
      "Epoch 75: Train 0.3911689018022339, Test 0.3816207945346832\n",
      "Epoch 100, lr 3.515625e-07\n",
      "Epoch 100: Train 0.3912590706029778, Test 0.38166189193725586\n",
      "Epoch 125, lr 4.39453125e-08\n",
      "Epoch 125: Train 0.39126163140033027, Test 0.3816552758216858\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.39125898058684366, Test 0.3816518485546112\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.39125464959714396, Test 0.3816472291946411\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.39125040534344857, Test 0.3816428780555725\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.3912462327371603, Test 0.3816387355327606\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.39124199766782847, Test 0.3816342353820801\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.39123773523284205, Test 0.3816298842430115\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.39123364636358227, Test 0.38162583112716675\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.3912294276011815, Test 0.3816215991973877\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.3912253313750591, Test 0.38161715865135193\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.3912213181362212, Test 0.3816130459308624\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.3912171564949384, Test 0.38160908222198486\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.3912130854789566, Test 0.3816048502922058\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.3912089762728919, Test 0.3816004991531372\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.3912050226386988, Test 0.3815968334674835\n",
      "TRAINING MODEL dt_norm_3_27\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 2.4136635501022092, Test 2.1267447471618652\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 1.764671252769174, Test 1.7292555570602417\n",
      "Epoch 50, lr 2.25e-05\n",
      "Epoch 50: Train 1.7490839078588394, Test 1.7119247913360596\n",
      "Epoch 75, lr 5.625e-06\n",
      "Epoch 75: Train 1.7433022719756686, Test 1.704487681388855\n",
      "Epoch 100, lr 2.8125e-06\n",
      "Epoch 100: Train 1.7425206432836342, Test 1.703373908996582\n",
      "Epoch 125, lr 7.03125e-07\n",
      "Epoch 125: Train 1.741274932441588, Test 1.701764464378357\n",
      "Epoch 150, lr 1.7578125e-07\n",
      "Epoch 150: Train 1.7409804110388154, Test 1.7014293670654297\n",
      "Epoch 175, lr 4.39453125e-08\n",
      "Epoch 175: Train 1.7409091937117591, Test 1.70133376121521\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 1.74088843316322, Test 1.7013158798217773\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 1.7408822049600792, Test 1.7013118267059326\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 1.7408760539150547, Test 1.7013083696365356\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 1.7408696108265602, Test 1.7013046741485596\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 1.740863371049702, Test 1.7012994289398193\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 1.7408571837403628, Test 1.7012965679168701\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 1.7408509219734414, Test 1.701291561126709\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 1.740844694156091, Test 1.7012882232666016\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 1.7408384435770967, Test 1.7012834548950195\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 1.7408321289568658, Test 1.701279640197754\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 1.7408174372799574, Test 1.7012667655944824\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 1.7407892707096335, Test 1.7012405395507812\n",
      "TRAINING MODEL dt_norm_3_29\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.998630291223526, Test 0.9338677525520325\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.8652948146685958, Test 0.8439111113548279\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 0.85894048307091, Test 0.8347626328468323\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 0.848178249411285, Test 0.8253345489501953\n",
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 0.8313789902254939, Test 0.8084970712661743\n",
      "Epoch 125, lr 1.125e-05\n",
      "Epoch 125: Train 0.8287513384595513, Test 0.805813729763031\n",
      "Epoch 150, lr 5.625e-06\n",
      "Epoch 150: Train 0.8262074567377568, Test 0.8032774329185486\n",
      "Epoch 175, lr 1.40625e-06\n",
      "Epoch 175: Train 0.8246605219319463, Test 0.8019518852233887\n",
      "Epoch 200, lr 3.515625e-07\n",
      "Epoch 200: Train 0.8242296045646071, Test 0.8015540838241577\n",
      "Epoch 225, lr 8.7890625e-08\n",
      "Epoch 225: Train 0.8241050569340587, Test 0.8014562129974365\n",
      "Epoch 250, lr 2.197265625e-08\n",
      "Epoch 250: Train 0.8240743031725287, Test 0.8014280200004578\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.8240638552233577, Test 0.8014184832572937\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.8240579426288605, Test 0.8014129400253296\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.8240518929436803, Test 0.8014076352119446\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.8240460585802794, Test 0.8014022707939148\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.8240400811657309, Test 0.801396906375885\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.8240342607721687, Test 0.8013911843299866\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.8240284519270062, Test 0.801385760307312\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.8240227973088622, Test 0.8013810515403748\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.824017227254808, Test 0.8013757467269897\n",
      "TRAINING MODEL dt_norm_3_32\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.2452758302912117, Test 1.121190071105957\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.9685973059386015, Test 0.9527957439422607\n",
      "Epoch 50, lr 2.25e-05\n",
      "Epoch 50: Train 0.8763690318912267, Test 0.8573133945465088\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 0.841545345261693, Test 0.8205442428588867\n",
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 0.8327245199121535, Test 0.8125516176223755\n",
      "Epoch 125, lr 5.625e-06\n",
      "Epoch 125: Train 0.8306338643655181, Test 0.8102294206619263\n",
      "Epoch 150, lr 5.625e-06\n",
      "Epoch 150: Train 0.8291729710064828, Test 0.8086124658584595\n",
      "Epoch 175, lr 5.625e-06\n",
      "Epoch 175: Train 0.8278530952520669, Test 0.8071521520614624\n",
      "Epoch 200, lr 5.625e-06\n",
      "Epoch 200: Train 0.8235363366082311, Test 0.8028061389923096\n",
      "Epoch 225, lr 5.625e-06\n",
      "Epoch 225: Train 0.8227225176990032, Test 0.80202317237854\n",
      "Epoch 250, lr 5.625e-06\n",
      "Epoch 250: Train 0.8208459313958884, Test 0.7999403476715088\n",
      "Epoch 275, lr 5.625e-06\n",
      "Epoch 275: Train 0.8200073927640915, Test 0.7989908456802368\n",
      "Epoch 300, lr 5.625e-06\n",
      "Epoch 300: Train 0.8192100486718118, Test 0.7983121871948242\n",
      "Epoch 325, lr 5.625e-06\n",
      "Epoch 325: Train 0.8187493656761944, Test 0.7975868582725525\n",
      "Epoch 350, lr 5.625e-06\n",
      "Epoch 350: Train 0.8182846399024128, Test 0.7972291707992554\n",
      "Epoch 375, lr 2.8125e-06\n",
      "Epoch 375: Train 0.8173122595064342, Test 0.7961728572845459\n",
      "Epoch 400, lr 1.40625e-06\n",
      "Epoch 400: Train 0.8165698670782149, Test 0.7954974174499512\n",
      "Epoch 425, lr 7.03125e-07\n",
      "Epoch 425: Train 0.8163003203459084, Test 0.7951968312263489\n",
      "Epoch 450, lr 8.7890625e-08\n",
      "Epoch 450: Train 0.8161053318530321, Test 0.7950165271759033\n",
      "Epoch 475, lr 2.197265625e-08\n",
      "Epoch 475: Train 0.8160753317177296, Test 0.7949904203414917\n",
      "TRAINING MODEL dt_norm_3_34\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.8219093257561326, Test 0.7507227659225464\n",
      "Epoch 25, lr 2.25e-05\n",
      "Epoch 25: Train 0.6672848852351307, Test 0.6518932580947876\n",
      "Epoch 50, lr 2.25e-05\n",
      "Epoch 50: Train 0.6596216374076903, Test 0.6431731581687927\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 0.658619427215308, Test 0.6408537030220032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 0.6539088591001928, Test 0.6359338760375977\n",
      "Epoch 125, lr 1.125e-05\n",
      "Epoch 125: Train 0.6529144143685699, Test 0.6352810263633728\n",
      "Epoch 150, lr 5.625e-06\n",
      "Epoch 150: Train 0.6517538252286613, Test 0.6339253187179565\n",
      "Epoch 175, lr 5.625e-06\n",
      "Epoch 175: Train 0.6510060274973511, Test 0.6330850124359131\n",
      "Epoch 200, lr 2.8125e-06\n",
      "Epoch 200: Train 0.6495715047232806, Test 0.6315804123878479\n",
      "Epoch 225, lr 2.8125e-06\n",
      "Epoch 225: Train 0.6485496062785387, Test 0.6306349635124207\n",
      "Epoch 250, lr 2.8125e-06\n",
      "Epoch 250: Train 0.6478154412470758, Test 0.6298058032989502\n",
      "Epoch 275, lr 1.40625e-06\n",
      "Epoch 275: Train 0.6470990282483399, Test 0.6289985775947571\n",
      "Epoch 300, lr 7.03125e-07\n",
      "Epoch 300: Train 0.6467882497236133, Test 0.628711998462677\n",
      "Epoch 325, lr 1.7578125e-07\n",
      "Epoch 325: Train 0.6466210337355733, Test 0.6285437345504761\n",
      "Epoch 350, lr 4.39453125e-08\n",
      "Epoch 350: Train 0.6465756203979254, Test 0.6285001039505005\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.6465619888156653, Test 0.6284878253936768\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.6465569587424398, Test 0.6284841299057007\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.6465521812438965, Test 0.6284801959991455\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.6465472855605185, Test 0.6284765601158142\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.646542408131063, Test 0.628473162651062\n",
      "TRAINING MODEL dt_norm_3_38\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.0929804543654125, Test 1.0179860591888428\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.9614590348375871, Test 0.9549630880355835\n",
      "Epoch 50, lr 2.25e-05\n",
      "Epoch 50: Train 0.5810121967551414, Test 0.5713818073272705\n",
      "Epoch 75, lr 1.125e-05\n",
      "Epoch 75: Train 0.5575767672910226, Test 0.5480337142944336\n",
      "Epoch 100, lr 2.8125e-06\n",
      "Epoch 100: Train 0.550870748606514, Test 0.541273295879364\n",
      "Epoch 125, lr 3.515625e-07\n",
      "Epoch 125: Train 0.5502845132618808, Test 0.5407878160476685\n",
      "Epoch 150, lr 1.7578125e-07\n",
      "Epoch 150: Train 0.5502347053213512, Test 0.5407424569129944\n",
      "Epoch 175, lr 8.7890625e-08\n",
      "Epoch 175: Train 0.5502103463317571, Test 0.5407227277755737\n",
      "Epoch 200, lr 2.197265625e-08\n",
      "Epoch 200: Train 0.5501899710308746, Test 0.5407049655914307\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.5501813519090303, Test 0.5406986474990845\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.5501754657829299, Test 0.5406942367553711\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.5501696084545793, Test 0.5406900644302368\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.5501638230089838, Test 0.540685772895813\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.5501582339015346, Test 0.5406815409660339\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.5501526551746697, Test 0.5406776070594788\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.5501469880454103, Test 0.5406741499900818\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.5501414518454548, Test 0.5406699776649475\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.5501357890693436, Test 0.5406656861305237\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.5501301373435317, Test 0.5406615734100342\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.5501246421078171, Test 0.540657639503479\n",
      "TRAINING MODEL dt_norm_1_1\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 11.354819965362548, Test 9.471136093139648\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 1.3758383251726627, Test 1.2205336093902588\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 0.7854647929780185, Test 0.6478776335716248\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 0.6244086184538901, Test 0.49826544523239136\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 0.5591320237144828, Test 0.43935883045196533\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 0.5345736572518944, Test 0.415025532245636\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 0.5134227038826793, Test 0.386700838804245\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 0.5057200234383344, Test 0.3770601749420166\n",
      "Epoch 200, lr 2.25e-05\n",
      "Epoch 200: Train 0.4713671302422881, Test 0.3505295515060425\n",
      "Epoch 225, lr 2.25e-05\n",
      "Epoch 225: Train 0.46539077353663744, Test 0.3414137363433838\n",
      "Epoch 250, lr 2.25e-05\n",
      "Epoch 250: Train 0.46002111020497977, Test 0.33166414499282837\n",
      "Epoch 275, lr 1.125e-05\n",
      "Epoch 275: Train 0.44364087395370005, Test 0.3176075220108032\n",
      "Epoch 300, lr 5.625e-06\n",
      "Epoch 300: Train 0.43631526581011715, Test 0.31029391288757324\n",
      "Epoch 325, lr 2.8125e-06\n",
      "Epoch 325: Train 0.43236123411916194, Test 0.3058261275291443\n",
      "Epoch 350, lr 7.03125e-07\n",
      "Epoch 350: Train 0.4293719637207687, Test 0.30295008420944214\n",
      "Epoch 375, lr 3.515625e-07\n",
      "Epoch 375: Train 0.4287832625210285, Test 0.3023983836174011\n",
      "Epoch 400, lr 8.7890625e-08\n",
      "Epoch 400: Train 0.4283991022966802, Test 0.3020212650299072\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.4282876802608371, Test 0.3019123077392578\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.42828445159830153, Test 0.3019104599952698\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.42828125404193995, Test 0.3019081950187683\n",
      "TRAINING MODEL dt_norm_1_3\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 20.832210886478425, Test 20.22285270690918\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 17.386097607016563, Test 16.950611114501953\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 16.14617600142956, Test 15.662725448608398\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 15.341435319185257, Test 14.823625564575195\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 14.747247785329819, Test 14.201539039611816\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 14.270287546515465, Test 13.702804565429688\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 13.872103813290597, Test 13.286447525024414\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 13.529252541065215, Test 12.926998138427734\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 13.22999464571476, Test 12.615814208984375\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 12.966116046905517, Test 12.334320068359375\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 12.731258311867714, Test 12.08255672454834\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 12.519580110907555, Test 11.859777450561523\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 12.331214770674706, Test 11.65818977355957\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 12.156469565629958, Test 11.470236778259277\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 11.989434316754341, Test 11.29092788696289\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 11.836651241779327, Test 11.133241653442383\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 11.69825459420681, Test 10.982585906982422\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 11.569701993465424, Test 10.845184326171875\n",
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 11.449950277805328, Test 10.723777770996094\n",
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 11.341618737578392, Test 10.602067947387695\n",
      "TRAINING MODEL dt_norm_1_5\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 22.35095059275627, Test 21.596694946289062\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 19.00398713350296, Test 18.407833099365234\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 17.748117592930793, Test 17.10542869567871\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 16.92830619812012, Test 16.242517471313477\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 16.305784061551094, Test 15.581130981445312\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 15.82132009267807, Test 15.062049865722656\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 15.423573186993599, Test 14.642483711242676\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 15.090983381867408, Test 14.292184829711914\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 14.807606145739555, Test 13.996908187866211\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 14.555449411273003, Test 13.73369026184082\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 14.331968459486962, Test 13.487165451049805\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 14.128616419434547, Test 13.275735855102539\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 13.947944065928459, Test 13.07313346862793\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 13.775569289922714, Test 12.898738861083984\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 13.629653108119964, Test 12.736987113952637\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 13.501214239001275, Test 12.593893051147461\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 13.373835000395776, Test 12.473371505737305\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 13.255564039945602, Test 12.338913917541504\n",
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 13.143462631106377, Test 12.218006134033203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 13.037329003214836, Test 12.102075576782227\n",
      "TRAINING MODEL dt_norm_1_7\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 18.066801822185518, Test 17.316150665283203\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 15.148745366930962, Test 14.648605346679688\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 14.113554382324219, Test 13.599193572998047\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 13.45674255490303, Test 12.913263320922852\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 12.954447835683823, Test 12.409078598022461\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 12.59336048066616, Test 12.013504028320312\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 12.255530506372452, Test 11.680097579956055\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 12.003792786598206, Test 11.398031234741211\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 11.778998005390168, Test 11.162459373474121\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 11.564760929346084, Test 10.946176528930664\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 11.3779456615448, Test 10.758258819580078\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 11.220312592387199, Test 10.588624954223633\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 11.065998330712318, Test 10.436628341674805\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 10.938293609023095, Test 10.29860782623291\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 10.8081375092268, Test 10.160257339477539\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 10.706300622224807, Test 10.035959243774414\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 10.572862622141837, Test 9.922722816467285\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 10.490555593371392, Test 9.818094253540039\n",
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 10.389709037542342, Test 9.715150833129883\n",
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 10.309770405292511, Test 9.626792907714844\n",
      "TRAINING MODEL dt_norm_1_9\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 13.83919142484665, Test 13.22280502319336\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 11.08532648384571, Test 10.74853515625\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 10.266462954878808, Test 9.937294960021973\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 9.745095759630203, Test 9.413312911987305\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 9.380558323860168, Test 9.028390884399414\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 9.07937907129526, Test 8.717263221740723\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 8.836338652670383, Test 8.46583366394043\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 8.634243023395538, Test 8.251057624816895\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 8.465725472569465, Test 8.078388214111328\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 8.2983338534832, Test 7.914156913757324\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 8.171982350945473, Test 7.770771026611328\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 8.043224668502807, Test 7.629717826843262\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 7.936481867730618, Test 7.524857044219971\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 7.838265718519688, Test 7.430341720581055\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 7.751349800825119, Test 7.33596134185791\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 7.658803799748421, Test 7.23382568359375\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 7.57308704406023, Test 7.153765678405762\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 7.4876851186156275, Test 7.06962776184082\n",
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 7.420117531716824, Test 7.003440856933594\n",
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 7.365232355892658, Test 6.929621696472168\n",
      "TRAINING MODEL dt_norm_1_11\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 10.797154188156128, Test 10.271167755126953\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 8.13153183311224, Test 7.935601234436035\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 7.4232494801282884, Test 7.2093963623046875\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 6.995019641518593, Test 6.769294738769531\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 6.685803027451039, Test 6.461155414581299\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 6.452131326496601, Test 6.219760417938232\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 6.257787664234638, Test 6.023432731628418\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 6.09121481180191, Test 5.848894119262695\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 5.95293939858675, Test 5.706177234649658\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 5.829404656589031, Test 5.5939741134643555\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 5.73030177205801, Test 5.486656665802002\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 5.631969827413559, Test 5.386898517608643\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 5.548743753135204, Test 5.300761699676514\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 5.474298079311848, Test 5.217368125915527\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 5.407749092578888, Test 5.155736446380615\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 5.3387645646929744, Test 5.0930986404418945\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 5.283588242530823, Test 5.032890796661377\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 5.22587762773037, Test 4.966620445251465\n",
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 5.172354730963707, Test 4.919539928436279\n",
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 5.126072683930397, Test 4.867895126342773\n",
      "TRAINING MODEL dt_norm_1_13\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 8.782886727154255, Test 8.308187484741211\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 6.058594211935997, Test 5.931199073791504\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 5.457961325347424, Test 5.3234710693359375\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 5.106428894400596, Test 4.988070487976074\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 4.851039443910122, Test 4.7032470703125\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 4.650760991871357, Test 4.495006561279297\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 4.48887023255229, Test 4.331527233123779\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 4.356478315591812, Test 4.20479679107666\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 4.243499092012644, Test 4.079103946685791\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 4.1452130384743215, Test 3.9849162101745605\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 4.057252110540867, Test 3.889864206314087\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 3.9828258253633977, Test 3.827521324157715\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 3.9122275695204736, Test 3.7509713172912598\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 3.846808545291424, Test 3.6725380420684814\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 3.7901939906179907, Test 3.622523546218872\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 3.7360966086387633, Test 3.565962791442871\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 3.6834641106426718, Test 3.520634651184082\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 3.6371033161878588, Test 3.462155818939209\n",
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 3.592987595498562, Test 3.432375907897949\n",
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 3.549136622995138, Test 3.3725051879882812\n",
      "TRAINING MODEL dt_norm_1_15\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 7.753750923275947, Test 7.299567222595215\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 5.059127728641033, Test 4.947182655334473\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 4.480471803247928, Test 4.361220359802246\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 4.139325599372387, Test 4.017883777618408\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 3.90609045997262, Test 3.7826895713806152\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 3.7307867027819155, Test 3.604922294616699\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 3.5928584054112433, Test 3.467531681060791\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 3.476008144766092, Test 3.3480544090270996\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 3.3792478159070014, Test 3.2481870651245117\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 3.2922664783895015, Test 3.1580936908721924\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 3.219139788299799, Test 3.0866217613220215\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 3.1527862802147864, Test 3.01603364944458\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 3.09211408495903, Test 2.9510300159454346\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 3.035744567215443, Test 2.89782452583313\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 2.9875507801771164, Test 2.847684860229492\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 2.94176282659173, Test 2.8078606128692627\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 2.9010506577789785, Test 2.7595479488372803\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 2.8608628436923027, Test 2.7184090614318848\n",
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 2.8248642116785048, Test 2.6790294647216797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 2.7921634025871755, Test 2.6453118324279785\n",
      "TRAINING MODEL dt_norm_1_17\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 6.571960325539112, Test 6.098953723907471\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 4.022074697911739, Test 3.910362958908081\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 3.5229443214833736, Test 3.405642509460449\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 3.245587442815304, Test 3.1318039894104004\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 3.0574514873325827, Test 2.9392545223236084\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 2.911170207709074, Test 2.7860891819000244\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 2.796944850683212, Test 2.672654628753662\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 2.7066728845238686, Test 2.5798583030700684\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 2.6310658007860184, Test 2.5063233375549316\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 2.567702765017748, Test 2.436840057373047\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 2.5123047858476637, Test 2.381157159805298\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 2.4628773666918278, Test 2.3302736282348633\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 2.4199286133050917, Test 2.2857184410095215\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 2.3812927570194007, Test 2.2475461959838867\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 2.347000077366829, Test 2.2101075649261475\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 2.3150428462773562, Test 2.183042049407959\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 2.286910226941109, Test 2.149646282196045\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 2.25804835408926, Test 2.12776517868042\n",
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 2.2333296708762647, Test 2.0990262031555176\n",
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 2.208406164124608, Test 2.069772481918335\n",
      "TRAINING MODEL dt_norm_1_19\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 5.486843690276146, Test 5.10607385635376\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 3.357803598791361, Test 3.2737393379211426\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 2.963899081200361, Test 2.8812930583953857\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 2.7441483877599238, Test 2.655369997024536\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 2.598828426748514, Test 2.502739429473877\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 2.4904294475913047, Test 2.400907516479492\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 2.401940099149942, Test 2.3030436038970947\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 2.331001861393452, Test 2.2331044673919678\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 2.2747693680226804, Test 2.1750080585479736\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 2.225256146490574, Test 2.1316192150115967\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 2.1786234505474567, Test 2.0916714668273926\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 2.1415098644793034, Test 2.042891502380371\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 2.104599018767476, Test 2.010503053665161\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 2.074044283106923, Test 1.9758033752441406\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 2.0470457140356304, Test 1.9449478387832642\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 2.020218539983034, Test 1.9218181371688843\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 1.9937081217765809, Test 1.8956298828125\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 1.9708428572863341, Test 1.872680425643921\n",
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 1.9498924419283867, Test 1.8476653099060059\n",
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 1.9291698817163705, Test 1.8292369842529297\n",
      "TRAINING MODEL dt_norm_1_21\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 5.24360243678093, Test 4.7896223068237305\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 2.75281725153327, Test 2.672645092010498\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 2.363967314735055, Test 2.283557891845703\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 2.164502004161477, Test 2.080805778503418\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 2.0298882205039264, Test 1.9467967748641968\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 1.9345290280878544, Test 1.8479853868484497\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 1.8611617378890515, Test 1.7720012664794922\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 1.8046204928308724, Test 1.7183012962341309\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 1.7592986326664686, Test 1.6725460290908813\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 1.7183484110981226, Test 1.6289196014404297\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 1.6829254738986492, Test 1.5930651426315308\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 1.6524185221642256, Test 1.5631370544433594\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 1.6252315923571587, Test 1.5327517986297607\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 1.6004146683961153, Test 1.5072933435440063\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 1.5775060337036848, Test 1.487963080406189\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 1.5568402167409658, Test 1.4645233154296875\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 1.5390271838754415, Test 1.443880558013916\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 1.5224560104310512, Test 1.4269609451293945\n",
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 1.5070011503994465, Test 1.4132676124572754\n",
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 1.4936219166964293, Test 1.3991308212280273\n",
      "TRAINING MODEL dt_norm_1_23\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 4.346996491402388, Test 3.9530463218688965\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 2.3292716089636087, Test 2.2654290199279785\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 2.0197476029396055, Test 1.956682801246643\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 1.8519977752119303, Test 1.7875442504882812\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 1.7472738228738307, Test 1.6792727708816528\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 1.6685491152107716, Test 1.600405216217041\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 1.6051388692110777, Test 1.5353670120239258\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 1.556281155720353, Test 1.484663724899292\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 1.5184959817677737, Test 1.4470806121826172\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 1.4831719130277634, Test 1.4147528409957886\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 1.4539641175419091, Test 1.3805994987487793\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 1.4274555455893279, Test 1.3546971082687378\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 1.4027421958744526, Test 1.328370213508606\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 1.383544896170497, Test 1.3107703924179077\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 1.363860348239541, Test 1.2894024848937988\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 1.3452101070433855, Test 1.270581603050232\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 1.3301498409360648, Test 1.2557951211929321\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 1.3156133718788623, Test 1.2427184581756592\n",
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 1.3019312907010316, Test 1.2290093898773193\n",
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 1.2892015758901834, Test 1.2123597860336304\n",
      "TRAINING MODEL dt_norm_1_25\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 4.23963242918253, Test 3.820232391357422\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 2.1526743952184915, Test 2.096223831176758\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 1.862507900968194, Test 1.8094197511672974\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 1.7042095314711332, Test 1.6475828886032104\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 1.6060309577733278, Test 1.5522143840789795\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 1.5290775891393422, Test 1.472376823425293\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 1.4673407137393952, Test 1.4104924201965332\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 1.4193966265767812, Test 1.361450433731079\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 1.3829223796725274, Test 1.3252487182617188\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 1.344990112259984, Test 1.2833030223846436\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 1.3150993295013904, Test 1.2542130947113037\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 1.2917031669989227, Test 1.2337661981582642\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 1.2726302314549685, Test 1.2116222381591797\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 1.2561359465122224, Test 1.192209243774414\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 1.240406378172338, Test 1.180112361907959\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 1.2251954708248376, Test 1.161375880241394\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 1.2126280292868614, Test 1.1514644622802734\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 1.2018719494342804, Test 1.1394504308700562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 1.1900755373761058, Test 1.1277687549591064\n",
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 1.1793794179335237, Test 1.1182239055633545\n",
      "TRAINING MODEL dt_norm_1_27\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 2.6733820874243976, Test 2.307187795639038\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 1.1997951872646808, Test 1.1585280895233154\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 1.0328894503414632, Test 0.9883502125740051\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 0.9486771238967776, Test 0.9052211046218872\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 0.8859469076618552, Test 0.8389362096786499\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 0.8473065532743931, Test 0.7982032299041748\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 0.8118439260870218, Test 0.7629433274269104\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 0.7878241343423724, Test 0.7398346662521362\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 0.7673718763515354, Test 0.7173184156417847\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 0.751275729201734, Test 0.7030823826789856\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 0.7399844955652952, Test 0.6893336176872253\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 0.7290109142661094, Test 0.6785642504692078\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 0.7183957451954484, Test 0.6679057478904724\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 0.7098517775535583, Test 0.6592706441879272\n",
      "Epoch 350, lr 4.5e-05\n",
      "Epoch 350: Train 0.7006478313356638, Test 0.6504104137420654\n",
      "Epoch 375, lr 4.5e-05\n",
      "Epoch 375: Train 0.69429741948843, Test 0.6464435458183289\n",
      "Epoch 400, lr 4.5e-05\n",
      "Epoch 400: Train 0.6883913885802031, Test 0.6374162435531616\n",
      "Epoch 425, lr 4.5e-05\n",
      "Epoch 425: Train 0.6827315897680819, Test 0.6345428824424744\n",
      "Epoch 450, lr 4.5e-05\n",
      "Epoch 450: Train 0.6741581524722278, Test 0.6215353012084961\n",
      "Epoch 475, lr 4.5e-05\n",
      "Epoch 475: Train 0.6692294653505086, Test 0.6203256845474243\n",
      "TRAINING MODEL dt_norm_1_29\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.8332518626004457, Test 1.7603312730789185\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 1.7279106698930264, Test 1.687009572982788\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 1.7244678728282452, Test 1.6813032627105713\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 1.718933839723468, Test 1.6750767230987549\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 1.7141040671616792, Test 1.668454885482788\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 1.7113834783434867, Test 1.6636879444122314\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 1.7083245508372784, Test 1.6590481996536255\n",
      "Epoch 175, lr 2.25e-05\n",
      "Epoch 175: Train 1.6996760439127683, Test 1.6518163681030273\n",
      "Epoch 200, lr 1.125e-05\n",
      "Epoch 200: Train 1.6939410977065563, Test 1.6466460227966309\n",
      "Epoch 225, lr 5.625e-06\n",
      "Epoch 225: Train 1.6910721477121116, Test 1.6441541910171509\n",
      "Epoch 250, lr 2.8125e-06\n",
      "Epoch 250: Train 1.6887731924653053, Test 1.6422516107559204\n",
      "Epoch 275, lr 1.40625e-06\n",
      "Epoch 275: Train 1.6876454181969165, Test 1.6412794589996338\n",
      "Epoch 300, lr 3.515625e-07\n",
      "Epoch 300: Train 1.6870392568409442, Test 1.6407872438430786\n",
      "Epoch 325, lr 8.7890625e-08\n",
      "Epoch 325: Train 1.6868692822754383, Test 1.6406522989273071\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 1.6868110585957765, Test 1.6406066417694092\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 1.6867848977446556, Test 1.6405861377716064\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 1.6867655765265226, Test 1.640570878982544\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 1.6867466922849417, Test 1.64055597782135\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 1.6867282167077065, Test 1.6405413150787354\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 1.6867100819945335, Test 1.6405270099639893\n",
      "TRAINING MODEL dt_norm_1_30\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.7811498682945968, Test 1.6657187938690186\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 1.4660237450152636, Test 1.4356328248977661\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 1.446521146222949, Test 1.4124436378479004\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 1.4332036461681128, Test 1.3980201482772827\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 1.4228513337671758, Test 1.3870187997817993\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 1.4127836275845767, Test 1.3751897811889648\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 1.4058074325323104, Test 1.3683290481567383\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 1.3991381216794252, Test 1.3605176210403442\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 1.3941678378731013, Test 1.3555176258087158\n",
      "Epoch 225, lr 2.25e-05\n",
      "Epoch 225: Train 1.3811077378690242, Test 1.3436294794082642\n",
      "Epoch 250, lr 1.125e-05\n",
      "Epoch 250: Train 1.3736941490322352, Test 1.3370497226715088\n",
      "Epoch 275, lr 1.125e-05\n",
      "Epoch 275: Train 1.3719685710966587, Test 1.3353304862976074\n",
      "Epoch 300, lr 5.625e-06\n",
      "Epoch 300: Train 1.3682991590350866, Test 1.3316311836242676\n",
      "Epoch 325, lr 5.625e-06\n",
      "Epoch 325: Train 1.3674267049878837, Test 1.3309406042099\n",
      "Epoch 350, lr 2.8125e-06\n",
      "Epoch 350: Train 1.3656076218932867, Test 1.3290915489196777\n",
      "Epoch 375, lr 1.40625e-06\n",
      "Epoch 375: Train 1.364673475921154, Test 1.3281800746917725\n",
      "Epoch 400, lr 3.515625e-07\n",
      "Epoch 400: Train 1.3640820987522602, Test 1.3276185989379883\n",
      "Epoch 425, lr 8.7890625e-08\n",
      "Epoch 425: Train 1.3639196936041116, Test 1.327469825744629\n",
      "Epoch 450, lr 2.197265625e-08\n",
      "Epoch 450: Train 1.3638730123639107, Test 1.3274279832839966\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 1.363859010115266, Test 1.3274166584014893\n",
      "TRAINING MODEL dt_norm_1_31\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.647841487452388, Test 1.5133394002914429\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 1.3165496066212654, Test 1.2954261302947998\n",
      "Epoch 50, lr 2.25e-05\n",
      "Epoch 50: Train 1.3031861416995525, Test 1.2783464193344116\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 1.296483675763011, Test 1.2703158855438232\n",
      "Epoch 100, lr 2.25e-05\n",
      "Epoch 100: Train 1.2843896659091114, Test 1.2562212944030762\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 1.2822124861180781, Test 1.2543413639068604\n",
      "Epoch 150, lr 1.125e-05\n",
      "Epoch 150: Train 1.2748209906741976, Test 1.2462646961212158\n",
      "Epoch 175, lr 1.125e-05\n",
      "Epoch 175: Train 1.2731371941044927, Test 1.2445132732391357\n",
      "Epoch 200, lr 1.125e-05\n",
      "Epoch 200: Train 1.2722853258252145, Test 1.2434738874435425\n",
      "Epoch 225, lr 1.125e-05\n",
      "Epoch 225: Train 1.2716473160311579, Test 1.2426857948303223\n",
      "Epoch 250, lr 1.125e-05\n",
      "Epoch 250: Train 1.2710172343999147, Test 1.2414989471435547\n",
      "Epoch 275, lr 1.125e-05\n",
      "Epoch 275: Train 1.2699820147827268, Test 1.2406319379806519\n",
      "Epoch 300, lr 1.125e-05\n",
      "Epoch 300: Train 1.268697634898126, Test 1.2396628856658936\n",
      "Epoch 325, lr 1.125e-05\n",
      "Epoch 325: Train 1.2675832699984313, Test 1.2380638122558594\n",
      "Epoch 350, lr 1.125e-05\n",
      "Epoch 350: Train 1.2667271690443158, Test 1.2372071743011475\n",
      "Epoch 375, lr 1.125e-05\n",
      "Epoch 375: Train 1.2657765220850705, Test 1.2357395887374878\n",
      "Epoch 400, lr 1.125e-05\n",
      "Epoch 400: Train 1.2648461347445845, Test 1.2351046800613403\n",
      "Epoch 425, lr 1.125e-05\n",
      "Epoch 425: Train 1.2640917401760816, Test 1.234243631362915\n",
      "Epoch 450, lr 1.125e-05\n",
      "Epoch 450: Train 1.2633055087178946, Test 1.233180284500122\n",
      "Epoch 475, lr 1.125e-05\n",
      "Epoch 475: Train 1.2619720054790378, Test 1.2317700386047363\n",
      "TRAINING MODEL dt_norm_1_32\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.44504689052701, Test 1.323612928390503\n",
      "Epoch 25, lr 2.25e-05\n",
      "Epoch 25: Train 1.1775792501866817, Test 1.1548455953598022\n",
      "Epoch 50, lr 2.25e-05\n",
      "Epoch 50: Train 1.1685687301680445, Test 1.1443451642990112\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 1.1616175930947066, Test 1.1378082036972046\n",
      "Epoch 100, lr 2.25e-05\n",
      "Epoch 100: Train 1.155072165466845, Test 1.1300976276397705\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 1.1481393720954656, Test 1.1238692998886108\n",
      "Epoch 150, lr 2.25e-05\n",
      "Epoch 150: Train 1.139142018929124, Test 1.1129628419876099\n",
      "Epoch 175, lr 1.125e-05\n",
      "Epoch 175: Train 1.1297392399981618, Test 1.1039706468582153\n",
      "Epoch 200, lr 1.125e-05\n",
      "Epoch 200: Train 1.1263720368966461, Test 1.1007881164550781\n",
      "Epoch 225, lr 1.125e-05\n",
      "Epoch 225: Train 1.1235272461548447, Test 1.0979453325271606\n",
      "Epoch 250, lr 1.125e-05\n",
      "Epoch 250: Train 1.1207263842225075, Test 1.0952163934707642\n",
      "Epoch 275, lr 1.125e-05\n",
      "Epoch 275: Train 1.1178532443940639, Test 1.0918623208999634\n",
      "Epoch 300, lr 1.125e-05\n",
      "Epoch 300: Train 1.1155413648113608, Test 1.0895185470581055\n",
      "Epoch 325, lr 1.125e-05\n",
      "Epoch 325: Train 1.1133601425215602, Test 1.087178349494934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350, lr 5.625e-06\n",
      "Epoch 350: Train 1.1090116394683718, Test 1.0831583738327026\n",
      "Epoch 375, lr 5.625e-06\n",
      "Epoch 375: Train 1.1075076341629029, Test 1.0815556049346924\n",
      "Epoch 400, lr 5.625e-06\n",
      "Epoch 400: Train 1.106085877865553, Test 1.0802326202392578\n",
      "Epoch 425, lr 5.625e-06\n",
      "Epoch 425: Train 1.10459755808115, Test 1.0787941217422485\n",
      "Epoch 450, lr 5.625e-06\n",
      "Epoch 450: Train 1.103187308833003, Test 1.07698655128479\n",
      "Epoch 475, lr 5.625e-06\n",
      "Epoch 475: Train 1.1016879165545106, Test 1.0755586624145508\n",
      "TRAINING MODEL dt_norm_1_33\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.154013487137854, Test 1.0694735050201416\n",
      "Epoch 25, lr 1.125e-05\n",
      "Epoch 25: Train 0.9943866284564138, Test 0.9791590571403503\n",
      "Epoch 50, lr 2.8125e-06\n",
      "Epoch 50: Train 0.9966010805219412, Test 0.9803684949874878\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.997205694951117, Test 0.9807583689689636\n",
      "Epoch 100, lr 1.7578125e-07\n",
      "Epoch 100: Train 0.9973281556740403, Test 0.9808381199836731\n",
      "Epoch 125, lr 2.197265625e-08\n",
      "Epoch 125: Train 0.9973071597516536, Test 0.9808162450790405\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.997263448126614, Test 0.9807788729667664\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.9972234103828669, Test 0.9807442426681519\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.9971835855394602, Test 0.9807105660438538\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.9971432434394956, Test 0.9806761145591736\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.9971024803817272, Test 0.98064124584198\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.9970619633793831, Test 0.9806066751480103\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.997021516226232, Test 0.9805721640586853\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.996981312148273, Test 0.9805376529693604\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.9969413170590997, Test 0.9805034399032593\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.9969015143811703, Test 0.9804694652557373\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.9968617785722017, Test 0.9804357290267944\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.996822297014296, Test 0.9804019927978516\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.9967830970883369, Test 0.9803686141967773\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.9967444449663162, Test 0.9803357124328613\n",
      "TRAINING MODEL dt_norm_2_1\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 11.91475469415838, Test 10.862446784973145\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 9.843798261700254, Test 9.849395751953125\n",
      "Epoch 50, lr 2.25e-05\n",
      "Epoch 50: Train 9.806007414153129, Test 9.81103515625\n",
      "Epoch 75, lr 1.125e-05\n",
      "Epoch 75: Train 9.796083623712713, Test 9.795127868652344\n",
      "Epoch 100, lr 5.625e-06\n",
      "Epoch 100: Train 9.7916347619259, Test 9.788747787475586\n",
      "Epoch 125, lr 1.40625e-06\n",
      "Epoch 125: Train 9.787469950589267, Test 9.785493850708008\n",
      "Epoch 150, lr 7.03125e-07\n",
      "Epoch 150: Train 9.77214798782811, Test 9.770901679992676\n",
      "Epoch 175, lr 1.7578125e-07\n",
      "Epoch 175: Train 9.771620750427246, Test 9.77031135559082\n",
      "Epoch 200, lr 4.39453125e-08\n",
      "Epoch 200: Train 9.771479895620635, Test 9.770203590393066\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 9.771454348708644, Test 9.77017593383789\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 9.771453279437441, Test 9.770173072814941\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 9.771453250538219, Test 9.770176887512207\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 9.771452007871686, Test 9.77017593383789\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 9.771452845949115, Test 9.770174980163574\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 9.7714512275927, Test 9.77017593383789\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 9.771452065670129, Test 9.770174980163574\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 9.771451372088809, Test 9.770174026489258\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 9.771451863375576, Test 9.770177841186523\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 9.771449435840953, Test 9.770174026489258\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 9.771449782631613, Test 9.77017593383789\n",
      "TRAINING MODEL dt_norm_2_3\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 15.638725382089614, Test 15.16859245300293\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 13.207327377796172, Test 13.118098258972168\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 13.006362274289131, Test 12.911314010620117\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 12.918005129694938, Test 12.823219299316406\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 12.819291025400162, Test 12.720268249511719\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 12.764738434553147, Test 12.662527084350586\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 12.727827659249305, Test 12.636089324951172\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 12.714085066318512, Test 12.624279022216797\n",
      "Epoch 200, lr 1.125e-05\n",
      "Epoch 200: Train 12.6792813539505, Test 12.584835052490234\n",
      "Epoch 225, lr 2.8125e-06\n",
      "Epoch 225: Train 12.673267900943756, Test 12.578941345214844\n",
      "Epoch 250, lr 7.03125e-07\n",
      "Epoch 250: Train 12.66884800195694, Test 12.57432746887207\n",
      "Epoch 275, lr 1.7578125e-07\n",
      "Epoch 275: Train 12.668276378512383, Test 12.573700904846191\n",
      "Epoch 300, lr 4.39453125e-08\n",
      "Epoch 300: Train 12.668142545223237, Test 12.573558807373047\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 12.668110060691834, Test 12.573528289794922\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 12.66810771226883, Test 12.573525428771973\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 12.66810493171215, Test 12.573524475097656\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 12.668102473020554, Test 12.573521614074707\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 12.66809984743595, Test 12.573519706726074\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 12.66809730231762, Test 12.573517799377441\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 12.668094757199288, Test 12.573514938354492\n",
      "TRAINING MODEL dt_norm_2_5\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 18.440840950608255, Test 18.08876609802246\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 16.389767956733703, Test 16.317249298095703\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 16.005779987573625, Test 15.940702438354492\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 15.786814084649086, Test 15.723955154418945\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 15.696909585595131, Test 15.640846252441406\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 15.638434931635857, Test 15.581673622131348\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 15.585798344016075, Test 15.526580810546875\n",
      "Epoch 175, lr 2.25e-05\n",
      "Epoch 175: Train 15.509678572416306, Test 15.426965713500977\n",
      "Epoch 200, lr 2.25e-05\n",
      "Epoch 200: Train 15.464221876859664, Test 15.375259399414062\n",
      "Epoch 225, lr 2.25e-05\n",
      "Epoch 225: Train 15.436384263634682, Test 15.350669860839844\n",
      "Epoch 250, lr 2.25e-05\n",
      "Epoch 250: Train 15.420836317539216, Test 15.335384368896484\n",
      "Epoch 275, lr 1.125e-05\n",
      "Epoch 275: Train 15.396775141358376, Test 15.31027603149414\n",
      "Epoch 300, lr 1.40625e-06\n",
      "Epoch 300: Train 15.385051938891412, Test 15.29767894744873\n",
      "Epoch 325, lr 3.515625e-07\n",
      "Epoch 325: Train 15.38191723227501, Test 15.294663429260254\n",
      "Epoch 350, lr 8.7890625e-08\n",
      "Epoch 350: Train 15.381510102748871, Test 15.29423713684082\n",
      "Epoch 375, lr 2.197265625e-08\n",
      "Epoch 375: Train 15.381414899230004, Test 15.294130325317383\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 15.381394788622856, Test 15.294110298156738\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 15.381389385461807, Test 15.294107437133789\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 15.381384247541428, Test 15.29410171508789\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 15.381379041075707, Test 15.294095993041992\n",
      "TRAINING MODEL dt_norm_2_7\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 18.311282348632812, Test 18.220121383666992\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 16.93028109818697, Test 16.864749908447266\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 16.687085610628127, Test 16.605998992919922\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 16.5265475705266, Test 16.43960952758789\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 16.37144647538662, Test 16.398685455322266\n",
      "Epoch 125, lr 1.125e-05\n",
      "Epoch 125: Train 16.18854840397835, Test 16.23906135559082\n",
      "Epoch 150, lr 2.8125e-06\n",
      "Epoch 150: Train 16.164163811504842, Test 16.215595245361328\n",
      "Epoch 175, lr 7.03125e-07\n",
      "Epoch 175: Train 16.158100230991842, Test 16.209896087646484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, lr 1.7578125e-07\n",
      "Epoch 200: Train 16.1566929936409, Test 16.208600997924805\n",
      "Epoch 225, lr 4.39453125e-08\n",
      "Epoch 225: Train 16.15632920116186, Test 16.208267211914062\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 16.156248196959496, Test 16.208192825317383\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 16.156229707598687, Test 16.208175659179688\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 16.156211805343627, Test 16.208158493041992\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 16.15619299411774, Test 16.208141326904297\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 16.156175217032434, Test 16.20812225341797\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 16.15615695863962, Test 16.208105087280273\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 16.15613876581192, Test 16.208086013793945\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 16.15612068027258, Test 16.20806884765625\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 16.156102958321572, Test 16.208053588867188\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 16.156084625422956, Test 16.20803451538086\n",
      "TRAINING MODEL dt_norm_2_9\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 13.852858048677444, Test 13.623037338256836\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 12.782231429219246, Test 12.63049602508545\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 12.423103785514831, Test 12.354649543762207\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 12.242906801402569, Test 12.227067947387695\n",
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 12.184486700594425, Test 12.183206558227539\n",
      "Epoch 125, lr 1.125e-05\n",
      "Epoch 125: Train 12.160818056762219, Test 12.156291961669922\n",
      "Epoch 150, lr 1.125e-05\n",
      "Epoch 150: Train 12.146705408394336, Test 12.142923355102539\n",
      "Epoch 175, lr 5.625e-06\n",
      "Epoch 175: Train 12.129655994474888, Test 12.127917289733887\n",
      "Epoch 200, lr 2.8125e-06\n",
      "Epoch 200: Train 12.120687648653984, Test 12.118805885314941\n",
      "Epoch 225, lr 7.03125e-07\n",
      "Epoch 225: Train 12.116847738623619, Test 12.115482330322266\n",
      "Epoch 250, lr 1.7578125e-07\n",
      "Epoch 250: Train 12.115946470201015, Test 12.114614486694336\n",
      "Epoch 275, lr 2.197265625e-08\n",
      "Epoch 275: Train 12.115725322067737, Test 12.11441421508789\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 12.115673086047172, Test 12.11436939239502\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 12.115662357211113, Test 12.114357948303223\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 12.115651999413966, Test 12.114348411560059\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 12.115641452372074, Test 12.114340782165527\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 12.115631034970283, Test 12.11432933807373\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 12.115620404481888, Test 12.11431884765625\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 12.11560974419117, Test 12.114309310913086\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 12.115599516034127, Test 12.114299774169922\n",
      "TRAINING MODEL dt_norm_2_11\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 8.94235943555832, Test 8.669257164001465\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 7.614942546188831, Test 7.454289436340332\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 7.503785209357739, Test 7.295612812042236\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 7.342744471132756, Test 7.221063137054443\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 7.30482227653265, Test 7.144288063049316\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 7.201139876246453, Test 7.090436935424805\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 7.155185249447823, Test 7.061587810516357\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 7.175486472249031, Test 7.045368194580078\n",
      "Epoch 200, lr 2.25e-05\n",
      "Epoch 200: Train 7.043162307143211, Test 6.999783515930176\n",
      "Epoch 225, lr 1.125e-05\n",
      "Epoch 225: Train 7.051426886022091, Test 6.998597145080566\n",
      "Epoch 250, lr 5.625e-06\n",
      "Epoch 250: Train 7.019084829092026, Test 6.978845596313477\n",
      "Epoch 275, lr 2.8125e-06\n",
      "Epoch 275: Train 7.01560475230217, Test 6.974949359893799\n",
      "Epoch 300, lr 7.03125e-07\n",
      "Epoch 300: Train 7.013385488092899, Test 6.972623348236084\n",
      "Epoch 325, lr 8.7890625e-08\n",
      "Epoch 325: Train 7.012769892811775, Test 6.972026348114014\n",
      "Epoch 350, lr 2.197265625e-08\n",
      "Epoch 350: Train 7.012688258290291, Test 6.971944808959961\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 7.012674836814403, Test 6.97192907333374\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 7.012671183049679, Test 6.971926689147949\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 7.012667761743069, Test 6.971924781799316\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 7.012664899230003, Test 6.971920013427734\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 7.012661224603653, Test 6.971917152404785\n",
      "TRAINING MODEL dt_norm_2_13\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 6.504169617593289, Test 6.2060041427612305\n",
      "Epoch 25, lr 2.25e-05\n",
      "Epoch 25: Train 5.305392128229141, Test 5.244833946228027\n",
      "Epoch 50, lr 1.125e-05\n",
      "Epoch 50: Train 5.237594050168991, Test 5.182391166687012\n",
      "Epoch 75, lr 1.125e-05\n",
      "Epoch 75: Train 5.213005241006613, Test 5.15757417678833\n",
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 5.198129627853632, Test 5.143641948699951\n",
      "Epoch 125, lr 5.625e-06\n",
      "Epoch 125: Train 5.1880027882754804, Test 5.133974075317383\n",
      "Epoch 150, lr 5.625e-06\n",
      "Epoch 150: Train 5.183204585313797, Test 5.128796100616455\n",
      "Epoch 175, lr 5.625e-06\n",
      "Epoch 175: Train 5.178946355730295, Test 5.1251983642578125\n",
      "Epoch 200, lr 5.625e-06\n",
      "Epoch 200: Train 5.175014740228653, Test 5.121517181396484\n",
      "Epoch 225, lr 1.40625e-06\n",
      "Epoch 225: Train 5.1709367141127585, Test 5.117307662963867\n",
      "Epoch 250, lr 3.515625e-07\n",
      "Epoch 250: Train 5.1687705799937245, Test 5.1150617599487305\n",
      "Epoch 275, lr 8.7890625e-08\n",
      "Epoch 275: Train 5.1684317968785765, Test 5.114757537841797\n",
      "Epoch 300, lr 2.197265625e-08\n",
      "Epoch 300: Train 5.168345718830824, Test 5.114677906036377\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 5.168329114466905, Test 5.114662170410156\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 5.168321622163058, Test 5.114655494689941\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 5.168314510583878, Test 5.114649772644043\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 5.168307321518659, Test 5.114643096923828\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 5.168300069868565, Test 5.114636421203613\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 5.168292883038521, Test 5.114629745483398\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 5.168285619467497, Test 5.114622592926025\n",
      "TRAINING MODEL dt_norm_2_15\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 5.28263529241085, Test 4.9548139572143555\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 4.242213755100965, Test 4.191015243530273\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 4.1743376269936565, Test 4.116889953613281\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 4.049643028527498, Test 3.99652099609375\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 4.031434173136949, Test 3.9794669151306152\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 3.9933575287461283, Test 3.9346671104431152\n",
      "Epoch 150, lr 5.625e-06\n",
      "Epoch 150: Train 3.9850186966359615, Test 3.9277544021606445\n",
      "Epoch 175, lr 2.8125e-06\n",
      "Epoch 175: Train 3.9804853975772856, Test 3.92238712310791\n",
      "Epoch 200, lr 3.515625e-07\n",
      "Epoch 200: Train 3.97926819473505, Test 3.921224355697632\n",
      "Epoch 225, lr 8.7890625e-08\n",
      "Epoch 225: Train 3.978932935744524, Test 3.9209275245666504\n",
      "Epoch 250, lr 2.197265625e-08\n",
      "Epoch 250: Train 3.9788933485746383, Test 3.9208884239196777\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 3.9788846991956235, Test 3.9208791255950928\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 3.9788819551467896, Test 3.920877456665039\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 3.9788790479302407, Test 3.9208760261535645\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 3.9788762383162974, Test 3.9208738803863525\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 3.9788733400404452, Test 3.9208717346191406\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 3.978870466351509, Test 3.920869827270508\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 3.978867746889591, Test 3.920868396759033\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 3.9788648784160614, Test 3.9208664894104004\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 3.9788620077073573, Test 3.9208638668060303\n",
      "TRAINING MODEL dt_norm_2_17\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 4.575780783593655, Test 4.233343124389648\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 3.596513621509075, Test 3.559216260910034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 3.5370469741523265, Test 3.501936912536621\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 3.515253622084856, Test 3.4748597145080566\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 3.4801401935517786, Test 3.440030097961426\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 3.468618004024029, Test 3.4308266639709473\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 3.4593882121145727, Test 3.4188246726989746\n",
      "Epoch 175, lr 2.25e-05\n",
      "Epoch 175: Train 3.4430885650217533, Test 3.4061245918273926\n",
      "Epoch 200, lr 5.625e-06\n",
      "Epoch 200: Train 3.4331147730350495, Test 3.3947601318359375\n",
      "Epoch 225, lr 2.8125e-06\n",
      "Epoch 225: Train 3.430597872287035, Test 3.3921737670898438\n",
      "Epoch 250, lr 1.40625e-06\n",
      "Epoch 250: Train 3.4297018758952618, Test 3.390692710876465\n",
      "Epoch 275, lr 1.7578125e-07\n",
      "Epoch 275: Train 3.429108028113842, Test 3.3901634216308594\n",
      "Epoch 300, lr 8.7890625e-08\n",
      "Epoch 300: Train 3.4289631485939025, Test 3.3900034427642822\n",
      "Epoch 325, lr 2.197265625e-08\n",
      "Epoch 325: Train 3.428924824297428, Test 3.389960289001465\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 3.4289173752069475, Test 3.38995361328125\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 3.4289157070219516, Test 3.3899519443511963\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 3.42891364172101, Test 3.389951229095459\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 3.4289116889238356, Test 3.3899505138397217\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 3.428909696638584, Test 3.3899497985839844\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 3.4289080426096916, Test 3.3899483680725098\n",
      "TRAINING MODEL dt_norm_2_19\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 4.6145752690732476, Test 4.293909072875977\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 3.6606935299932957, Test 3.6332335472106934\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 3.626944263279438, Test 3.600050210952759\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 3.575676432996988, Test 3.542393684387207\n",
      "Epoch 100, lr 2.25e-05\n",
      "Epoch 100: Train 3.5397600598633288, Test 3.507214069366455\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 3.53090847954154, Test 3.497969388961792\n",
      "Epoch 150, lr 1.125e-05\n",
      "Epoch 150: Train 3.5239067181944845, Test 3.4913249015808105\n",
      "Epoch 175, lr 5.625e-06\n",
      "Epoch 175: Train 3.5203661620616913, Test 3.4878673553466797\n",
      "Epoch 200, lr 2.8125e-06\n",
      "Epoch 200: Train 3.518740765750408, Test 3.4864747524261475\n",
      "Epoch 225, lr 7.03125e-07\n",
      "Epoch 225: Train 3.5176099352538586, Test 3.485175609588623\n",
      "Epoch 250, lr 1.7578125e-07\n",
      "Epoch 250: Train 3.517330702394247, Test 3.4848499298095703\n",
      "Epoch 275, lr 4.39453125e-08\n",
      "Epoch 275: Train 3.5172554180026054, Test 3.4847846031188965\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 3.5172359317541124, Test 3.4847657680511475\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 3.517235068976879, Test 3.4847652912139893\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 3.517234644293785, Test 3.4847660064697266\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 3.517233555018902, Test 3.4847657680511475\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 3.5172329947352408, Test 3.48476505279541\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 3.517232445627451, Test 3.4847640991210938\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 3.5172317810356617, Test 3.48476505279541\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 3.517230935394764, Test 3.484764337539673\n",
      "TRAINING MODEL dt_norm_2_21\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 3.2873213663697243, Test 3.058411121368408\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 2.64215344004333, Test 2.627440929412842\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 2.558854450285435, Test 2.5368924140930176\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 2.5370150111615657, Test 2.5175137519836426\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 2.5145442854613065, Test 2.4881858825683594\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 2.485245968028903, Test 2.460235118865967\n",
      "Epoch 150, lr 1.125e-05\n",
      "Epoch 150: Train 2.4717326018959285, Test 2.4456377029418945\n",
      "Epoch 175, lr 1.125e-05\n",
      "Epoch 175: Train 2.4576221611350775, Test 2.431039571762085\n",
      "Epoch 200, lr 1.125e-05\n",
      "Epoch 200: Train 2.453269137814641, Test 2.4276084899902344\n",
      "Epoch 225, lr 5.625e-06\n",
      "Epoch 225: Train 2.451676782593131, Test 2.4250667095184326\n",
      "Epoch 250, lr 2.8125e-06\n",
      "Epoch 250: Train 2.446235469728708, Test 2.4199259281158447\n",
      "Epoch 275, lr 3.515625e-07\n",
      "Epoch 275: Train 2.4446365270763635, Test 2.4182047843933105\n",
      "Epoch 300, lr 1.7578125e-07\n",
      "Epoch 300: Train 2.4442442916333675, Test 2.4178147315979004\n",
      "Epoch 325, lr 2.197265625e-08\n",
      "Epoch 325: Train 2.4441390939056875, Test 2.4177122116088867\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 2.444126191362739, Test 2.41770076751709\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 2.4441207993775604, Test 2.417696952819824\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 2.4441152587532997, Test 2.417691230773926\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 2.444109722971916, Test 2.417686700820923\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 2.4441042099148036, Test 2.417682647705078\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 2.4440987180918454, Test 2.417677879333496\n",
      "TRAINING MODEL dt_norm_2_23\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 3.2269211357290093, Test 2.936285972595215\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 2.5685311309941166, Test 2.5497074127197266\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 2.5284709709507602, Test 2.5000460147857666\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 2.5172240546533278, Test 2.4923620223999023\n",
      "Epoch 100, lr 2.25e-05\n",
      "Epoch 100: Train 2.4959678579043674, Test 2.4688310623168945\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 2.47508028420535, Test 2.446608066558838\n",
      "Epoch 150, lr 2.25e-05\n",
      "Epoch 150: Train 2.4700918906218523, Test 2.4403724670410156\n",
      "Epoch 175, lr 2.25e-05\n",
      "Epoch 175: Train 2.4694734161550347, Test 2.4393389225006104\n",
      "Epoch 200, lr 5.625e-06\n",
      "Epoch 200: Train 2.4626394135135037, Test 2.4331798553466797\n",
      "Epoch 225, lr 2.8125e-06\n",
      "Epoch 225: Train 2.461573068912213, Test 2.4318084716796875\n",
      "Epoch 250, lr 7.03125e-07\n",
      "Epoch 250: Train 2.4606542295509284, Test 2.4307193756103516\n",
      "Epoch 275, lr 8.7890625e-08\n",
      "Epoch 275: Train 2.460440800323353, Test 2.430508613586426\n",
      "Epoch 300, lr 2.197265625e-08\n",
      "Epoch 300: Train 2.460374826734716, Test 2.4304451942443848\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 2.460369322266612, Test 2.43044114112854\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 2.460368529066339, Test 2.430440902709961\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 2.4603681039143277, Test 2.430441379547119\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 2.4603674424278155, Test 2.430441379547119\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 2.4603666242186004, Test 2.430440902709961\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 2.4603659527285116, Test 2.430440902709961\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 2.4603653600165893, Test 2.430440902709961\n",
      "TRAINING MODEL dt_norm_2_25\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 2.6923746806753557, Test 2.4149599075317383\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 2.113447436505118, Test 2.080017566680908\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 2.031065621618497, Test 1.9834387302398682\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 2.0202362961688283, Test 1.9756087064743042\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 2.0120567325818337, Test 1.9609489440917969\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 1.9921149547490697, Test 1.9424424171447754\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 1.988192709152308, Test 1.9354069232940674\n",
      "Epoch 175, lr 1.125e-05\n",
      "Epoch 175: Train 1.9777088683877289, Test 1.9228034019470215\n",
      "Epoch 200, lr 2.8125e-06\n",
      "Epoch 200: Train 1.9748866591749892, Test 1.9197814464569092\n",
      "Epoch 225, lr 7.03125e-07\n",
      "Epoch 225: Train 1.974234400495971, Test 1.9190278053283691\n",
      "Epoch 250, lr 1.7578125e-07\n",
      "Epoch 250: Train 1.9740643036567558, Test 1.9188053607940674\n",
      "Epoch 275, lr 4.39453125e-08\n",
      "Epoch 275: Train 1.974020235282553, Test 1.9187514781951904\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 1.9740097199456166, Test 1.91874098777771\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 1.9740089077060505, Test 1.918741226196289\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 1.97400823959523, Test 1.9187407493591309\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 1.9740075687904142, Test 1.918741226196289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 1.9740068791276317, Test 1.91874098777771\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 1.97400618340336, Test 1.9187405109405518\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 1.97400532805987, Test 1.9187402725219727\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 1.9740046215596172, Test 1.9187405109405518\n",
      "TRAINING MODEL dt_norm_2_27\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.5856814028380752, Test 1.372949242591858\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 1.1601677962711878, Test 1.1424410343170166\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 1.1205718559878213, Test 1.0953384637832642\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 1.1048895410903088, Test 1.0784547328948975\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 1.0855439142747358, Test 1.057971477508545\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 1.078352197811201, Test 1.0480488538742065\n",
      "Epoch 150, lr 5.625e-06\n",
      "Epoch 150: Train 1.070343946868723, Test 1.0397300720214844\n",
      "Epoch 175, lr 2.8125e-06\n",
      "Epoch 175: Train 1.068539491721562, Test 1.037903070449829\n",
      "Epoch 200, lr 7.03125e-07\n",
      "Epoch 200: Train 1.067958969187427, Test 1.0373055934906006\n",
      "Epoch 225, lr 8.7890625e-08\n",
      "Epoch 225: Train 1.0677895151175463, Test 1.037154197692871\n",
      "Epoch 250, lr 2.197265625e-08\n",
      "Epoch 250: Train 1.0677692553439697, Test 1.0371397733688354\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 1.0677664051582287, Test 1.037136435508728\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 1.067766390063546, Test 1.0371360778808594\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 1.0677664260585586, Test 1.0371366739273071\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 1.067766293689802, Test 1.0371358394622803\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 1.0677663463276703, Test 1.0371358394622803\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 1.0677664500552337, Test 1.0371359586715698\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 1.0677663707113885, Test 1.0371360778808594\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 1.0677663265884696, Test 1.0371357202529907\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 1.0677664616665283, Test 1.0371358394622803\n",
      "TRAINING MODEL dt_norm_2_29\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.1534876923105415, Test 1.0254939794540405\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.8438254621248603, Test 0.8219019174575806\n",
      "Epoch 50, lr 2.25e-05\n",
      "Epoch 50: Train 0.8509612956144704, Test 0.8281959295272827\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 0.8341899921055946, Test 0.8098798990249634\n",
      "Epoch 100, lr 2.25e-05\n",
      "Epoch 100: Train 0.8321901484561048, Test 0.8074936866760254\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 0.8309226811135588, Test 0.8041414022445679\n",
      "Epoch 150, lr 5.625e-06\n",
      "Epoch 150: Train 0.8279766015225303, Test 0.8015997409820557\n",
      "Epoch 175, lr 2.8125e-06\n",
      "Epoch 175: Train 0.8275459962086466, Test 0.8009154796600342\n",
      "Epoch 200, lr 2.8125e-06\n",
      "Epoch 200: Train 0.8276788641161479, Test 0.8008717894554138\n",
      "Epoch 225, lr 7.03125e-07\n",
      "Epoch 225: Train 0.8272840610543208, Test 0.8005704879760742\n",
      "Epoch 250, lr 1.7578125e-07\n",
      "Epoch 250: Train 0.8272040500575772, Test 0.8004840612411499\n",
      "Epoch 275, lr 2.197265625e-08\n",
      "Epoch 275: Train 0.827172059247925, Test 0.8004472255706787\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.8271634680419245, Test 0.8004424571990967\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.8271575747089581, Test 0.8004390597343445\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.8271518703613672, Test 0.8004368543624878\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.8271460952205463, Test 0.8004342317581177\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.8271403933141012, Test 0.8004312515258789\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.8271346981208072, Test 0.8004287481307983\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.8271289539011673, Test 0.8004252910614014\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.8271232682690278, Test 0.8004224300384521\n",
      "TRAINING MODEL dt_norm_2_30\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.316464947591914, Test 1.1483139991760254\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.9659400862632411, Test 0.9552435874938965\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 0.9491149246102513, Test 0.933840274810791\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 0.9364058266181757, Test 0.9207409620285034\n",
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 0.9313189729605571, Test 0.9144814610481262\n",
      "Epoch 125, lr 5.625e-06\n",
      "Epoch 125: Train 0.9265456108173521, Test 0.9099632501602173\n",
      "Epoch 150, lr 5.625e-06\n",
      "Epoch 150: Train 0.9226206691548375, Test 0.9054087400436401\n",
      "Epoch 175, lr 5.625e-06\n",
      "Epoch 175: Train 0.9208557045105661, Test 0.9037171602249146\n",
      "Epoch 200, lr 2.8125e-06\n",
      "Epoch 200: Train 0.9194440118747182, Test 0.9021719694137573\n",
      "Epoch 225, lr 2.8125e-06\n",
      "Epoch 225: Train 0.9161266528143741, Test 0.89884352684021\n",
      "Epoch 250, lr 2.8125e-06\n",
      "Epoch 250: Train 0.914848392847741, Test 0.8975470066070557\n",
      "Epoch 275, lr 2.8125e-06\n",
      "Epoch 275: Train 0.9140723436185629, Test 0.8964561223983765\n",
      "Epoch 300, lr 2.8125e-06\n",
      "Epoch 300: Train 0.906994102614941, Test 0.8885549306869507\n",
      "Epoch 325, lr 2.8125e-06\n",
      "Epoch 325: Train 0.8894649561088864, Test 0.8717361688613892\n",
      "Epoch 350, lr 2.8125e-06\n",
      "Epoch 350: Train 0.8852578410417726, Test 0.8676609992980957\n",
      "Epoch 375, lr 2.8125e-06\n",
      "Epoch 375: Train 0.8839298011642871, Test 0.8662200570106506\n",
      "Epoch 400, lr 2.8125e-06\n",
      "Epoch 400: Train 0.8823936785211658, Test 0.8645929098129272\n",
      "Epoch 425, lr 2.8125e-06\n",
      "Epoch 425: Train 0.8811318136677884, Test 0.8633652925491333\n",
      "Epoch 450, lr 2.8125e-06\n",
      "Epoch 450: Train 0.8801762376091268, Test 0.8623038530349731\n",
      "Epoch 475, lr 2.8125e-06\n",
      "Epoch 475: Train 0.8796383818187336, Test 0.8616161942481995\n",
      "TRAINING MODEL dt_norm_2_31\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.002356160570074, Test 0.8857531547546387\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.7668690089090371, Test 0.7511768341064453\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 0.7234023739526301, Test 0.7071289420127869\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 0.6706747188244337, Test 0.6513172388076782\n",
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 0.652056195485739, Test 0.6326232552528381\n",
      "Epoch 125, lr 2.8125e-06\n",
      "Epoch 125: Train 0.6490415577535276, Test 0.6294674873352051\n",
      "Epoch 150, lr 7.03125e-07\n",
      "Epoch 150: Train 0.6484119682400314, Test 0.6287823915481567\n",
      "Epoch 175, lr 1.7578125e-07\n",
      "Epoch 175: Train 0.6483347099504353, Test 0.6286916732788086\n",
      "Epoch 200, lr 4.39453125e-08\n",
      "Epoch 200: Train 0.6483264889246152, Test 0.628683865070343\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.6483237482147453, Test 0.6286789178848267\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.6483240885499083, Test 0.6286792159080505\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.6483243431574033, Test 0.6286790370941162\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.6483246183689729, Test 0.6286792755126953\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.6483249925536874, Test 0.6286795139312744\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.6483252026416637, Test 0.6286798119544983\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.6483254612963877, Test 0.6286797523498535\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.6483258652834245, Test 0.6286797523498535\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.648326141230854, Test 0.6286799311637878\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.6483264388861479, Test 0.6286799907684326\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.6483267328621428, Test 0.6286797523498535\n",
      "TRAINING MODEL dt_norm_2_32\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.05451781697133, Test 0.9440361261367798\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.7893939640592126, Test 0.7761309146881104\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 0.7644742990241331, Test 0.7471365928649902\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 0.7590587928014643, Test 0.7395599484443665\n",
      "Epoch 100, lr 2.25e-05\n",
      "Epoch 100: Train 0.750788523870356, Test 0.7308335304260254\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 0.7259636635289473, Test 0.7049424648284912\n",
      "Epoch 150, lr 2.25e-05\n",
      "Epoch 150: Train 0.7010076729690328, Test 0.679879367351532\n",
      "Epoch 175, lr 5.625e-06\n",
      "Epoch 175: Train 0.6994328853838584, Test 0.6781318187713623\n",
      "Epoch 200, lr 1.40625e-06\n",
      "Epoch 200: Train 0.6990445278146687, Test 0.6778101921081543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225, lr 3.515625e-07\n",
      "Epoch 225: Train 0.6989856625304502, Test 0.677740216255188\n",
      "Epoch 250, lr 8.7890625e-08\n",
      "Epoch 250: Train 0.6989709436893463, Test 0.6777274012565613\n",
      "Epoch 275, lr 2.197265625e-08\n",
      "Epoch 275: Train 0.6989664466065519, Test 0.6777225732803345\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.6989655819009332, Test 0.6777213215827942\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.6989655087099356, Test 0.6777210235595703\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.6989654504200992, Test 0.6777210235595703\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.6989653119269539, Test 0.677720844745636\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.6989652023595923, Test 0.6777206659317017\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.6989651440697557, Test 0.6777201890945435\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.698964973582941, Test 0.677720308303833\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.698964873657507, Test 0.6777198314666748\n",
      "TRAINING MODEL dt_norm_2_34\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 1.0388372758403421, Test 0.9633995890617371\n",
      "Epoch 25, lr 2.25e-05\n",
      "Epoch 25: Train 0.9066593512892723, Test 0.8962024450302124\n",
      "Epoch 50, lr 2.8125e-06\n",
      "Epoch 50: Train 0.9044483112171292, Test 0.8931522369384766\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.9046772250905633, Test 0.893413782119751\n",
      "Epoch 100, lr 1.7578125e-07\n",
      "Epoch 100: Train 0.904729044996202, Test 0.8934659957885742\n",
      "Epoch 125, lr 4.39453125e-08\n",
      "Epoch 125: Train 0.904727554321289, Test 0.8934646844863892\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.9047124920412898, Test 0.8934496641159058\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.9047027129679919, Test 0.8934410810470581\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.904692929238081, Test 0.8934318423271179\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.904683274589479, Test 0.8934229016304016\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.9046734564006329, Test 0.8934139013290405\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.9046638188883662, Test 0.8934052586555481\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.9046541290357709, Test 0.8933964967727661\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.9046445621177555, Test 0.8933876752853394\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.9046348787844181, Test 0.8933787941932678\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.904625165835023, Test 0.8933702707290649\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.9046155884861946, Test 0.8933614492416382\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.9046059891581535, Test 0.8933525681495667\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.9045965392142534, Test 0.8933438658714294\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.904586824402213, Test 0.8933352828025818\n",
      "TRAINING MODEL dt_norm_2_35\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.8724449736997485, Test 0.8040839433670044\n",
      "Epoch 25, lr 2.25e-05\n",
      "Epoch 25: Train 0.7780181715264917, Test 0.7668992280960083\n",
      "Epoch 50, lr 5.625e-06\n",
      "Epoch 50: Train 0.7869921751320362, Test 0.7750343680381775\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.7882451279088855, Test 0.7761699557304382\n",
      "Epoch 100, lr 1.7578125e-07\n",
      "Epoch 100: Train 0.7885611522942781, Test 0.7764540910720825\n",
      "Epoch 125, lr 4.39453125e-08\n",
      "Epoch 125: Train 0.7886173967272043, Test 0.7765082716941833\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.788613386824727, Test 0.776504397392273\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.7886077729985118, Test 0.7764987945556641\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.7886020993813873, Test 0.7764932513237\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.7885963363572955, Test 0.7764880657196045\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.7885907709598541, Test 0.7764824032783508\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.7885853551328182, Test 0.7764775156974792\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.7885798728093505, Test 0.7764725685119629\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.7885746845975519, Test 0.7764673829078674\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.7885695254430175, Test 0.776462733745575\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.7885643208399415, Test 0.7764570713043213\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.7885591311380267, Test 0.7764521837234497\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.7885539749637246, Test 0.7764472961425781\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.7885489083826542, Test 0.7764423489570618\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.7885437892749906, Test 0.7764376401901245\n",
      "TRAINING MODEL dt_norm_2_36\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.7737888380885124, Test 0.7041906118392944\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.6692167520523071, Test 0.6604079604148865\n",
      "Epoch 50, lr 5.625e-06\n",
      "Epoch 50: Train 0.6697811149992049, Test 0.6614295840263367\n",
      "Epoch 75, lr 1.40625e-06\n",
      "Epoch 75: Train 0.6699006328359246, Test 0.661564290523529\n",
      "Epoch 100, lr 3.515625e-07\n",
      "Epoch 100: Train 0.6700913487002254, Test 0.6617587804794312\n",
      "Epoch 125, lr 8.7890625e-08\n",
      "Epoch 125: Train 0.6701205955818296, Test 0.6617950797080994\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.6701130896806717, Test 0.6617908477783203\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.6701083658263087, Test 0.6617872714996338\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.6701043339446187, Test 0.6617834568023682\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.6701002866029739, Test 0.6617804765701294\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.6700962947681546, Test 0.6617775559425354\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.6700923476368189, Test 0.6617741584777832\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.6700885552912951, Test 0.6617706418037415\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.6700846953317523, Test 0.6617680191993713\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.6700808450579643, Test 0.6617646217346191\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.6700769700109959, Test 0.661761462688446\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.6700731532648205, Test 0.6617584824562073\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.6700693394988775, Test 0.6617556214332581\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.6700655534863472, Test 0.6617527008056641\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.6700617413967848, Test 0.6617493033409119\n",
      "TRAINING MODEL dt_norm_2_37\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.735232799872756, Test 0.6818374395370483\n",
      "Epoch 25, lr 2.25e-05\n",
      "Epoch 25: Train 0.7117811061441899, Test 0.7037806510925293\n",
      "Epoch 50, lr 2.8125e-06\n",
      "Epoch 50: Train 0.715323394164443, Test 0.7061737179756165\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.7145850580185652, Test 0.7053413987159729\n",
      "Epoch 100, lr 1.7578125e-07\n",
      "Epoch 100: Train 0.7145381605252623, Test 0.7052644491195679\n",
      "Epoch 125, lr 2.197265625e-08\n",
      "Epoch 125: Train 0.7145094266161323, Test 0.7052300572395325\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.7144881099462509, Test 0.7052081823348999\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.7144728776067495, Test 0.7051923274993896\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.7144576283171773, Test 0.7051769495010376\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.7144425816833972, Test 0.7051612138748169\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.7144275486469269, Test 0.7051455974578857\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.7144125185906887, Test 0.7051302790641785\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.7143976135179401, Test 0.7051151394844055\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.7143825648352504, Test 0.7050994634628296\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.7143677806481719, Test 0.705083966255188\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.7143527695909142, Test 0.7050684094429016\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.7143379200249911, Test 0.7050533294677734\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.7143231108784676, Test 0.7050378918647766\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.7143090328201651, Test 0.7050232887268066\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.7142962126061321, Test 0.7050105333328247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL dt_norm_2_38\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.544381927186196, Test 0.4817758798599243\n",
      "Epoch 25, lr 2.25e-05\n",
      "Epoch 25: Train 0.3964937856984795, Test 0.39082959294319153\n",
      "Epoch 50, lr 5.625e-06\n",
      "Epoch 50: Train 0.4035464476007934, Test 0.397497296333313\n",
      "Epoch 75, lr 1.40625e-06\n",
      "Epoch 75: Train 0.40484266488923937, Test 0.398613303899765\n",
      "Epoch 100, lr 3.515625e-07\n",
      "Epoch 100: Train 0.40528411411364146, Test 0.3990102708339691\n",
      "Epoch 125, lr 4.39453125e-08\n",
      "Epoch 125: Train 0.40537898392852295, Test 0.39909785985946655\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.4053912228400554, Test 0.3991090655326843\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.40539097649241806, Test 0.3991081416606903\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.40539086657926576, Test 0.39910808205604553\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.4053908972018356, Test 0.39910775423049927\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.40539072166889084, Test 0.39910730719566345\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.4053907153803274, Test 0.3991071581840515\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.4053860011450741, Test 0.39910173416137695\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.4053755492792217, Test 0.39909103512763977\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.40536549031187635, Test 0.3990810811519623\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.4053553509602853, Test 0.3990703821182251\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.40534536800253285, Test 0.3990599513053894\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.4053357741154662, Test 0.3990499973297119\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.4053262015548321, Test 0.39904022216796875\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.4053168947543573, Test 0.39903080463409424\n",
      "TRAINING MODEL dt_norm_2_39\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.6016989280195797, Test 0.5130637884140015\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.31424690892591195, Test 0.3012298345565796\n",
      "Epoch 50, lr 1.125e-05\n",
      "Epoch 50: Train 0.31581396916333365, Test 0.29755499958992004\n",
      "Epoch 75, lr 2.8125e-06\n",
      "Epoch 75: Train 0.31750958149923997, Test 0.2981345057487488\n",
      "Epoch 100, lr 7.03125e-07\n",
      "Epoch 100: Train 0.3178483366089709, Test 0.29825496673583984\n",
      "Epoch 125, lr 8.7890625e-08\n",
      "Epoch 125: Train 0.3179152441375396, Test 0.2982867956161499\n",
      "Epoch 150, lr 2.197265625e-08\n",
      "Epoch 150: Train 0.3179215615724816, Test 0.29828259348869324\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.31792306527495384, Test 0.2982827126979828\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.3179241611677058, Test 0.29828330874443054\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.3179253835011931, Test 0.29828357696533203\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.31792644564719763, Test 0.2982841432094574\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.3179275257622494, Test 0.2982849180698395\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.31792886314146657, Test 0.2982850670814514\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.3179298957042834, Test 0.29828545451164246\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.31793107662130804, Test 0.29828596115112305\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.3179322411032284, Test 0.29828667640686035\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.31793339703889456, Test 0.2982868552207947\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.31793452185742993, Test 0.29828739166259766\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.31793561402489157, Test 0.29828792810440063\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.31793685498483043, Test 0.29828840494155884\n",
      "TRAINING MODEL dt_norm_2_40\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.28972084836827383, Test 0.24068887531757355\n",
      "Epoch 25, lr 2.25e-05\n",
      "Epoch 25: Train 0.21767386065589056, Test 0.21458503603935242\n",
      "Epoch 50, lr 5.625e-06\n",
      "Epoch 50: Train 0.2277436998155382, Test 0.22417430579662323\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.23015078173743353, Test 0.22640299797058105\n",
      "Epoch 100, lr 1.7578125e-07\n",
      "Epoch 100: Train 0.23063244339492586, Test 0.22685278952121735\n",
      "Epoch 125, lr 4.39453125e-08\n",
      "Epoch 125: Train 0.2307343754503462, Test 0.22695107758045197\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.23074761546320385, Test 0.226963609457016\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.23075033277273177, Test 0.22696614265441895\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.23075307640764448, Test 0.22696858644485474\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.2307558321290546, Test 0.22697117924690247\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.230758688516087, Test 0.2269737869501114\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.23076137022839652, Test 0.22697627544403076\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.23076417611704933, Test 0.22697898745536804\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.2307669452495045, Test 0.22698146104812622\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.23076974782678816, Test 0.2269839495420456\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.23077237771617043, Test 0.22698646783828735\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.23077516853809357, Test 0.22698920965194702\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.23077799032131832, Test 0.2269917130470276\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.2307807602816158, Test 0.2269943505525589\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.23078357378641765, Test 0.2269970029592514\n",
      "TRAINING MODEL dt_norm_2_41\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.20333775024390915, Test 0.1712348312139511\n",
      "Epoch 25, lr 1.125e-05\n",
      "Epoch 25: Train 0.22028177672798194, Test 0.21657313406467438\n",
      "Epoch 50, lr 2.8125e-06\n",
      "Epoch 50: Train 0.23943790894688913, Test 0.2351105511188507\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.24339603466316334, Test 0.2389201521873474\n",
      "Epoch 100, lr 1.7578125e-07\n",
      "Epoch 100: Train 0.2442188453905791, Test 0.23971185088157654\n",
      "Epoch 125, lr 2.197265625e-08\n",
      "Epoch 125: Train 0.24438038757703837, Test 0.2398642897605896\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.24440580273716195, Test 0.23988892138004303\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.24442112142021216, Test 0.23990394175052643\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.24443644791552163, Test 0.23991885781288147\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.24445174663390928, Test 0.23993393778800964\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.24446765412983384, Test 0.23994974792003632\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.244484088663916, Test 0.23996596038341522\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.2445005872874584, Test 0.23998208343982697\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.24451712670835477, Test 0.23999829590320587\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.24453363357817084, Test 0.24001465737819672\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.24455010992230722, Test 0.24003095924854279\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.244566660916921, Test 0.24004727602005005\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.24458314015448673, Test 0.2400633990764618\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.24459960275483364, Test 0.2400796264410019\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.24461629740821506, Test 0.24009597301483154\n",
      "TRAINING MODEL dt_norm_2_42\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.3670579024723598, Test 0.31323614716529846\n",
      "Epoch 25, lr 2.25e-05\n",
      "Epoch 25: Train 0.2651815048995472, Test 0.26290372014045715\n",
      "Epoch 50, lr 1.125e-05\n",
      "Epoch 50: Train 0.2659344492214067, Test 0.26330170035362244\n",
      "Epoch 75, lr 2.8125e-06\n",
      "Epoch 75: Train 0.26699782269341604, Test 0.26441264152526855\n",
      "Epoch 100, lr 7.03125e-07\n",
      "Epoch 100: Train 0.2672847147498812, Test 0.2646748125553131\n",
      "Epoch 125, lr 1.7578125e-07\n",
      "Epoch 125: Train 0.26734446947063717, Test 0.2647334933280945\n",
      "Epoch 150, lr 2.197265625e-08\n",
      "Epoch 150: Train 0.2673536730664117, Test 0.26474255323410034\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.2673553434156236, Test 0.26474398374557495\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.2673563943022773, Test 0.2647450566291809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.2673573912609191, Test 0.264745831489563\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.2673583797046116, Test 0.2647468149662018\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.2673594430088997, Test 0.2647477388381958\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.2673604516755967, Test 0.2647484838962555\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.26736155968336833, Test 0.26474958658218384\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.2673624895867847, Test 0.26475054025650024\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.2673635958206086, Test 0.2647514045238495\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.2673645895861444, Test 0.2647522985935211\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.2673655762558892, Test 0.264753133058548\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.26736668390887125, Test 0.264754056930542\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.267367670578616, Test 0.2647549510002136\n",
      "TRAINING MODEL dt_norm_2_43\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.324858900272485, Test 0.290029913187027\n",
      "Epoch 25, lr 2.25e-05\n",
      "Epoch 25: Train 0.23353137572606406, Test 0.22786372900009155\n",
      "Epoch 50, lr 1.125e-05\n",
      "Epoch 50: Train 0.23253673315048218, Test 0.22598092257976532\n",
      "Epoch 75, lr 2.8125e-06\n",
      "Epoch 75: Train 0.23275365477258508, Test 0.2260260432958603\n",
      "Epoch 100, lr 3.515625e-07\n",
      "Epoch 100: Train 0.23281680634527496, Test 0.22602516412734985\n",
      "Epoch 125, lr 8.7890625e-08\n",
      "Epoch 125: Train 0.23282516770290607, Test 0.2260194718837738\n",
      "Epoch 150, lr 2.197265625e-08\n",
      "Epoch 150: Train 0.2328295481927467, Test 0.22602131962776184\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.23283000561324033, Test 0.22602133452892303\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.2328305063825665, Test 0.22602151334285736\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.23283103559956406, Test 0.2260216623544693\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.23283156526811194, Test 0.22602149844169617\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.2328320795839483, Test 0.22602155804634094\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.23283280341914206, Test 0.22602173686027527\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.23283316240166174, Test 0.22602181136608124\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.23283373632214285, Test 0.22602204978466034\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.23283436262246335, Test 0.2260221540927887\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.2328348010778427, Test 0.22602222859859467\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.23283529010686008, Test 0.2260221391916275\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.23283587486454935, Test 0.22602224349975586\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.23283642214356046, Test 0.22602245211601257\n",
      "TRAINING MODEL dt_norm_2_44\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.1778660010546446, Test 0.12981641292572021\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.08255710117518902, Test 0.07970055192708969\n",
      "Epoch 50, lr 2.25e-05\n",
      "Epoch 50: Train 0.08244989402592182, Test 0.07927397638559341\n",
      "Epoch 75, lr 1.125e-05\n",
      "Epoch 75: Train 0.08304179757833481, Test 0.07945054024457932\n",
      "Epoch 100, lr 5.625e-06\n",
      "Epoch 100: Train 0.08266727812588215, Test 0.07866412401199341\n",
      "Epoch 125, lr 2.8125e-06\n",
      "Epoch 125: Train 0.08264455758035183, Test 0.07857111841440201\n",
      "Epoch 150, lr 7.03125e-07\n",
      "Epoch 150: Train 0.08259323611855507, Test 0.07849209755659103\n",
      "Epoch 175, lr 1.7578125e-07\n",
      "Epoch 175: Train 0.08257594965398311, Test 0.07847114652395248\n",
      "Epoch 200, lr 4.39453125e-08\n",
      "Epoch 200: Train 0.08257396891713142, Test 0.07846741378307343\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.08257318772375584, Test 0.07846630364656448\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.08257337249815463, Test 0.07846637070178986\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.08257356621325015, Test 0.07846647500991821\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.08257368057966233, Test 0.07846634089946747\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.08257398009300232, Test 0.07846634089946747\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.08257410451769828, Test 0.07846631109714508\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.08257421068847179, Test 0.0784662663936615\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.08257439695298671, Test 0.07846642285585403\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.08257456570863723, Test 0.07846634089946747\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.08257485739886761, Test 0.07846654206514359\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.08257497623562812, Test 0.07846652716398239\n",
      "TRAINING MODEL dt_norm_2_45\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.23692623187195172, Test 0.20342949032783508\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.1795564777020252, Test 0.1725333034992218\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 0.17721367875734964, Test 0.1686839610338211\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 0.17905508523637598, Test 0.1689315140247345\n",
      "Epoch 100, lr 5.625e-06\n",
      "Epoch 100: Train 0.17913197884053894, Test 0.1688244640827179\n",
      "Epoch 125, lr 7.03125e-07\n",
      "Epoch 125: Train 0.17914883069919818, Test 0.1687319427728653\n",
      "Epoch 150, lr 1.7578125e-07\n",
      "Epoch 150: Train 0.1791729498090166, Test 0.16874319314956665\n",
      "Epoch 175, lr 4.39453125e-08\n",
      "Epoch 175: Train 0.17917619103735144, Test 0.16874051094055176\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.17917590430288605, Test 0.16873963177204132\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.1791758081226638, Test 0.16873925924301147\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.17917576883778427, Test 0.16873906552791595\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.1791757322622068, Test 0.168738454580307\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.17917568439787085, Test 0.16873806715011597\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.17917559499090369, Test 0.16873779892921448\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.17917552454905075, Test 0.16873744130134583\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.1791755078416882, Test 0.16873739659786224\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.17917547216921142, Test 0.16873690485954285\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.17917545681649988, Test 0.1687367558479309\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.17917539540565375, Test 0.1687363237142563\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.17917531232039133, Test 0.16873599588871002\n",
      "TRAINING MODEL dt_norm_3_1\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 13.267944292833576, Test 12.582460403442383\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 11.733455340067545, Test 11.703262329101562\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 11.536026259600106, Test 11.470976829528809\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 11.373563545571882, Test 11.33910083770752\n",
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 11.357871793757724, Test 11.321378707885742\n",
      "Epoch 125, lr 5.625e-06\n",
      "Epoch 125: Train 11.348898790650448, Test 11.311653137207031\n",
      "Epoch 150, lr 2.8125e-06\n",
      "Epoch 150: Train 11.344659649046127, Test 11.305418968200684\n",
      "Epoch 175, lr 1.40625e-06\n",
      "Epoch 175: Train 11.343666830978824, Test 11.304553985595703\n",
      "Epoch 200, lr 1.7578125e-07\n",
      "Epoch 200: Train 11.34281448859953, Test 11.303518295288086\n",
      "Epoch 225, lr 4.39453125e-08\n",
      "Epoch 225: Train 11.342729094338281, Test 11.30342960357666\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 11.342704816053143, Test 11.303400993347168\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 11.342703727679064, Test 11.303400993347168\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 11.342703005688339, Test 11.303400993347168\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 11.342702256757661, Test 11.303400039672852\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 11.342701610198802, Test 11.303401947021484\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 11.342700613420561, Test 11.303400993347168\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 11.342700069233523, Test 11.303400993347168\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 11.342699239482988, Test 11.303400993347168\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 11.342698312748624, Test 11.303401947021484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 11.342697542265984, Test 11.303400039672852\n",
      "TRAINING MODEL dt_norm_3_3\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 16.307332354784013, Test 15.902122497558594\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 12.925718203186989, Test 12.73122501373291\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 12.595598232746124, Test 12.402135848999023\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 12.431997925043106, Test 12.244697570800781\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 12.344263689219952, Test 12.15537166595459\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 12.224025151133537, Test 12.031597137451172\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 12.178842359781266, Test 12.02134895324707\n",
      "Epoch 175, lr 4.5e-05\n",
      "Epoch 175: Train 12.132384023070335, Test 11.948750495910645\n",
      "Epoch 200, lr 4.5e-05\n",
      "Epoch 200: Train 12.10829039812088, Test 11.921371459960938\n",
      "Epoch 225, lr 4.5e-05\n",
      "Epoch 225: Train 12.08933297842741, Test 11.947856903076172\n",
      "Epoch 250, lr 4.5e-05\n",
      "Epoch 250: Train 12.061192356050014, Test 11.901568412780762\n",
      "Epoch 275, lr 4.5e-05\n",
      "Epoch 275: Train 12.035840091109275, Test 11.872906684875488\n",
      "Epoch 300, lr 4.5e-05\n",
      "Epoch 300: Train 12.025172446668147, Test 11.85020637512207\n",
      "Epoch 325, lr 4.5e-05\n",
      "Epoch 325: Train 11.988257181644439, Test 11.83726692199707\n",
      "Epoch 350, lr 2.25e-05\n",
      "Epoch 350: Train 11.947382886707782, Test 11.773106575012207\n",
      "Epoch 375, lr 2.25e-05\n",
      "Epoch 375: Train 11.93809844404459, Test 11.765460968017578\n",
      "Epoch 400, lr 2.25e-05\n",
      "Epoch 400: Train 11.930710890889168, Test 11.756110191345215\n",
      "Epoch 425, lr 2.25e-05\n",
      "Epoch 425: Train 11.918754231929778, Test 11.746033668518066\n",
      "Epoch 450, lr 2.25e-05\n",
      "Epoch 450: Train 11.910257326066494, Test 11.735280990600586\n",
      "Epoch 475, lr 2.25e-05\n",
      "Epoch 475: Train 11.904106679558755, Test 11.73271369934082\n",
      "TRAINING MODEL dt_norm_3_5\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 20.531477418541908, Test 20.158063888549805\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 19.061876833438873, Test 18.81016731262207\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 18.76174623966217, Test 18.538330078125\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 18.556569328904153, Test 18.361583709716797\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 18.405651471018793, Test 18.248838424682617\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 18.392271333932875, Test 18.293594360351562\n",
      "Epoch 150, lr 2.25e-05\n",
      "Epoch 150: Train 18.18344484269619, Test 18.076766967773438\n",
      "Epoch 175, lr 2.25e-05\n",
      "Epoch 175: Train 18.148781615495682, Test 18.038930892944336\n",
      "Epoch 200, lr 2.25e-05\n",
      "Epoch 200: Train 18.130767166614532, Test 18.014068603515625\n",
      "Epoch 225, lr 2.25e-05\n",
      "Epoch 225: Train 18.099946370720865, Test 17.994239807128906\n",
      "Epoch 250, lr 2.25e-05\n",
      "Epoch 250: Train 18.08581794798374, Test 17.97431182861328\n",
      "Epoch 275, lr 2.25e-05\n",
      "Epoch 275: Train 18.066987046599387, Test 17.95462417602539\n",
      "Epoch 300, lr 2.25e-05\n",
      "Epoch 300: Train 18.040549755096436, Test 17.940326690673828\n",
      "Epoch 325, lr 2.25e-05\n",
      "Epoch 325: Train 18.031724962592126, Test 17.924108505249023\n",
      "Epoch 350, lr 1.125e-05\n",
      "Epoch 350: Train 17.984249657392503, Test 17.888710021972656\n",
      "Epoch 375, lr 1.125e-05\n",
      "Epoch 375: Train 17.974759578704834, Test 17.879987716674805\n",
      "Epoch 400, lr 5.625e-06\n",
      "Epoch 400: Train 17.956477093696595, Test 17.866331100463867\n",
      "Epoch 425, lr 1.40625e-06\n",
      "Epoch 425: Train 17.94673784971237, Test 17.858369827270508\n",
      "Epoch 450, lr 3.515625e-07\n",
      "Epoch 450: Train 17.944319155812263, Test 17.85634994506836\n",
      "Epoch 475, lr 8.7890625e-08\n",
      "Epoch 475: Train 17.943719501793385, Test 17.855802536010742\n",
      "TRAINING MODEL dt_norm_3_7\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 15.483354434370995, Test 14.895665168762207\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 13.893769890069962, Test 13.618606567382812\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 13.67788274139166, Test 13.514571189880371\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 13.575178344547748, Test 13.621236801147461\n",
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 13.281500568985939, Test 13.078049659729004\n",
      "Epoch 125, lr 1.125e-05\n",
      "Epoch 125: Train 13.211065055429936, Test 12.965248107910156\n",
      "Epoch 150, lr 1.125e-05\n",
      "Epoch 150: Train 13.185572773218155, Test 12.937232971191406\n",
      "Epoch 175, lr 1.125e-05\n",
      "Epoch 175: Train 13.14503961801529, Test 12.903482437133789\n",
      "Epoch 200, lr 1.125e-05\n",
      "Epoch 200: Train 13.12613640576601, Test 12.881006240844727\n",
      "Epoch 225, lr 1.125e-05\n",
      "Epoch 225: Train 13.111730533838273, Test 12.86590576171875\n",
      "Epoch 250, lr 1.125e-05\n",
      "Epoch 250: Train 13.098446460068226, Test 12.855278015136719\n",
      "Epoch 275, lr 1.125e-05\n",
      "Epoch 275: Train 13.084563630819321, Test 12.838817596435547\n",
      "Epoch 300, lr 1.125e-05\n",
      "Epoch 300: Train 13.076154890656472, Test 12.835773468017578\n",
      "Epoch 325, lr 1.125e-05\n",
      "Epoch 325: Train 13.06545066088438, Test 12.820698738098145\n",
      "Epoch 350, lr 1.125e-05\n",
      "Epoch 350: Train 13.05675560683012, Test 12.816665649414062\n",
      "Epoch 375, lr 1.125e-05\n",
      "Epoch 375: Train 12.976731872558593, Test 12.734929084777832\n",
      "Epoch 400, lr 1.125e-05\n",
      "Epoch 400: Train 12.949053892493248, Test 12.705683708190918\n",
      "Epoch 425, lr 5.625e-06\n",
      "Epoch 425: Train 12.92638111114502, Test 12.675249099731445\n",
      "Epoch 450, lr 5.625e-06\n",
      "Epoch 450: Train 12.921316844224929, Test 12.670219421386719\n",
      "Epoch 475, lr 5.625e-06\n",
      "Epoch 475: Train 12.916231162846088, Test 12.665214538574219\n",
      "TRAINING MODEL dt_norm_3_9\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 13.971562308073043, Test 13.33301830291748\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 12.54388759881258, Test 12.088582038879395\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 12.116318051517009, Test 11.690178871154785\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 12.006430442631245, Test 11.568012237548828\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 11.781191159784793, Test 11.380427360534668\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 11.681091445684434, Test 11.246011734008789\n",
      "Epoch 150, lr 4.5e-05\n",
      "Epoch 150: Train 11.670693618059158, Test 11.253649711608887\n",
      "Epoch 175, lr 2.25e-05\n",
      "Epoch 175: Train 11.518966215848923, Test 11.158960342407227\n",
      "Epoch 200, lr 1.125e-05\n",
      "Epoch 200: Train 11.450799083709716, Test 11.112180709838867\n",
      "Epoch 225, lr 1.125e-05\n",
      "Epoch 225: Train 11.446000292897224, Test 11.102909088134766\n",
      "Epoch 250, lr 1.125e-05\n",
      "Epoch 250: Train 11.439268843829632, Test 11.096562385559082\n",
      "Epoch 275, lr 5.625e-06\n",
      "Epoch 275: Train 11.4258622944355, Test 11.085603713989258\n",
      "Epoch 300, lr 1.40625e-06\n",
      "Epoch 300: Train 11.417836736142636, Test 11.079169273376465\n",
      "Epoch 325, lr 3.515625e-07\n",
      "Epoch 325: Train 11.415895941853524, Test 11.07720947265625\n",
      "Epoch 350, lr 8.7890625e-08\n",
      "Epoch 350: Train 11.415424075722694, Test 11.076763153076172\n",
      "Epoch 375, lr 2.197265625e-08\n",
      "Epoch 375: Train 11.415294028818607, Test 11.076647758483887\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 11.41526906490326, Test 11.07662582397461\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 11.415261177718639, Test 11.076619148254395\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 11.415253140032291, Test 11.076610565185547\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 11.415244747698306, Test 11.076605796813965\n",
      "TRAINING MODEL dt_norm_3_11\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 10.292991243302822, Test 9.739266395568848\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 8.686787939071655, Test 8.3748197555542\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 8.47542805224657, Test 8.194271087646484\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 8.37879025861621, Test 8.068824768066406\n",
      "Epoch 100, lr 2.25e-05\n",
      "Epoch 100: Train 8.238950651139021, Test 7.989418983459473\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 8.213287016749382, Test 7.966401100158691\n",
      "Epoch 150, lr 2.25e-05\n",
      "Epoch 150: Train 8.189475718140603, Test 7.948666572570801\n",
      "Epoch 175, lr 2.25e-05\n",
      "Epoch 175: Train 8.155844385921956, Test 7.911281585693359\n",
      "Epoch 200, lr 2.25e-05\n",
      "Epoch 200: Train 8.139573672413826, Test 7.89921760559082\n",
      "Epoch 225, lr 2.25e-05\n",
      "Epoch 225: Train 8.132147756963969, Test 7.8860297203063965\n",
      "Epoch 250, lr 1.125e-05\n",
      "Epoch 250: Train 8.103565583378076, Test 7.872807502746582\n",
      "Epoch 275, lr 5.625e-06\n",
      "Epoch 275: Train 8.09254964441061, Test 7.862287521362305\n",
      "Epoch 300, lr 1.40625e-06\n",
      "Epoch 300: Train 8.086338052898645, Test 7.856931686401367\n",
      "Epoch 325, lr 3.515625e-07\n",
      "Epoch 325: Train 8.08485085144639, Test 7.855709075927734\n",
      "Epoch 350, lr 8.7890625e-08\n",
      "Epoch 350: Train 8.084473711997271, Test 7.855353355407715\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 8.084385148435832, Test 7.855268478393555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 8.084367190301418, Test 7.855254650115967\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 8.084360271692276, Test 7.855247974395752\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 8.084354282170533, Test 7.855243682861328\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 8.084347929805517, Test 7.855238914489746\n",
      "TRAINING MODEL dt_norm_3_13\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 9.150458681583405, Test 8.682182312011719\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 7.5245166450738905, Test 7.398359298706055\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 7.457824593782425, Test 7.344204902648926\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 7.42789709046483, Test 7.395072937011719\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 7.415888821333647, Test 7.294632911682129\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 7.387514527142048, Test 7.266217231750488\n",
      "Epoch 150, lr 2.25e-05\n",
      "Epoch 150: Train 7.36281366199255, Test 7.238628387451172\n",
      "Epoch 175, lr 2.25e-05\n",
      "Epoch 175: Train 7.358050512522459, Test 7.235260486602783\n",
      "Epoch 200, lr 1.125e-05\n",
      "Epoch 200: Train 7.3439103126525875, Test 7.223720550537109\n",
      "Epoch 225, lr 1.125e-05\n",
      "Epoch 225: Train 7.342086447030306, Test 7.221825122833252\n",
      "Epoch 250, lr 5.625e-06\n",
      "Epoch 250: Train 7.335230319947004, Test 7.217246055603027\n",
      "Epoch 275, lr 1.40625e-06\n",
      "Epoch 275: Train 7.331189077347517, Test 7.213937759399414\n",
      "Epoch 300, lr 3.515625e-07\n",
      "Epoch 300: Train 7.330175890773535, Test 7.2130537033081055\n",
      "Epoch 325, lr 4.39453125e-08\n",
      "Epoch 325: Train 7.329889309406281, Test 7.212807655334473\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 7.329850294440985, Test 7.212775707244873\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 7.329846509546042, Test 7.212772846221924\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 7.3298431664705275, Test 7.212770938873291\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 7.329839638620615, Test 7.212767601013184\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 7.329836788028478, Test 7.212766647338867\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 7.329833190888166, Test 7.212762832641602\n",
      "TRAINING MODEL dt_norm_3_15\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 5.694054679572583, Test 5.304841041564941\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 4.556993299722672, Test 4.426602363586426\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 4.497130215167999, Test 4.371063232421875\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 4.4771256349980835, Test 4.350372791290283\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 4.46081215813756, Test 4.334384918212891\n",
      "Epoch 125, lr 4.5e-05\n",
      "Epoch 125: Train 4.4419862404465675, Test 4.32172966003418\n",
      "Epoch 150, lr 2.25e-05\n",
      "Epoch 150: Train 4.4197529293596745, Test 4.297805309295654\n",
      "Epoch 175, lr 1.125e-05\n",
      "Epoch 175: Train 4.410084135830402, Test 4.289090156555176\n",
      "Epoch 200, lr 2.8125e-06\n",
      "Epoch 200: Train 4.403781817853451, Test 4.283965110778809\n",
      "Epoch 225, lr 7.03125e-07\n",
      "Epoch 225: Train 4.402194567024708, Test 4.2825188636779785\n",
      "Epoch 250, lr 1.7578125e-07\n",
      "Epoch 250: Train 4.401793053001166, Test 4.282161712646484\n",
      "Epoch 275, lr 4.39453125e-08\n",
      "Epoch 275: Train 4.40169515684247, Test 4.2820892333984375\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 4.401668104529381, Test 4.282064914703369\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 4.401665554195643, Test 4.282063007354736\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 4.401662120968103, Test 4.282060146331787\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 4.401659008860588, Test 4.2820587158203125\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 4.4016557015478615, Test 4.28205680847168\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 4.401652682572603, Test 4.282055377960205\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 4.401649855822325, Test 4.282052993774414\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 4.401646827161312, Test 4.282052040100098\n",
      "TRAINING MODEL dt_norm_3_17\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 4.947771643102169, Test 4.605482578277588\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 3.787357372790575, Test 3.731879234313965\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 3.7360840126872064, Test 3.672365188598633\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 3.7165813982486724, Test 3.6566710472106934\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 3.7101643279194834, Test 3.6502585411071777\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 3.6906698018312456, Test 3.6291871070861816\n",
      "Epoch 150, lr 1.125e-05\n",
      "Epoch 150: Train 3.683287415653467, Test 3.6230416297912598\n",
      "Epoch 175, lr 5.625e-06\n",
      "Epoch 175: Train 3.6797394417226315, Test 3.6193885803222656\n",
      "Epoch 200, lr 7.03125e-07\n",
      "Epoch 200: Train 3.677232560515404, Test 3.6169447898864746\n",
      "Epoch 225, lr 1.7578125e-07\n",
      "Epoch 225: Train 3.676505470275879, Test 3.6162102222442627\n",
      "Epoch 250, lr 8.7890625e-08\n",
      "Epoch 250: Train 3.6764433085918427, Test 3.616161346435547\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 3.676403398811817, Test 3.6161136627197266\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 3.6763948269188402, Test 3.616107702255249\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 3.676392734795809, Test 3.6161060333251953\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 3.6763905622065067, Test 3.6161048412323\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 3.676388227194548, Test 3.6161036491394043\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 3.6763861164450646, Test 3.6161022186279297\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 3.6763840280473232, Test 3.6161017417907715\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 3.676381739228964, Test 3.616100311279297\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 3.6763797238469125, Test 3.6160988807678223\n",
      "TRAINING MODEL dt_norm_3_19\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 4.448880594223738, Test 4.063498497009277\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 3.42500839009881, Test 3.344294548034668\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 3.3955282092094423, Test 3.312695026397705\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 3.3728051610291003, Test 3.2855782508850098\n",
      "Epoch 100, lr 2.25e-05\n",
      "Epoch 100: Train 3.355505429953337, Test 3.267625331878662\n",
      "Epoch 125, lr 1.125e-05\n",
      "Epoch 125: Train 3.3476858746260403, Test 3.2593870162963867\n",
      "Epoch 150, lr 5.625e-06\n",
      "Epoch 150: Train 3.343990558385849, Test 3.255542278289795\n",
      "Epoch 175, lr 1.40625e-06\n",
      "Epoch 175: Train 3.3413475073873995, Test 3.252727508544922\n",
      "Epoch 200, lr 3.515625e-07\n",
      "Epoch 200: Train 3.340496801584959, Test 3.251880168914795\n",
      "Epoch 225, lr 1.7578125e-07\n",
      "Epoch 225: Train 3.3403112068772316, Test 3.251675605773926\n",
      "Epoch 250, lr 4.39453125e-08\n",
      "Epoch 250: Train 3.3402177721261976, Test 3.251579761505127\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 3.34019292332232, Test 3.2515549659729004\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 3.34018732085824, Test 3.2515501976013184\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 3.340182041376829, Test 3.2515463829040527\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 3.3401765577495097, Test 3.2515413761138916\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 3.340170945972204, Test 3.251537322998047\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 3.340165230631828, Test 3.251533031463623\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 3.340159986168146, Test 3.251528739929199\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 3.340154531598091, Test 3.251525402069092\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 3.340149079635739, Test 3.2515201568603516\n",
      "TRAINING MODEL dt_norm_3_21\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 5.448913249373436, Test 5.070803165435791\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 4.474857528880238, Test 4.450643539428711\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 4.458205603808165, Test 4.43160343170166\n",
      "Epoch 75, lr 4.5e-05\n",
      "Epoch 75: Train 4.447249683737755, Test 4.419620990753174\n",
      "Epoch 100, lr 4.5e-05\n",
      "Epoch 100: Train 4.437052360549569, Test 4.408699989318848\n",
      "Epoch 125, lr 2.25e-05\n",
      "Epoch 125: Train 4.4263050392270085, Test 4.397768497467041\n",
      "Epoch 150, lr 2.25e-05\n",
      "Epoch 150: Train 4.413708675652742, Test 4.386321067810059\n",
      "Epoch 175, lr 1.125e-05\n",
      "Epoch 175: Train 4.408077280968428, Test 4.379957675933838\n",
      "Epoch 200, lr 2.8125e-06\n",
      "Epoch 200: Train 4.403477325662971, Test 4.375444412231445\n",
      "Epoch 225, lr 7.03125e-07\n",
      "Epoch 225: Train 4.4024249270558355, Test 4.3744001388549805\n",
      "Epoch 250, lr 1.7578125e-07\n",
      "Epoch 250: Train 4.402172787860036, Test 4.374139785766602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275, lr 2.197265625e-08\n",
      "Epoch 275: Train 4.402105833217502, Test 4.374085426330566\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 4.402089377865195, Test 4.3740668296813965\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 4.4020884949713945, Test 4.37406587600708\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 4.402087189257145, Test 4.374064922332764\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 4.40208630412817, Test 4.374063491821289\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 4.402085084468126, Test 4.374063014984131\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 4.402084409818054, Test 4.374063014984131\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 4.40208326280117, Test 4.374061584472656\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 4.402082068473101, Test 4.374061107635498\n",
      "TRAINING MODEL dt_norm_3_23\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 3.801257172971964, Test 3.483030319213867\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 3.036909031495452, Test 3.020883083343506\n",
      "Epoch 50, lr 4.5e-05\n",
      "Epoch 50: Train 3.023850193619728, Test 3.004711151123047\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 3.0079658679664134, Test 2.986374855041504\n",
      "Epoch 100, lr 1.125e-05\n",
      "Epoch 100: Train 2.992870081216097, Test 2.9734320640563965\n",
      "Epoch 125, lr 2.8125e-06\n",
      "Epoch 125: Train 2.989359415322542, Test 2.970508575439453\n",
      "Epoch 150, lr 7.03125e-07\n",
      "Epoch 150: Train 2.988374861329794, Test 2.969607353210449\n",
      "Epoch 175, lr 1.7578125e-07\n",
      "Epoch 175: Train 2.9881491262465714, Test 2.9693992137908936\n",
      "Epoch 200, lr 4.39453125e-08\n",
      "Epoch 200: Train 2.9880956918001176, Test 2.969341278076172\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 2.9880809031426905, Test 2.9693245887756348\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 2.988079573586583, Test 2.9693245887756348\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 2.988078287243843, Test 2.9693236351013184\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 2.988077125698328, Test 2.969322681427002\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 2.988076080754399, Test 2.969322443008423\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 2.988074804097414, Test 2.9693210124969482\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 2.9880736380815507, Test 2.9693212509155273\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 2.9880725648254156, Test 2.969320058822632\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 2.988071446865797, Test 2.9693193435668945\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 2.988070171698928, Test 2.9693188667297363\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 2.9880689300596712, Test 2.96931791305542\n",
      "TRAINING MODEL dt_norm_3_25\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 3.3262064844369887, Test 3.0338315963745117\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 2.5355182457715273, Test 2.5070455074310303\n",
      "Epoch 50, lr 2.25e-05\n",
      "Epoch 50: Train 2.5115091685205697, Test 2.4830026626586914\n",
      "Epoch 75, lr 2.25e-05\n",
      "Epoch 75: Train 2.4896319467574357, Test 2.4590349197387695\n",
      "Epoch 100, lr 5.625e-06\n",
      "Epoch 100: Train 2.4807873599231245, Test 2.450026512145996\n",
      "Epoch 125, lr 2.8125e-06\n",
      "Epoch 125: Train 2.4764838900417088, Test 2.446244239807129\n",
      "Epoch 150, lr 3.515625e-07\n",
      "Epoch 150: Train 2.4756091982126236, Test 2.4453139305114746\n",
      "Epoch 175, lr 8.7890625e-08\n",
      "Epoch 175: Train 2.4753546353429554, Test 2.4450674057006836\n",
      "Epoch 200, lr 2.197265625e-08\n",
      "Epoch 200: Train 2.475324123725295, Test 2.4450340270996094\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 2.4753173403441906, Test 2.44502854347229\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 2.475315199419856, Test 2.445026397705078\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 2.4753129594027996, Test 2.4450244903564453\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 2.4753107290714977, Test 2.4450225830078125\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 2.4753083903342485, Test 2.4450206756591797\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 2.475306338816881, Test 2.445018768310547\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 2.4753040600568057, Test 2.4450178146362305\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 2.475301919505, Test 2.445014715194702\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 2.4752996545284986, Test 2.4450130462646484\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 2.4752974808216095, Test 2.4450111389160156\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 2.4752952504903076, Test 2.445009469985962\n",
      "TRAINING MODEL dt_norm_3_39\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.7253137493604108, Test 0.6482310891151428\n",
      "Epoch 25, lr 4.5e-05\n",
      "Epoch 25: Train 0.49496878618211076, Test 0.47872108221054077\n",
      "Epoch 50, lr 2.25e-05\n",
      "Epoch 50: Train 0.4973466191114041, Test 0.483465313911438\n",
      "Epoch 75, lr 5.625e-06\n",
      "Epoch 75: Train 0.49638333328460393, Test 0.4832649528980255\n",
      "Epoch 100, lr 2.8125e-06\n",
      "Epoch 100: Train 0.4858033969475512, Test 0.4723619222640991\n",
      "Epoch 125, lr 1.40625e-06\n",
      "Epoch 125: Train 0.4829036820875971, Test 0.4697822630405426\n",
      "Epoch 150, lr 3.515625e-07\n",
      "Epoch 150: Train 0.4829461940547876, Test 0.46983763575553894\n",
      "Epoch 175, lr 8.7890625e-08\n",
      "Epoch 175: Train 0.48294734863335625, Test 0.4698362946510315\n",
      "Epoch 200, lr 2.197265625e-08\n",
      "Epoch 200: Train 0.4829440180931175, Test 0.46983394026756287\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.48294138738460707, Test 0.4698317348957062\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.48293973923775185, Test 0.46982988715171814\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.4829379751494056, Test 0.46982842683792114\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.4829362694892967, Test 0.46982645988464355\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.4829345704954967, Test 0.4698249101638794\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.4829328726781042, Test 0.4698232114315033\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.48293122230914604, Test 0.4698215126991272\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.48292958945558784, Test 0.4698198139667511\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.48292779582634304, Test 0.46981799602508545\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.48292620440846995, Test 0.46981632709503174\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.4829245003169043, Test 0.46981489658355713\n",
      "TRAINING MODEL dt_norm_3_40\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.35029305161470436, Test 0.3121112883090973\n",
      "Epoch 25, lr 1.125e-05\n",
      "Epoch 25: Train 0.38988033958165297, Test 0.3833092451095581\n",
      "Epoch 50, lr 2.8125e-06\n",
      "Epoch 50: Train 0.40441404930148944, Test 0.3967864513397217\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.4073216812425401, Test 0.3995314836502075\n",
      "Epoch 100, lr 8.7890625e-08\n",
      "Epoch 100: Train 0.4079156595159812, Test 0.40009447932243347\n",
      "Epoch 125, lr 2.197265625e-08\n",
      "Epoch 125: Train 0.40801075813304855, Test 0.40018436312675476\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.40800482557114376, Test 0.4001775085926056\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.4079942503773359, Test 0.40016674995422363\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.40798377450481355, Test 0.40015602111816406\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.40797320542582477, Test 0.40014520287513733\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.40796272005455425, Test 0.4001343250274658\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.4079522254220043, Test 0.40012386441230774\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.4079416052872441, Test 0.40011274814605713\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.40793110103721164, Test 0.4001019597053528\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.407920730600794, Test 0.400091290473938\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.40791023887723565, Test 0.4000804126262665\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.40789982783366957, Test 0.4000696837902069\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.4078893442434144, Test 0.40005913376808167\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.40787895795596074, Test 0.40004855394363403\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.4078686793011973, Test 0.4000377357006073\n",
      "TRAINING MODEL dt_norm_3_41\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.2429354060089813, Test 0.2112177163362503\n",
      "Epoch 25, lr 1.125e-05\n",
      "Epoch 25: Train 0.29171372205018997, Test 0.28854113817214966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, lr 2.8125e-06\n",
      "Epoch 50: Train 0.3056881624572682, Test 0.30246633291244507\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.3094779235433857, Test 0.306052029132843\n",
      "Epoch 100, lr 8.7890625e-08\n",
      "Epoch 100: Train 0.3102493551823328, Test 0.3067915737628937\n",
      "Epoch 125, lr 2.197265625e-08\n",
      "Epoch 125: Train 0.31038223445977803, Test 0.3069167733192444\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.3103948598903305, Test 0.3069286048412323\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.31039974037206397, Test 0.3069334328174591\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.3104045258940391, Test 0.30693817138671875\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.3104094369512684, Test 0.3069429397583008\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.31041436030898456, Test 0.3069479465484619\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.3104192469761057, Test 0.306952565908432\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.3104241046140779, Test 0.3069572448730469\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.3104289691403227, Test 0.3069619834423065\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.31043388743726713, Test 0.3069666028022766\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.3104388301243197, Test 0.3069716989994049\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.31044375931598106, Test 0.30697664618492126\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.31044866875657495, Test 0.3069812059402466\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.31045359127082917, Test 0.306986004114151\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.31045848363131845, Test 0.30699074268341064\n",
      "TRAINING MODEL dt_norm_3_42\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.20876108858320447, Test 0.1859070062637329\n",
      "Epoch 25, lr 1.125e-05\n",
      "Epoch 25: Train 0.3630032594998678, Test 0.35780811309814453\n",
      "Epoch 50, lr 2.8125e-06\n",
      "Epoch 50: Train 0.3906428337097168, Test 0.3844578266143799\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.39591299480862086, Test 0.38953152298927307\n",
      "Epoch 100, lr 8.7890625e-08\n",
      "Epoch 100: Train 0.3968197888798184, Test 0.3903878927230835\n",
      "Epoch 125, lr 2.197265625e-08\n",
      "Epoch 125: Train 0.396991026269065, Test 0.3905532658100128\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.3970039694839054, Test 0.39056506752967834\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.39700617763731216, Test 0.39056724309921265\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.397008351220025, Test 0.39056941866874695\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.3970106961992052, Test 0.39057159423828125\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.39701307985517714, Test 0.39057403802871704\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.39701551424132453, Test 0.3905763030052185\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.39701794412400987, Test 0.39057865738868713\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.39702046910921734, Test 0.39058107137680054\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.39702292707231307, Test 0.3905835449695587\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.39702543179194133, Test 0.39058583974838257\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.3970280485683017, Test 0.3905884027481079\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.3970309689309862, Test 0.3905912935733795\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.39703409685028923, Test 0.39059436321258545\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.39703717364205254, Test 0.39059725403785706\n",
      "TRAINING MODEL dt_norm_3_43\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.2221737419848615, Test 0.19399939477443695\n",
      "Epoch 25, lr 1.125e-05\n",
      "Epoch 25: Train 0.3127566230111789, Test 0.3041800260543823\n",
      "Epoch 50, lr 2.8125e-06\n",
      "Epoch 50: Train 0.3326833791683375, Test 0.32349181175231934\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.336781893060615, Test 0.32746589183807373\n",
      "Epoch 100, lr 8.7890625e-08\n",
      "Epoch 100: Train 0.3375839364034524, Test 0.3282439708709717\n",
      "Epoch 125, lr 2.197265625e-08\n",
      "Epoch 125: Train 0.3377202228869799, Test 0.3283740282058716\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.3377285510147174, Test 0.3283843398094177\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.33772893952582167, Test 0.32838666439056396\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.33772921716611004, Test 0.3283891975879669\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.33772963563395286, Test 0.32839152216911316\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.3377300371160161, Test 0.3283941149711609\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.33773047056222827, Test 0.32839658856391907\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.33773096114242634, Test 0.32839930057525635\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.33773140864051066, Test 0.3284018039703369\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.3377318521237744, Test 0.3284042477607727\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.33773236324132416, Test 0.3284068703651428\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.3377328701896371, Test 0.3284095525741577\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.33773333266609074, Test 0.3284120559692383\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.33773388238768504, Test 0.3284146785736084\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.33773439798330396, Test 0.32841724157333374\n",
      "TRAINING MODEL dt_norm_3_44\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.21511171187977401, Test 0.19129814207553864\n",
      "Epoch 25, lr 1.125e-05\n",
      "Epoch 25: Train 0.3561018836133334, Test 0.35594767332077026\n",
      "Epoch 50, lr 2.8125e-06\n",
      "Epoch 50: Train 0.3832838430392499, Test 0.3824012577533722\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.3889727136310266, Test 0.3879380524158478\n",
      "Epoch 100, lr 8.7890625e-08\n",
      "Epoch 100: Train 0.3900747361535929, Test 0.3890102505683899\n",
      "Epoch 125, lr 2.197265625e-08\n",
      "Epoch 125: Train 0.3902733290986139, Test 0.38919681310653687\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.39029023112082967, Test 0.3892131447792053\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.39029588002939614, Test 0.3892187476158142\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.39030163446251226, Test 0.3892245888710022\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.39030763734968343, Test 0.3892305791378021\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.3903134991319812, Test 0.3892366290092468\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.39031947586609395, Test 0.38924258947372437\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.39032543952367743, Test 0.38924863934516907\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.39033136258319934, Test 0.38925445079803467\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.39033738827827025, Test 0.38926053047180176\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.39034340302554926, Test 0.3892664313316345\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.39034932213170187, Test 0.3892725110054016\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.3903553137669758, Test 0.3892785310745239\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.39036144072912177, Test 0.389284610748291\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.39036758532937693, Test 0.3892906606197357\n",
      "TRAINING MODEL dt_norm_3_45\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.235026591858327, Test 0.2016104757785797\n",
      "Epoch 25, lr 1.125e-05\n",
      "Epoch 25: Train 0.23948877941298957, Test 0.23265910148620605\n",
      "Epoch 50, lr 2.8125e-06\n",
      "Epoch 50: Train 0.25432750069542437, Test 0.24667143821716309\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.25689858632371915, Test 0.24913527071475983\n",
      "Epoch 100, lr 8.7890625e-08\n",
      "Epoch 100: Train 0.25742531355643117, Test 0.24963556230068207\n",
      "Epoch 125, lr 2.197265625e-08\n",
      "Epoch 125: Train 0.2575207428624298, Test 0.24972620606422424\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.2575304423341688, Test 0.24973508715629578\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.25753437703018944, Test 0.24973879754543304\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.25753820041157555, Test 0.24974223971366882\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.25754203750992455, Test 0.2497459501028061\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.257545967863885, Test 0.24974948167800903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.2575498581524716, Test 0.24975314736366272\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.25755371202696237, Test 0.24975675344467163\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.2575576349796838, Test 0.2497604638338089\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.25756155842582124, Test 0.24976396560668945\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.2575653949320711, Test 0.24976760149002075\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.25756924357635297, Test 0.24977107346057892\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.2575731624830638, Test 0.24977481365203857\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.25757713290239803, Test 0.24977853894233704\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.2575810360197989, Test 0.24978211522102356\n",
      "TRAINING MODEL dt_norm_3_46\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.23015981838569877, Test 0.1966964602470398\n",
      "Epoch 25, lr 1.125e-05\n",
      "Epoch 25: Train 0.30118109137745375, Test 0.2981046140193939\n",
      "Epoch 50, lr 2.8125e-06\n",
      "Epoch 50: Train 0.3276742685655629, Test 0.3239360749721527\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.33325643541279787, Test 0.3293209373950958\n",
      "Epoch 100, lr 8.7890625e-08\n",
      "Epoch 100: Train 0.3344064541855214, Test 0.330422043800354\n",
      "Epoch 125, lr 2.197265625e-08\n",
      "Epoch 125: Train 0.33461949451369527, Test 0.3306235671043396\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.33464905675153556, Test 0.33065205812454224\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.334665251259478, Test 0.33066800236701965\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.3346816573453986, Test 0.3306843340396881\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.33469810952310974, Test 0.330700546503067\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.3347143279099316, Test 0.33071643114089966\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.33473060238435404, Test 0.3307324945926666\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.3347468772289916, Test 0.33074861764907837\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.3347633455110633, Test 0.33076488971710205\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.3347797323457943, Test 0.3307809829711914\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.33479614454026546, Test 0.33079734444618225\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.33481261078615365, Test 0.3308134078979492\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.3348290166869667, Test 0.33082976937294006\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.33484538501093847, Test 0.3308458626270294\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.33486178683938445, Test 0.3308618664741516\n",
      "TRAINING MODEL dt_norm_3_47\n",
      "Epoch 0, lr 4.5e-05\n",
      "Epoch 0: Train 0.17775240999417027, Test 0.15142540633678436\n",
      "Epoch 25, lr 1.125e-05\n",
      "Epoch 25: Train 0.2635904817261558, Test 0.2594510316848755\n",
      "Epoch 50, lr 2.8125e-06\n",
      "Epoch 50: Train 0.28588582164999365, Test 0.2807048261165619\n",
      "Epoch 75, lr 7.03125e-07\n",
      "Epoch 75: Train 0.29168727821198065, Test 0.28624671697616577\n",
      "Epoch 100, lr 1.7578125e-07\n",
      "Epoch 100: Train 0.29291407893533294, Test 0.2874208390712738\n",
      "Epoch 125, lr 2.197265625e-08\n",
      "Epoch 125: Train 0.2931515613327856, Test 0.28764230012893677\n",
      "Epoch 150, lr 1.0986328125e-08\n",
      "Epoch 150: Train 0.2931828527994778, Test 0.2876720130443573\n",
      "Epoch 175, lr 1.0986328125e-08\n",
      "Epoch 175: Train 0.2931989339598711, Test 0.2876878082752228\n",
      "Epoch 200, lr 1.0986328125e-08\n",
      "Epoch 200: Train 0.29321522200885025, Test 0.28770363330841064\n",
      "Epoch 225, lr 1.0986328125e-08\n",
      "Epoch 225: Train 0.2932314198950063, Test 0.2877195477485657\n",
      "Epoch 250, lr 1.0986328125e-08\n",
      "Epoch 250: Train 0.2932476323583852, Test 0.2877352833747864\n",
      "Epoch 275, lr 1.0986328125e-08\n",
      "Epoch 275: Train 0.29326382052639255, Test 0.28775134682655334\n",
      "Epoch 300, lr 1.0986328125e-08\n",
      "Epoch 300: Train 0.29328013135903125, Test 0.287767231464386\n",
      "Epoch 325, lr 1.0986328125e-08\n",
      "Epoch 325: Train 0.2932962756873905, Test 0.2877829372882843\n",
      "Epoch 350, lr 1.0986328125e-08\n",
      "Epoch 350: Train 0.29331252497175464, Test 0.2877989411354065\n",
      "Epoch 375, lr 1.0986328125e-08\n",
      "Epoch 375: Train 0.2933288417432619, Test 0.28781479597091675\n",
      "Epoch 400, lr 1.0986328125e-08\n",
      "Epoch 400: Train 0.293345110139985, Test 0.28783082962036133\n",
      "Epoch 425, lr 1.0986328125e-08\n",
      "Epoch 425: Train 0.2933612648343694, Test 0.28784653544425964\n",
      "Epoch 450, lr 1.0986328125e-08\n",
      "Epoch 450: Train 0.2933774718987769, Test 0.2878623306751251\n",
      "Epoch 475, lr 1.0986328125e-08\n",
      "Epoch 475: Train 0.29339361665905384, Test 0.28787821531295776\n"
     ]
    }
   ],
   "source": [
    "# train_models(data,model_params = [],epochs = 500, lr = 0.000045, dir_label = 'wafer_layer_split_mip_std_1_mean_nonzero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95b7b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'MIT_TTbar'\n",
    "data_non_norm = []\n",
    "prefixed = [filename for filename in os.listdir(path) if filename.startswith(\"dt_1\")]\n",
    "\n",
    "for p in prefixed:\n",
    "    data_non_norm.append([torch.load(f'{path}/{p}'),p])\n",
    "    \n",
    "prefixed = [filename for filename in os.listdir(path) if filename.startswith(\"dt_2\")]\n",
    "\n",
    "for p in prefixed:\n",
    "    data_non_norm.append([torch.load(f'{path}/{p}'),p])\n",
    "prefixed = [filename for filename in os.listdir(path) if filename.startswith(\"dt_3\")]\n",
    "\n",
    "for p in prefixed:\n",
    "    data_non_norm.append([torch.load(f'{path}/{p}'),p])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd4ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating MSE of trained models\n",
    "path = '/uscms/home/nswood/nobackup/Notebooks/AE_Dev/models/batched_models/wafer_layer_split_mip_std_1_mean_nonzero'\n",
    "models = os.listdir(path)[9:]\n",
    "cur_model = models[1]\n",
    "def get_data(data,cur_model):\n",
    "    cur_data = []\n",
    "    for d in data:\n",
    "        if d[1] == cur_model:\n",
    "            cur_data = d[0]\n",
    "            break\n",
    "    return cur_data\n",
    "test_set = []\n",
    "pred_set = []\n",
    "\n",
    "for m in models:\n",
    "    cur_model = torch.load(os.path.join(path,m)).to('cpu')\n",
    "    cur_data = get_data(data,m).to('cpu')\n",
    "    if len(cur_data)< 20000:\n",
    "        test_data = cur_data[-int(0.19*len(cur_data)):]\n",
    "        test_set.append(test_data)\n",
    "        pred_set.append(cur_model(test_data[:,0:48]))\n",
    "    else:\n",
    "        test_data = cur_data[-int(0.19*20000):]\n",
    "        test_set.append(test_data)\n",
    "        pred_set.append(cur_model(test_data[:,0:48]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "189f5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all past 29\n",
    "high_p_error = []\n",
    "for m in models:\n",
    "    if int(m[10:]) >= 29 and int(m[8]) == 3:\n",
    "        high_p_error.append(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f6b36a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dt_norm_3_36: 1.0381478893504144\n",
      "model dt_norm_3_30: 1.8685837958278657\n",
      "model dt_norm_3_31: 2.0062977086648943\n",
      "model dt_norm_3_33: 1.96181069181633\n",
      "model dt_norm_3_35: 1.3837918068494799\n",
      "model dt_norm_3_37: 0.7695213048548699\n",
      "model dt_norm_3_27: 1.033476417805195\n",
      "model dt_norm_3_29: 1.7814479705114366\n",
      "model dt_norm_3_32: 1.9048256756000521\n",
      "model dt_norm_3_34: 1.3661959368782044\n",
      "model dt_norm_3_38: 1.0650395926423073\n",
      "model dt_norm_1_1: 0.5635025843582154\n",
      "model dt_norm_1_3: 4.245519473276139\n",
      "model dt_norm_1_5: 6.042746063661576\n",
      "model dt_norm_1_7: 6.7547323364639285\n",
      "model dt_norm_1_9: 6.21603508610344\n",
      "model dt_norm_1_11: 6.593338716373444\n",
      "model dt_norm_1_13: 6.620123031646729\n",
      "model dt_norm_1_15: 4.57067295929718\n",
      "model dt_norm_1_17: 3.43209436681366\n",
      "model dt_norm_1_19: 2.794706414523125\n",
      "model dt_norm_1_21: 2.103925287757874\n",
      "model dt_norm_1_23: 1.6940443242988588\n",
      "model dt_norm_1_25: 1.6224409981298449\n",
      "model dt_norm_1_27: 0.8012111567502023\n",
      "model dt_norm_1_29: 2.627484351453781\n",
      "model dt_norm_1_30: 2.030152130104065\n",
      "model dt_norm_1_31: 1.9796300549869539\n",
      "model dt_norm_1_32: 1.6702333031988146\n",
      "model dt_norm_1_33: 1.542896800937176\n",
      "model dt_norm_2_1: 0.13860620479863883\n",
      "model dt_norm_2_3: 1.6893016316843035\n",
      "model dt_norm_2_5: 2.209098590769768\n",
      "model dt_norm_2_7: 3.714969987436295\n",
      "model dt_norm_2_9: 2.8471588773736958\n",
      "model dt_norm_2_11: 3.100001834263802\n",
      "model dt_norm_2_13: 3.2510418768711093\n",
      "model dt_norm_2_15: 1.9751466515779497\n",
      "model dt_norm_2_17: 2.0018927597150804\n",
      "model dt_norm_2_19: 1.8028575061798098\n",
      "model dt_norm_2_21: 1.4464876770915986\n",
      "model dt_norm_2_23: 1.6530972171621323\n",
      "model dt_norm_2_25: 0.9966007817988396\n",
      "model dt_norm_2_27: 2.4229758329286577\n",
      "model dt_norm_2_29: 1.6863068228130342\n",
      "model dt_norm_2_30: 1.7804486498823167\n",
      "model dt_norm_2_31: 1.564919783706665\n",
      "model dt_norm_2_32: 1.947970064008713\n",
      "model dt_norm_2_34: 1.7333909975624087\n",
      "model dt_norm_2_35: 1.2657716325130464\n",
      "model dt_norm_2_36: 1.1293102089500429\n",
      "model dt_norm_2_37: 1.2361608237862587\n",
      "model dt_norm_2_38: 0.6196137050707341\n",
      "model dt_norm_2_39: 0.44321191386151315\n",
      "model dt_norm_2_40: 0.2862089150447846\n",
      "model dt_norm_2_41: 0.3043041903072596\n",
      "model dt_norm_2_42: 0.3936657435922623\n",
      "model dt_norm_2_43: 0.23577410428476336\n",
      "model dt_norm_2_44: 0.06449879845932127\n",
      "model dt_norm_2_45: 0.18242882783389092\n",
      "model dt_norm_3_1: 0.10248131119698287\n",
      "model dt_norm_3_3: 11.078178416942597\n",
      "model dt_norm_3_5: 19.848587943054202\n",
      "model dt_norm_3_7: 27.628071281707765\n",
      "model dt_norm_3_9: 24.0630680131073\n",
      "model dt_norm_3_11: 17.183335281097413\n",
      "model dt_norm_3_13: 15.67660311103821\n",
      "model dt_norm_3_15: 10.653197844898225\n",
      "model dt_norm_3_17: 9.346070140514374\n",
      "model dt_norm_3_19: 9.537277938869478\n",
      "model dt_norm_3_21: 12.682458969749451\n",
      "model dt_norm_3_23: 9.697956380722047\n",
      "model dt_norm_3_25: 6.574152057048798\n",
      "model dt_norm_3_39: 0.9750403650369645\n",
      "model dt_norm_3_40: 0.8115254142680168\n",
      "model dt_norm_3_41: 0.6016009414572716\n",
      "model dt_norm_3_42: 0.8897162256717682\n",
      "model dt_norm_3_43: 0.6094286748447418\n",
      "model dt_norm_3_44: 0.8326916112828255\n",
      "model dt_norm_3_45: 0.4593167317972184\n",
      "model dt_norm_3_46: 0.6449690549046994\n",
      "model dt_norm_3_47: 0.5642239758925438\n"
     ]
    }
   ],
   "source": [
    "stats_per = []\n",
    "for i in range(len(pred_set)):\n",
    "    stats_per.append(AE_MSE(pred_set[i],test_set[i][:,0:48]).item()*3.5280**2)\n",
    "    print(f'model {models[i]}: {stats_per[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd44985",
   "metadata": {},
   "source": [
    "## Training Larger Model on only bad data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9674c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_models = []\n",
    "data_bad = []\n",
    "for i in range(len(stats_per)):\n",
    "    if stats_per[i]> 10:\n",
    "        bad_models.append(models[i])\n",
    "        data_bad.append([get_data(data,models[i]),models[i]])\n",
    "dt_1_bad = []\n",
    "dt_2_bad = []\n",
    "dt_3_bad = []\n",
    "\n",
    "for d in bad_models:\n",
    "    if d[8] == '1':\n",
    "        dt_1_bad.append(d)\n",
    "    elif d[8] == '2':\n",
    "        dt_2_bad.append(d)\n",
    "    else:\n",
    "        dt_3_bad.append(d)\n",
    "dt_1 = []\n",
    "for p in dt_1_bad:\n",
    "    dt_1.append(get_data(data,p))\n",
    "    \n",
    "dt_1 = torch.vstack(dt_1)\n",
    "\n",
    "dt_2 = []\n",
    "for p in dt_2_bad:\n",
    "    dt_2.append(get_data(data,p))\n",
    "dt_2 = torch.vstack(dt_2)\n",
    "\n",
    "dt_3 = []\n",
    "for p in dt_3_bad:\n",
    "    dt_3.append(get_data(data,p))\n",
    "dt_3 = torch.vstack(dt_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_train.train_models(data_bad,\n",
    "             override = True,\n",
    "             model_params = [48,250,250,100,16],\n",
    "             epochs = 250, \n",
    "             lr = 4.5e-3,\n",
    "             max_dt_size = 10000,\n",
    "             dir_label = 'wafer_layer_split_mip_std_1_mean_nonzero_bad_layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bbda37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up way to continue a training. IE just not delete and don't train if already a model saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16387a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dt_norm_1_3 has MSE of 7.673231889610291 and is being retrained\n",
      "Model dt_norm_1_5 has MSE of 18.8831373837204 and is being retrained\n",
      "Model dt_norm_1_7 has MSE of 19.87493677116394 and is being retrained\n",
      "Model dt_norm_1_9 has MSE of 14.93008611884308 and is being retrained\n",
      "Model dt_norm_1_11 has MSE of 15.435902604583742 and is being retrained\n",
      "Model dt_norm_1_13 has MSE of 11.52729180319977 and is being retrained\n",
      "Model dt_norm_2_11 has MSE of 19.08767094090271 and is being retrained\n",
      "Model dt_norm_2_13 has MSE of 15.458542001998902 and is being retrained\n",
      "Model dt_norm_2_15 has MSE of 12.146947749412538 and is being retrained\n",
      "Model dt_norm_2_17 has MSE of 10.804908367103577 and is being retrained\n",
      "Model dt_norm_2_19 has MSE of 10.916827084362032 and is being retrained\n",
      "Model dt_norm_2_21 has MSE of 6.759815740287781 and is being retrained\n",
      "Model dt_norm_2_23 has MSE of 8.071081685554505 and is being retrained\n",
      "Model dt_norm_2_25 has MSE of 6.053142114126206 and is being retrained\n",
      "Model dt_norm_3_3 has MSE of 11.078178416942597 and is being retrained\n",
      "Model dt_norm_3_5 has MSE of 19.848587943054202 and is being retrained\n",
      "Model dt_norm_3_7 has MSE of 27.628071281707765 and is being retrained\n",
      "Model dt_norm_3_9 has MSE of 24.0630680131073 and is being retrained\n",
      "Model dt_norm_3_11 has MSE of 17.183335281097413 and is being retrained\n",
      "Model dt_norm_3_13 has MSE of 15.67660311103821 and is being retrained\n",
      "Model dt_norm_3_15 has MSE of 10.653197844898225 and is being retrained\n",
      "Model dt_norm_3_17 has MSE of 9.346070140514374 and is being retrained\n",
      "Model dt_norm_3_19 has MSE of 9.537277938869478 and is being retrained\n",
      "Model dt_norm_3_21 has MSE of 12.682458969749451 and is being retrained\n",
      "Model dt_norm_3_23 has MSE of 9.697956380722047 and is being retrained\n",
      "Model dt_norm_3_25 has MSE of 7.938491794807435 and is being retrained\n",
      "TRAINING MODEL dt_norm_1_3\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 198000\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 5.300, Test 5.172\n",
      "MSE NON-NORMALIZED: Train MSE 209.729, Test MSE 143.024\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 0.886, Test 0.978\n",
      "MSE NON-NORMALIZED: Train MSE 29.311, Test MSE 25.694\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 0.666, Test 0.731\n",
      "MSE NON-NORMALIZED: Train MSE 22.784, Test MSE 19.345\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 0.572, Test 0.643\n",
      "MSE NON-NORMALIZED: Train MSE 20.285, Test MSE 17.334\n",
      "Epoch 100, lr 8.5e-05\n",
      "Epoch 100: Train 0.510, Test 0.571\n",
      "MSE NON-NORMALIZED: Train MSE 19.052, Test MSE 15.112\n",
      "Epoch 125, lr 8.5e-05\n",
      "Epoch 125: Train 0.523, Test 0.576\n",
      "MSE NON-NORMALIZED: Train MSE 18.390, Test MSE 15.954\n",
      "Epoch 150, lr 4.25e-05\n",
      "Epoch 150: Train 0.410, Test 0.467\n",
      "MSE NON-NORMALIZED: Train MSE 14.877, Test MSE 12.501\n",
      "Epoch 175, lr 4.25e-05\n",
      "Epoch 175: Train 0.388, Test 0.442\n",
      "MSE NON-NORMALIZED: Train MSE 14.284, Test MSE 12.166\n",
      "Epoch 200, lr 4.25e-05\n",
      "Epoch 200: Train 0.378, Test 0.428\n",
      "MSE NON-NORMALIZED: Train MSE 13.999, Test MSE 12.001\n",
      "Epoch 225, lr 2.125e-05\n",
      "Epoch 225: Train 0.346, Test 0.389\n",
      "MSE NON-NORMALIZED: Train MSE 12.758, Test MSE 10.689\n",
      "Epoch 250, lr 2.125e-05\n",
      "Epoch 250: Train 0.341, Test 0.380\n",
      "MSE NON-NORMALIZED: Train MSE 12.555, Test MSE 10.466\n",
      "Epoch 275, lr 2.125e-05\n",
      "Epoch 275: Train 0.337, Test 0.375\n",
      "MSE NON-NORMALIZED: Train MSE 12.431, Test MSE 10.350\n",
      "Epoch 300, lr 2.125e-05\n",
      "Epoch 300: Train 0.332, Test 0.371\n",
      "MSE NON-NORMALIZED: Train MSE 12.347, Test MSE 10.248\n",
      "Epoch 325, lr 2.125e-05\n",
      "Epoch 325: Train 0.330, Test 0.367\n",
      "MSE NON-NORMALIZED: Train MSE 12.214, Test MSE 10.098\n",
      "Epoch 350, lr 2.125e-05\n",
      "Epoch 350: Train 0.327, Test 0.363\n",
      "MSE NON-NORMALIZED: Train MSE 12.118, Test MSE 10.005\n",
      "Epoch 375, lr 2.125e-05\n",
      "Epoch 375: Train 0.325, Test 0.359\n",
      "MSE NON-NORMALIZED: Train MSE 12.048, Test MSE 9.909\n",
      "Epoch 400, lr 2.125e-05\n",
      "Epoch 400: Train 0.322, Test 0.357\n",
      "MSE NON-NORMALIZED: Train MSE 11.981, Test MSE 9.874\n",
      "Epoch 425, lr 2.125e-05\n",
      "Epoch 425: Train 0.321, Test 0.355\n",
      "MSE NON-NORMALIZED: Train MSE 11.918, Test MSE 9.784\n",
      "Epoch 450, lr 2.125e-05\n",
      "Epoch 450: Train 0.320, Test 0.353\n",
      "MSE NON-NORMALIZED: Train MSE 11.860, Test MSE 9.749\n",
      "Epoch 475, lr 1.0625e-05\n",
      "Epoch 475: Train 0.311, Test 0.341\n",
      "MSE NON-NORMALIZED: Train MSE 11.393, Test MSE 9.367\n",
      "TRAINING MODEL dt_norm_1_5\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 198000\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 7.965, Test 6.804\n",
      "MSE NON-NORMALIZED: Train MSE 315.970, Test MSE 206.378\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 2.028, Test 1.521\n",
      "MSE NON-NORMALIZED: Train MSE 50.692, Test MSE 43.713\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 1.458, Test 1.102\n",
      "MSE NON-NORMALIZED: Train MSE 37.889, Test MSE 31.296\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 1.262, Test 0.931\n",
      "MSE NON-NORMALIZED: Train MSE 33.515, Test MSE 26.444\n",
      "Epoch 100, lr 4.25e-05\n",
      "Epoch 100: Train 1.096, Test 0.757\n",
      "MSE NON-NORMALIZED: Train MSE 25.623, Test MSE 21.246\n",
      "Epoch 125, lr 4.25e-05\n",
      "Epoch 125: Train 1.031, Test 0.700\n",
      "MSE NON-NORMALIZED: Train MSE 24.445, Test MSE 20.062\n",
      "Epoch 150, lr 2.125e-05\n",
      "Epoch 150: Train 0.956, Test 0.636\n",
      "MSE NON-NORMALIZED: Train MSE 21.938, Test MSE 18.499\n",
      "Epoch 175, lr 2.125e-05\n",
      "Epoch 175: Train 0.932, Test 0.615\n",
      "MSE NON-NORMALIZED: Train MSE 21.415, Test MSE 18.367\n",
      "Epoch 200, lr 2.125e-05\n",
      "Epoch 200: Train 0.914, Test 0.600\n",
      "MSE NON-NORMALIZED: Train MSE 20.977, Test MSE 18.351\n",
      "Epoch 225, lr 2.125e-05\n",
      "Epoch 225: Train 0.891, Test 0.580\n",
      "MSE NON-NORMALIZED: Train MSE 20.639, Test MSE 17.671\n",
      "Epoch 250, lr 2.125e-05\n",
      "Epoch 250: Train 0.879, Test 0.568\n",
      "MSE NON-NORMALIZED: Train MSE 20.219, Test MSE 17.380\n",
      "Epoch 275, lr 1.0625e-05\n",
      "Epoch 275: Train 0.852, Test 0.544\n",
      "MSE NON-NORMALIZED: Train MSE 19.188, Test MSE 16.601\n",
      "Epoch 300, lr 1.0625e-05\n",
      "Epoch 300: Train 0.842, Test 0.535\n",
      "MSE NON-NORMALIZED: Train MSE 18.961, Test MSE 16.392\n",
      "Epoch 325, lr 1.0625e-05\n",
      "Epoch 325: Train 0.836, Test 0.528\n",
      "MSE NON-NORMALIZED: Train MSE 18.791, Test MSE 16.205\n",
      "Epoch 350, lr 1.0625e-05\n",
      "Epoch 350: Train 0.827, Test 0.521\n",
      "MSE NON-NORMALIZED: Train MSE 18.578, Test MSE 16.019\n",
      "Epoch 375, lr 1.0625e-05\n",
      "Epoch 375: Train 0.822, Test 0.515\n",
      "MSE NON-NORMALIZED: Train MSE 18.398, Test MSE 15.783\n",
      "Epoch 400, lr 1.0625e-05\n",
      "Epoch 400: Train 0.815, Test 0.509\n",
      "MSE NON-NORMALIZED: Train MSE 18.254, Test MSE 15.636\n",
      "Epoch 425, lr 1.0625e-05\n",
      "Epoch 425: Train 0.809, Test 0.505\n",
      "MSE NON-NORMALIZED: Train MSE 18.150, Test MSE 15.507\n",
      "Epoch 450, lr 1.0625e-05\n",
      "Epoch 450: Train 0.806, Test 0.500\n",
      "MSE NON-NORMALIZED: Train MSE 18.004, Test MSE 15.385\n",
      "Epoch 475, lr 1.0625e-05\n",
      "Epoch 475: Train 0.803, Test 0.496\n",
      "MSE NON-NORMALIZED: Train MSE 17.923, Test MSE 15.296\n",
      "TRAINING MODEL dt_norm_1_7\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 198000\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 5.322, Test 5.693\n",
      "MSE NON-NORMALIZED: Train MSE 282.680, Test MSE 180.126\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 1.530, Test 1.524\n",
      "MSE NON-NORMALIZED: Train MSE 53.553, Test MSE 45.125\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 1.259, Test 1.165\n",
      "MSE NON-NORMALIZED: Train MSE 41.051, Test MSE 33.336\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 1.081, Test 1.008\n",
      "MSE NON-NORMALIZED: Train MSE 37.406, Test MSE 28.189\n",
      "Epoch 100, lr 8.5e-05\n",
      "Epoch 100: Train 0.972, Test 0.924\n",
      "MSE NON-NORMALIZED: Train MSE 32.351, Test MSE 25.875\n",
      "Epoch 125, lr 4.25e-05\n",
      "Epoch 125: Train 0.812, Test 0.772\n",
      "MSE NON-NORMALIZED: Train MSE 25.116, Test MSE 21.485\n",
      "Epoch 150, lr 4.25e-05\n",
      "Epoch 150: Train 0.772, Test 0.727\n",
      "MSE NON-NORMALIZED: Train MSE 23.680, Test MSE 20.639\n",
      "Epoch 175, lr 4.25e-05\n",
      "Epoch 175: Train 0.741, Test 0.692\n",
      "MSE NON-NORMALIZED: Train MSE 23.088, Test MSE 19.993\n",
      "Epoch 200, lr 2.125e-05\n",
      "Epoch 200: Train 0.690, Test 0.648\n",
      "MSE NON-NORMALIZED: Train MSE 20.424, Test MSE 19.048\n",
      "Epoch 225, lr 2.125e-05\n",
      "Epoch 225: Train 0.663, Test 0.625\n",
      "MSE NON-NORMALIZED: Train MSE 19.965, Test MSE 18.308\n",
      "Epoch 250, lr 1.0625e-05\n",
      "Epoch 250: Train 0.642, Test 0.604\n",
      "MSE NON-NORMALIZED: Train MSE 18.859, Test MSE 17.693\n",
      "Epoch 275, lr 1.0625e-05\n",
      "Epoch 275: Train 0.629, Test 0.593\n",
      "MSE NON-NORMALIZED: Train MSE 18.628, Test MSE 17.418\n",
      "Epoch 300, lr 1.0625e-05\n",
      "Epoch 300: Train 0.621, Test 0.585\n",
      "MSE NON-NORMALIZED: Train MSE 18.344, Test MSE 17.136\n",
      "Epoch 325, lr 1.0625e-05\n",
      "Epoch 325: Train 0.611, Test 0.577\n",
      "MSE NON-NORMALIZED: Train MSE 18.151, Test MSE 16.944\n",
      "Epoch 350, lr 1.0625e-05\n",
      "Epoch 350: Train 0.605, Test 0.570\n",
      "MSE NON-NORMALIZED: Train MSE 17.939, Test MSE 16.712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375, lr 1.0625e-05\n",
      "Epoch 375: Train 0.597, Test 0.564\n",
      "MSE NON-NORMALIZED: Train MSE 17.781, Test MSE 16.541\n",
      "Epoch 400, lr 5.3125e-06\n",
      "Epoch 400: Train 0.588, Test 0.556\n",
      "MSE NON-NORMALIZED: Train MSE 17.409, Test MSE 16.262\n",
      "Epoch 425, lr 5.3125e-06\n",
      "Epoch 425: Train 0.584, Test 0.552\n",
      "MSE NON-NORMALIZED: Train MSE 17.320, Test MSE 16.164\n",
      "Epoch 450, lr 5.3125e-06\n",
      "Epoch 450: Train 0.581, Test 0.549\n",
      "MSE NON-NORMALIZED: Train MSE 17.237, Test MSE 16.086\n",
      "Epoch 475, lr 5.3125e-06\n",
      "Epoch 475: Train 0.578, Test 0.545\n",
      "MSE NON-NORMALIZED: Train MSE 17.153, Test MSE 15.998\n",
      "TRAINING MODEL dt_norm_1_9\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 198000\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 4.110, Test 3.986\n",
      "MSE NON-NORMALIZED: Train MSE 203.543, Test MSE 122.715\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 1.331, Test 1.187\n",
      "MSE NON-NORMALIZED: Train MSE 36.861, Test MSE 34.027\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 1.186, Test 1.079\n",
      "MSE NON-NORMALIZED: Train MSE 31.137, Test MSE 32.778\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 0.995, Test 0.872\n",
      "MSE NON-NORMALIZED: Train MSE 27.714, Test MSE 24.518\n",
      "Epoch 100, lr 8.5e-05\n",
      "Epoch 100: Train 0.958, Test 0.869\n",
      "MSE NON-NORMALIZED: Train MSE 26.392, Test MSE 26.942\n",
      "Epoch 125, lr 8.5e-05\n",
      "Epoch 125: Train 0.925, Test 0.812\n",
      "MSE NON-NORMALIZED: Train MSE 24.505, Test MSE 23.881\n",
      "Epoch 150, lr 8.5e-05\n",
      "Epoch 150: Train 0.883, Test 0.785\n",
      "MSE NON-NORMALIZED: Train MSE 24.464, Test MSE 24.874\n",
      "Epoch 175, lr 8.5e-05\n",
      "Epoch 175: Train 0.847, Test 0.740\n",
      "MSE NON-NORMALIZED: Train MSE 23.176, Test MSE 22.503\n",
      "Epoch 200, lr 8.5e-05\n",
      "Epoch 200: Train 0.849, Test 0.757\n",
      "MSE NON-NORMALIZED: Train MSE 22.537, Test MSE 24.636\n",
      "Epoch 225, lr 4.25e-05\n",
      "Epoch 225: Train 0.747, Test 0.627\n",
      "MSE NON-NORMALIZED: Train MSE 18.023, Test MSE 17.906\n",
      "Epoch 250, lr 4.25e-05\n",
      "Epoch 250: Train 0.707, Test 0.595\n",
      "MSE NON-NORMALIZED: Train MSE 17.725, Test MSE 16.774\n",
      "Epoch 275, lr 4.25e-05\n",
      "Epoch 275: Train 0.707, Test 0.599\n",
      "MSE NON-NORMALIZED: Train MSE 17.132, Test MSE 17.203\n",
      "Epoch 300, lr 2.125e-05\n",
      "Epoch 300: Train 0.669, Test 0.553\n",
      "MSE NON-NORMALIZED: Train MSE 15.601, Test MSE 15.276\n",
      "Epoch 325, lr 2.125e-05\n",
      "Epoch 325: Train 0.653, Test 0.542\n",
      "MSE NON-NORMALIZED: Train MSE 15.386, Test MSE 15.103\n",
      "Epoch 350, lr 2.125e-05\n",
      "Epoch 350: Train 0.642, Test 0.533\n",
      "MSE NON-NORMALIZED: Train MSE 15.168, Test MSE 14.781\n",
      "Epoch 375, lr 2.125e-05\n",
      "Epoch 375: Train 0.637, Test 0.529\n",
      "MSE NON-NORMALIZED: Train MSE 15.083, Test MSE 14.755\n",
      "Epoch 400, lr 2.125e-05\n",
      "Epoch 400: Train 0.634, Test 0.526\n",
      "MSE NON-NORMALIZED: Train MSE 14.943, Test MSE 14.683\n",
      "Epoch 425, lr 1.0625e-05\n",
      "Epoch 425: Train 0.616, Test 0.508\n",
      "MSE NON-NORMALIZED: Train MSE 14.113, Test MSE 13.782\n",
      "Epoch 450, lr 1.0625e-05\n",
      "Epoch 450: Train 0.611, Test 0.504\n",
      "MSE NON-NORMALIZED: Train MSE 14.014, Test MSE 13.697\n",
      "Epoch 475, lr 1.0625e-05\n",
      "Epoch 475: Train 0.607, Test 0.501\n",
      "MSE NON-NORMALIZED: Train MSE 13.954, Test MSE 13.635\n",
      "TRAINING MODEL dt_norm_1_11\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 198000\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 2.353, Test 2.696\n",
      "MSE NON-NORMALIZED: Train MSE 130.283, Test MSE 83.004\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 0.780, Test 0.887\n",
      "MSE NON-NORMALIZED: Train MSE 27.007, Test MSE 23.892\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 0.704, Test 0.765\n",
      "MSE NON-NORMALIZED: Train MSE 20.970, Test MSE 18.156\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 0.688, Test 0.725\n",
      "MSE NON-NORMALIZED: Train MSE 20.076, Test MSE 17.343\n",
      "Epoch 100, lr 4.25e-05\n",
      "Epoch 100: Train 0.613, Test 0.653\n",
      "MSE NON-NORMALIZED: Train MSE 16.639, Test MSE 15.203\n",
      "Epoch 125, lr 4.25e-05\n",
      "Epoch 125: Train 0.596, Test 0.629\n",
      "MSE NON-NORMALIZED: Train MSE 15.732, Test MSE 14.510\n",
      "Epoch 150, lr 2.125e-05\n",
      "Epoch 150: Train 0.570, Test 0.598\n",
      "MSE NON-NORMALIZED: Train MSE 14.431, Test MSE 13.906\n",
      "Epoch 175, lr 2.125e-05\n",
      "Epoch 175: Train 0.560, Test 0.586\n",
      "MSE NON-NORMALIZED: Train MSE 14.201, Test MSE 13.859\n",
      "Epoch 200, lr 2.125e-05\n",
      "Epoch 200: Train 0.552, Test 0.577\n",
      "MSE NON-NORMALIZED: Train MSE 14.016, Test MSE 13.878\n",
      "Epoch 225, lr 2.125e-05\n",
      "Epoch 225: Train 0.545, Test 0.569\n",
      "MSE NON-NORMALIZED: Train MSE 13.885, Test MSE 13.704\n",
      "Epoch 250, lr 2.125e-05\n",
      "Epoch 250: Train 0.539, Test 0.564\n",
      "MSE NON-NORMALIZED: Train MSE 13.746, Test MSE 13.568\n",
      "Epoch 275, lr 2.125e-05\n",
      "Epoch 275: Train 0.535, Test 0.559\n",
      "MSE NON-NORMALIZED: Train MSE 13.652, Test MSE 13.471\n",
      "Epoch 300, lr 2.125e-05\n",
      "Epoch 300: Train 0.531, Test 0.555\n",
      "MSE NON-NORMALIZED: Train MSE 13.590, Test MSE 13.376\n",
      "Epoch 325, lr 1.0625e-05\n",
      "Epoch 325: Train 0.523, Test 0.546\n",
      "MSE NON-NORMALIZED: Train MSE 13.093, Test MSE 13.079\n",
      "Epoch 350, lr 1.0625e-05\n",
      "Epoch 350: Train 0.519, Test 0.543\n",
      "MSE NON-NORMALIZED: Train MSE 12.978, Test MSE 12.991\n",
      "Epoch 375, lr 1.0625e-05\n",
      "Epoch 375: Train 0.516, Test 0.540\n",
      "MSE NON-NORMALIZED: Train MSE 12.934, Test MSE 12.932\n",
      "Epoch 400, lr 1.0625e-05\n",
      "Epoch 400: Train 0.513, Test 0.537\n",
      "MSE NON-NORMALIZED: Train MSE 12.861, Test MSE 12.873\n",
      "Epoch 425, lr 1.0625e-05\n",
      "Epoch 425: Train 0.510, Test 0.535\n",
      "MSE NON-NORMALIZED: Train MSE 12.833, Test MSE 12.827\n",
      "Epoch 450, lr 1.0625e-05\n",
      "Epoch 450: Train 0.509, Test 0.533\n",
      "MSE NON-NORMALIZED: Train MSE 12.750, Test MSE 12.767\n",
      "Epoch 475, lr 1.0625e-05\n",
      "Epoch 475: Train 0.507, Test 0.531\n",
      "MSE NON-NORMALIZED: Train MSE 12.730, Test MSE 12.719\n",
      "TRAINING MODEL dt_norm_1_13\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 198000\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 1.693, Test 1.724\n",
      "MSE NON-NORMALIZED: Train MSE 83.934, Test MSE 50.603\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 0.734, Test 0.694\n",
      "MSE NON-NORMALIZED: Train MSE 17.962, Test MSE 16.683\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 0.755, Test 0.687\n",
      "MSE NON-NORMALIZED: Train MSE 15.656, Test MSE 16.734\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 0.706, Test 0.641\n",
      "MSE NON-NORMALIZED: Train MSE 15.163, Test MSE 14.677\n",
      "Epoch 100, lr 4.25e-05\n",
      "Epoch 100: Train 0.656, Test 0.590\n",
      "MSE NON-NORMALIZED: Train MSE 13.613, Test MSE 12.868\n",
      "Epoch 125, lr 2.125e-05\n",
      "Epoch 125: Train 0.641, Test 0.573\n",
      "MSE NON-NORMALIZED: Train MSE 12.942, Test MSE 12.643\n",
      "Epoch 150, lr 2.125e-05\n",
      "Epoch 150: Train 0.633, Test 0.565\n",
      "MSE NON-NORMALIZED: Train MSE 12.779, Test MSE 12.777\n",
      "Epoch 175, lr 2.125e-05\n",
      "Epoch 175: Train 0.626, Test 0.559\n",
      "MSE NON-NORMALIZED: Train MSE 12.687, Test MSE 12.851\n",
      "Epoch 200, lr 2.125e-05\n",
      "Epoch 200: Train 0.621, Test 0.555\n",
      "MSE NON-NORMALIZED: Train MSE 12.574, Test MSE 12.949\n",
      "Epoch 225, lr 2.125e-05\n",
      "Epoch 225: Train 0.617, Test 0.551\n",
      "MSE NON-NORMALIZED: Train MSE 12.493, Test MSE 12.835\n",
      "Epoch 250, lr 1.0625e-05\n",
      "Epoch 250: Train 0.609, Test 0.544\n",
      "MSE NON-NORMALIZED: Train MSE 12.275, Test MSE 12.582\n",
      "Epoch 275, lr 1.0625e-05\n",
      "Epoch 275: Train 0.607, Test 0.542\n",
      "MSE NON-NORMALIZED: Train MSE 12.227, Test MSE 12.529\n",
      "Epoch 300, lr 1.0625e-05\n",
      "Epoch 300: Train 0.606, Test 0.540\n",
      "MSE NON-NORMALIZED: Train MSE 12.187, Test MSE 12.485\n",
      "Epoch 325, lr 1.0625e-05\n",
      "Epoch 325: Train 0.605, Test 0.539\n",
      "MSE NON-NORMALIZED: Train MSE 12.160, Test MSE 12.464\n",
      "Epoch 350, lr 5.3125e-06\n",
      "Epoch 350: Train 0.602, Test 0.536\n",
      "MSE NON-NORMALIZED: Train MSE 12.074, Test MSE 12.400\n",
      "Epoch 375, lr 5.3125e-06\n",
      "Epoch 375: Train 0.601, Test 0.535\n",
      "MSE NON-NORMALIZED: Train MSE 12.054, Test MSE 12.378\n",
      "Epoch 400, lr 5.3125e-06\n",
      "Epoch 400: Train 0.601, Test 0.535\n",
      "MSE NON-NORMALIZED: Train MSE 12.038, Test MSE 12.362\n",
      "Epoch 425, lr 2.65625e-06\n",
      "Epoch 425: Train 0.599, Test 0.533\n",
      "MSE NON-NORMALIZED: Train MSE 11.999, Test MSE 12.330\n",
      "Epoch 450, lr 2.65625e-06\n",
      "Epoch 450: Train 0.599, Test 0.533\n",
      "MSE NON-NORMALIZED: Train MSE 11.991, Test MSE 12.320\n",
      "Epoch 475, lr 2.65625e-06\n",
      "Epoch 475: Train 0.599, Test 0.533\n",
      "MSE NON-NORMALIZED: Train MSE 11.984, Test MSE 12.313\n",
      "TRAINING MODEL dt_norm_2_11\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 88110\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 0.967, Test 0.952\n",
      "MSE NON-NORMALIZED: Train MSE 41.776, Test MSE 22.709\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 0.380, Test 0.350\n",
      "MSE NON-NORMALIZED: Train MSE 14.599, Test MSE 8.602\n",
      "Epoch 50, lr 4.25e-05\n",
      "Epoch 50: Train 0.335, Test 0.320\n",
      "MSE NON-NORMALIZED: Train MSE 12.894, Test MSE 8.536\n",
      "Epoch 75, lr 4.25e-05\n",
      "Epoch 75: Train 0.315, Test 0.298\n",
      "MSE NON-NORMALIZED: Train MSE 10.961, Test MSE 7.564\n",
      "Epoch 100, lr 4.25e-05\n",
      "Epoch 100: Train 0.305, Test 0.286\n",
      "MSE NON-NORMALIZED: Train MSE 10.847, Test MSE 7.326\n",
      "Epoch 125, lr 4.25e-05\n",
      "Epoch 125: Train 0.299, Test 0.279\n",
      "MSE NON-NORMALIZED: Train MSE 9.622, Test MSE 7.413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, lr 4.25e-05\n",
      "Epoch 150: Train 0.294, Test 0.274\n",
      "MSE NON-NORMALIZED: Train MSE 9.505, Test MSE 7.696\n",
      "Epoch 175, lr 2.125e-05\n",
      "Epoch 175: Train 0.290, Test 0.266\n",
      "MSE NON-NORMALIZED: Train MSE 7.965, Test MSE 7.686\n",
      "Epoch 200, lr 2.125e-05\n",
      "Epoch 200: Train 0.288, Test 0.264\n",
      "MSE NON-NORMALIZED: Train MSE 7.857, Test MSE 7.881\n",
      "Epoch 225, lr 2.125e-05\n",
      "Epoch 225: Train 0.286, Test 0.261\n",
      "MSE NON-NORMALIZED: Train MSE 7.774, Test MSE 7.829\n",
      "Epoch 250, lr 2.125e-05\n",
      "Epoch 250: Train 0.284, Test 0.261\n",
      "MSE NON-NORMALIZED: Train MSE 7.681, Test MSE 7.900\n",
      "Epoch 275, lr 2.125e-05\n",
      "Epoch 275: Train 0.282, Test 0.258\n",
      "MSE NON-NORMALIZED: Train MSE 7.714, Test MSE 7.750\n",
      "Epoch 300, lr 2.125e-05\n",
      "Epoch 300: Train 0.282, Test 0.258\n",
      "MSE NON-NORMALIZED: Train MSE 7.536, Test MSE 7.746\n",
      "Epoch 325, lr 2.125e-05\n",
      "Epoch 325: Train 0.280, Test 0.256\n",
      "MSE NON-NORMALIZED: Train MSE 7.628, Test MSE 7.686\n",
      "Epoch 350, lr 1.0625e-05\n",
      "Epoch 350: Train 0.279, Test 0.254\n",
      "MSE NON-NORMALIZED: Train MSE 7.225, Test MSE 7.630\n",
      "Epoch 375, lr 1.0625e-05\n",
      "Epoch 375: Train 0.277, Test 0.252\n",
      "MSE NON-NORMALIZED: Train MSE 7.219, Test MSE 7.596\n",
      "Epoch 400, lr 1.0625e-05\n",
      "Epoch 400: Train 0.277, Test 0.252\n",
      "MSE NON-NORMALIZED: Train MSE 7.184, Test MSE 7.577\n",
      "Epoch 425, lr 1.0625e-05\n",
      "Epoch 425: Train 0.275, Test 0.251\n",
      "MSE NON-NORMALIZED: Train MSE 7.185, Test MSE 7.556\n",
      "Epoch 450, lr 1.0625e-05\n",
      "Epoch 450: Train 0.274, Test 0.250\n",
      "MSE NON-NORMALIZED: Train MSE 7.152, Test MSE 7.542\n",
      "Epoch 475, lr 1.0625e-05\n",
      "Epoch 475: Train 0.273, Test 0.249\n",
      "MSE NON-NORMALIZED: Train MSE 7.148, Test MSE 7.522\n",
      "TRAINING MODEL dt_norm_2_13\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 84917\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 0.700, Test 0.722\n",
      "MSE NON-NORMALIZED: Train MSE 31.112, Test MSE 17.672\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 0.204, Test 0.301\n",
      "MSE NON-NORMALIZED: Train MSE 9.545, Test MSE 8.415\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 0.190, Test 0.284\n",
      "MSE NON-NORMALIZED: Train MSE 8.864, Test MSE 8.080\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 0.186, Test 0.276\n",
      "MSE NON-NORMALIZED: Train MSE 8.808, Test MSE 7.911\n",
      "Epoch 100, lr 8.5e-05\n",
      "Epoch 100: Train 0.183, Test 0.271\n",
      "MSE NON-NORMALIZED: Train MSE 8.552, Test MSE 7.780\n",
      "Epoch 125, lr 8.5e-05\n",
      "Epoch 125: Train 0.180, Test 0.266\n",
      "MSE NON-NORMALIZED: Train MSE 8.605, Test MSE 7.940\n",
      "Epoch 150, lr 2.125e-05\n",
      "Epoch 150: Train 0.178, Test 0.263\n",
      "MSE NON-NORMALIZED: Train MSE 8.009, Test MSE 8.092\n",
      "Epoch 175, lr 2.125e-05\n",
      "Epoch 175: Train 0.177, Test 0.262\n",
      "MSE NON-NORMALIZED: Train MSE 8.016, Test MSE 8.313\n",
      "Epoch 200, lr 5.3125e-06\n",
      "Epoch 200: Train 0.176, Test 0.261\n",
      "MSE NON-NORMALIZED: Train MSE 7.972, Test MSE 8.516\n",
      "Epoch 225, lr 1.328125e-06\n",
      "Epoch 225: Train 0.175, Test 0.261\n",
      "MSE NON-NORMALIZED: Train MSE 7.957, Test MSE 8.508\n",
      "Epoch 250, lr 3.3203125e-07\n",
      "Epoch 250: Train 0.175, Test 0.261\n",
      "MSE NON-NORMALIZED: Train MSE 7.954, Test MSE 8.509\n",
      "Epoch 275, lr 8.30078125e-08\n",
      "Epoch 275: Train 0.175, Test 0.261\n",
      "MSE NON-NORMALIZED: Train MSE 7.952, Test MSE 8.508\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 0.175, Test 0.261\n",
      "MSE NON-NORMALIZED: Train MSE 7.951, Test MSE 8.507\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 0.175, Test 0.261\n",
      "MSE NON-NORMALIZED: Train MSE 7.950, Test MSE 8.507\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 0.175, Test 0.261\n",
      "MSE NON-NORMALIZED: Train MSE 7.950, Test MSE 8.506\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 0.175, Test 0.260\n",
      "MSE NON-NORMALIZED: Train MSE 7.949, Test MSE 8.506\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 0.175, Test 0.260\n",
      "MSE NON-NORMALIZED: Train MSE 7.949, Test MSE 8.506\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 0.175, Test 0.260\n",
      "MSE NON-NORMALIZED: Train MSE 7.949, Test MSE 8.506\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 0.175, Test 0.260\n",
      "MSE NON-NORMALIZED: Train MSE 7.948, Test MSE 8.506\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 0.175, Test 0.260\n",
      "MSE NON-NORMALIZED: Train MSE 7.948, Test MSE 8.505\n",
      "TRAINING MODEL dt_norm_2_15\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 60726\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 0.567, Test 0.484\n",
      "MSE NON-NORMALIZED: Train MSE 17.084, Test MSE 10.012\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 0.190, Test 0.190\n",
      "MSE NON-NORMALIZED: Train MSE 4.408, Test MSE 3.853\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 0.175, Test 0.175\n",
      "MSE NON-NORMALIZED: Train MSE 4.147, Test MSE 3.555\n",
      "Epoch 75, lr 4.25e-05\n",
      "Epoch 75: Train 0.161, Test 0.165\n",
      "MSE NON-NORMALIZED: Train MSE 3.916, Test MSE 3.313\n",
      "Epoch 100, lr 1.0625e-05\n",
      "Epoch 100: Train 0.153, Test 0.160\n",
      "MSE NON-NORMALIZED: Train MSE 3.799, Test MSE 3.199\n",
      "Epoch 125, lr 5.3125e-06\n",
      "Epoch 125: Train 0.151, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.794, Test MSE 3.326\n",
      "Epoch 150, lr 1.328125e-06\n",
      "Epoch 150: Train 0.151, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.795, Test MSE 3.458\n",
      "Epoch 175, lr 3.3203125e-07\n",
      "Epoch 175: Train 0.150, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.805, Test MSE 3.589\n",
      "Epoch 200, lr 8.30078125e-08\n",
      "Epoch 200: Train 0.150, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.817, Test MSE 3.720\n",
      "Epoch 225, lr 1.03759765625e-08\n",
      "Epoch 225: Train 0.150, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.816, Test MSE 3.718\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 0.150, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.815, Test MSE 3.717\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 0.150, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.814, Test MSE 3.716\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 0.150, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.814, Test MSE 3.716\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 0.150, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.813, Test MSE 3.715\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 0.150, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.813, Test MSE 3.715\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 0.150, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.812, Test MSE 3.714\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 0.150, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.812, Test MSE 3.714\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 0.150, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.812, Test MSE 3.714\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 0.150, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.811, Test MSE 3.713\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 0.150, Test 0.158\n",
      "MSE NON-NORMALIZED: Train MSE 3.811, Test MSE 3.713\n",
      "TRAINING MODEL dt_norm_2_17\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 50402\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 0.336, Test 0.319\n",
      "MSE NON-NORMALIZED: Train MSE 14.888, Test MSE 6.850\n",
      "Epoch 25, lr 4.25e-05\n",
      "Epoch 25: Train 0.182, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.924, Test MSE 3.582\n",
      "Epoch 50, lr 1.0625e-05\n",
      "Epoch 50: Train 0.174, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 3.738, Test MSE 3.400\n",
      "Epoch 75, lr 2.65625e-06\n",
      "Epoch 75: Train 0.177, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.767, Test MSE 3.429\n",
      "Epoch 100, lr 6.640625e-07\n",
      "Epoch 100: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.776, Test MSE 3.436\n",
      "Epoch 125, lr 8.30078125e-08\n",
      "Epoch 125: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.792, Test MSE 3.584\n",
      "Epoch 150, lr 2.0751953125e-08\n",
      "Epoch 150: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.806, Test MSE 3.727\n",
      "Epoch 175, lr 1.03759765625e-08\n",
      "Epoch 175: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.819, Test MSE 3.866\n",
      "Epoch 200, lr 1.03759765625e-08\n",
      "Epoch 200: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.833, Test MSE 4.002\n",
      "Epoch 225, lr 1.03759765625e-08\n",
      "Epoch 225: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.832, Test MSE 3.997\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.831, Test MSE 3.994\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.830, Test MSE 3.992\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.830, Test MSE 3.990\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.829, Test MSE 3.989\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.828, Test MSE 3.988\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.828, Test MSE 3.987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.827, Test MSE 3.986\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.827, Test MSE 3.985\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.826, Test MSE 3.984\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 0.178, Test 0.161\n",
      "MSE NON-NORMALIZED: Train MSE 3.826, Test MSE 3.983\n",
      "TRAINING MODEL dt_norm_2_19\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 43279\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 0.411, Test 0.387\n",
      "MSE NON-NORMALIZED: Train MSE 17.729, Test MSE 8.827\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 0.149, Test 0.155\n",
      "MSE NON-NORMALIZED: Train MSE 4.314, Test MSE 3.686\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 0.140, Test 0.154\n",
      "MSE NON-NORMALIZED: Train MSE 4.143, Test MSE 3.723\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 0.138, Test 0.150\n",
      "MSE NON-NORMALIZED: Train MSE 4.124, Test MSE 3.631\n",
      "Epoch 100, lr 2.125e-05\n",
      "Epoch 100: Train 0.134, Test 0.146\n",
      "MSE NON-NORMALIZED: Train MSE 3.931, Test MSE 3.453\n",
      "Epoch 125, lr 5.3125e-06\n",
      "Epoch 125: Train 0.134, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.922, Test MSE 3.600\n",
      "Epoch 150, lr 1.328125e-06\n",
      "Epoch 150: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.934, Test MSE 3.753\n",
      "Epoch 175, lr 3.3203125e-07\n",
      "Epoch 175: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.949, Test MSE 3.902\n",
      "Epoch 200, lr 8.30078125e-08\n",
      "Epoch 200: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.965, Test MSE 4.050\n",
      "Epoch 225, lr 1.03759765625e-08\n",
      "Epoch 225: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.964, Test MSE 4.048\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.963, Test MSE 4.047\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.962, Test MSE 4.047\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.962, Test MSE 4.046\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.962, Test MSE 4.046\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.961, Test MSE 4.045\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.961, Test MSE 4.045\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.960, Test MSE 4.044\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.960, Test MSE 4.044\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.960, Test MSE 4.044\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 0.133, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 3.959, Test MSE 4.043\n",
      "TRAINING MODEL dt_norm_2_21\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 40878\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 0.202, Test 0.237\n",
      "MSE NON-NORMALIZED: Train MSE 10.667, Test MSE 5.191\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 0.104, Test 0.122\n",
      "MSE NON-NORMALIZED: Train MSE 3.278, Test MSE 2.874\n",
      "Epoch 50, lr 4.25e-05\n",
      "Epoch 50: Train 0.104, Test 0.119\n",
      "MSE NON-NORMALIZED: Train MSE 3.198, Test MSE 2.799\n",
      "Epoch 75, lr 1.0625e-05\n",
      "Epoch 75: Train 0.101, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.088, Test MSE 2.695\n",
      "Epoch 100, lr 5.3125e-06\n",
      "Epoch 100: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.090, Test MSE 2.699\n",
      "Epoch 125, lr 1.328125e-06\n",
      "Epoch 125: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.095, Test MSE 2.816\n",
      "Epoch 150, lr 3.3203125e-07\n",
      "Epoch 150: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.107, Test MSE 2.933\n",
      "Epoch 175, lr 4.150390625e-08\n",
      "Epoch 175: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.119, Test MSE 3.048\n",
      "Epoch 200, lr 1.03759765625e-08\n",
      "Epoch 200: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.132, Test MSE 3.161\n",
      "Epoch 225, lr 1.03759765625e-08\n",
      "Epoch 225: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.131, Test MSE 3.159\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.131, Test MSE 3.158\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.130, Test MSE 3.158\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.130, Test MSE 3.157\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.129, Test MSE 3.156\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.129, Test MSE 3.156\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.129, Test MSE 3.155\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.128, Test MSE 3.155\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.128, Test MSE 3.154\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.128, Test MSE 3.154\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 0.100, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 3.128, Test MSE 3.154\n",
      "TRAINING MODEL dt_norm_2_23\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 35333\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 0.184, Test 0.242\n",
      "MSE NON-NORMALIZED: Train MSE 11.209, Test MSE 5.586\n",
      "Epoch 25, lr 4.25e-05\n",
      "Epoch 25: Train 0.123, Test 0.135\n",
      "MSE NON-NORMALIZED: Train MSE 3.847, Test MSE 3.378\n",
      "Epoch 50, lr 1.0625e-05\n",
      "Epoch 50: Train 0.124, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.749, Test MSE 3.303\n",
      "Epoch 75, lr 1.328125e-06\n",
      "Epoch 75: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.737, Test MSE 3.299\n",
      "Epoch 100, lr 3.3203125e-07\n",
      "Epoch 100: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.734, Test MSE 3.299\n",
      "Epoch 125, lr 8.30078125e-08\n",
      "Epoch 125: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.749, Test MSE 3.425\n",
      "Epoch 150, lr 2.0751953125e-08\n",
      "Epoch 150: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.763, Test MSE 3.547\n",
      "Epoch 175, lr 1.03759765625e-08\n",
      "Epoch 175: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.777, Test MSE 3.668\n",
      "Epoch 200, lr 1.03759765625e-08\n",
      "Epoch 200: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.791, Test MSE 3.787\n",
      "Epoch 225, lr 1.03759765625e-08\n",
      "Epoch 225: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.790, Test MSE 3.784\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.789, Test MSE 3.782\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.788, Test MSE 3.780\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.788, Test MSE 3.779\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.787, Test MSE 3.778\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.786, Test MSE 3.777\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.786, Test MSE 3.776\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 0.123, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.785, Test MSE 3.775\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 0.122, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.785, Test MSE 3.774\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 0.122, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.784, Test MSE 3.773\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 0.122, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 3.784, Test MSE 3.773\n",
      "TRAINING MODEL dt_norm_2_25\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 21845\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 0.141, Test 0.152\n",
      "MSE NON-NORMALIZED: Train MSE 7.901, Test MSE 2.861\n",
      "Epoch 25, lr 4.25e-05\n",
      "Epoch 25: Train 0.080, Test 0.082\n",
      "MSE NON-NORMALIZED: Train MSE 2.263, Test MSE 1.591\n",
      "Epoch 50, lr 5.3125e-06\n",
      "Epoch 50: Train 0.077, Test 0.081\n",
      "MSE NON-NORMALIZED: Train MSE 2.244, Test MSE 1.558\n",
      "Epoch 75, lr 1.328125e-06\n",
      "Epoch 75: Train 0.077, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.237, Test MSE 1.552\n",
      "Epoch 100, lr 3.3203125e-07\n",
      "Epoch 100: Train 0.077, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.237, Test MSE 1.552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125, lr 8.30078125e-08\n",
      "Epoch 125: Train 0.077, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.249, Test MSE 1.635\n",
      "Epoch 150, lr 2.0751953125e-08\n",
      "Epoch 150: Train 0.077, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.261, Test MSE 1.716\n",
      "Epoch 175, lr 1.03759765625e-08\n",
      "Epoch 175: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.273, Test MSE 1.795\n",
      "Epoch 200, lr 1.03759765625e-08\n",
      "Epoch 200: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.284, Test MSE 1.872\n",
      "Epoch 225, lr 1.03759765625e-08\n",
      "Epoch 225: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.283, Test MSE 1.868\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.282, Test MSE 1.866\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.282, Test MSE 1.864\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.281, Test MSE 1.863\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.280, Test MSE 1.861\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.279, Test MSE 1.860\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.279, Test MSE 1.859\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.278, Test MSE 1.858\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.277, Test MSE 1.857\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.277, Test MSE 1.856\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 0.076, Test 0.080\n",
      "MSE NON-NORMALIZED: Train MSE 2.276, Test MSE 1.855\n",
      "TRAINING MODEL dt_norm_3_3\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 190628\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 6.867, Test 7.819\n",
      "MSE NON-NORMALIZED: Train MSE 387.962, Test MSE 212.747\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 2.496, Test 2.882\n",
      "MSE NON-NORMALIZED: Train MSE 80.322, Test MSE 79.028\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 2.240, Test 2.621\n",
      "MSE NON-NORMALIZED: Train MSE 74.660, Test MSE 71.502\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 2.151, Test 2.504\n",
      "MSE NON-NORMALIZED: Train MSE 71.148, Test MSE 69.131\n",
      "Epoch 100, lr 4.25e-05\n",
      "Epoch 100: Train 2.071, Test 2.414\n",
      "MSE NON-NORMALIZED: Train MSE 67.827, Test MSE 66.133\n",
      "Epoch 125, lr 1.0625e-05\n",
      "Epoch 125: Train 2.048, Test 2.388\n",
      "MSE NON-NORMALIZED: Train MSE 66.962, Test MSE 67.347\n",
      "Epoch 150, lr 1.0625e-05\n",
      "Epoch 150: Train 2.036, Test 2.383\n",
      "MSE NON-NORMALIZED: Train MSE 66.958, Test MSE 69.383\n",
      "Epoch 175, lr 2.65625e-06\n",
      "Epoch 175: Train 2.031, Test 2.378\n",
      "MSE NON-NORMALIZED: Train MSE 66.883, Test MSE 71.347\n",
      "Epoch 200, lr 6.640625e-07\n",
      "Epoch 200: Train 2.030, Test 2.377\n",
      "MSE NON-NORMALIZED: Train MSE 66.958, Test MSE 73.442\n",
      "Epoch 225, lr 1.66015625e-07\n",
      "Epoch 225: Train 2.030, Test 2.377\n",
      "MSE NON-NORMALIZED: Train MSE 66.948, Test MSE 73.434\n",
      "Epoch 250, lr 2.0751953125e-08\n",
      "Epoch 250: Train 2.030, Test 2.377\n",
      "MSE NON-NORMALIZED: Train MSE 66.945, Test MSE 73.432\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 2.030, Test 2.376\n",
      "MSE NON-NORMALIZED: Train MSE 66.944, Test MSE 73.431\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 2.029, Test 2.376\n",
      "MSE NON-NORMALIZED: Train MSE 66.943, Test MSE 73.430\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 2.029, Test 2.376\n",
      "MSE NON-NORMALIZED: Train MSE 66.942, Test MSE 73.430\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 2.029, Test 2.376\n",
      "MSE NON-NORMALIZED: Train MSE 66.941, Test MSE 73.430\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 2.029, Test 2.376\n",
      "MSE NON-NORMALIZED: Train MSE 66.940, Test MSE 73.429\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 2.029, Test 2.376\n",
      "MSE NON-NORMALIZED: Train MSE 66.940, Test MSE 73.429\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 2.029, Test 2.376\n",
      "MSE NON-NORMALIZED: Train MSE 66.939, Test MSE 73.429\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 2.029, Test 2.376\n",
      "MSE NON-NORMALIZED: Train MSE 66.938, Test MSE 73.428\n",
      "MSE of 29.577587127685547 was larger than initial of 11.078178416942597 and was not saved\n",
      "TRAINING MODEL dt_norm_3_5\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 198000\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 12.781, Test 13.865\n",
      "MSE NON-NORMALIZED: Train MSE 1214.529, Test MSE 665.003\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 5.332, Test 5.644\n",
      "MSE NON-NORMALIZED: Train MSE 270.991, Test MSE 258.948\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 4.129, Test 5.052\n",
      "MSE NON-NORMALIZED: Train MSE 249.680, Test MSE 229.981\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 3.817, Test 4.326\n",
      "MSE NON-NORMALIZED: Train MSE 207.901, Test MSE 194.868\n",
      "Epoch 100, lr 8.5e-05\n",
      "Epoch 100: Train 3.749, Test 4.234\n",
      "MSE NON-NORMALIZED: Train MSE 229.698, Test MSE 189.120\n",
      "Epoch 125, lr 8.5e-05\n",
      "Epoch 125: Train 4.008, Test 4.414\n",
      "MSE NON-NORMALIZED: Train MSE 186.294, Test MSE 198.686\n",
      "Epoch 150, lr 4.25e-05\n",
      "Epoch 150: Train 3.504, Test 3.930\n",
      "MSE NON-NORMALIZED: Train MSE 182.297, Test MSE 177.587\n",
      "Epoch 175, lr 2.125e-05\n",
      "Epoch 175: Train 3.372, Test 3.837\n",
      "MSE NON-NORMALIZED: Train MSE 172.972, Test MSE 177.098\n",
      "Epoch 200, lr 2.125e-05\n",
      "Epoch 200: Train 3.323, Test 3.776\n",
      "MSE NON-NORMALIZED: Train MSE 171.083, Test MSE 177.845\n",
      "Epoch 225, lr 2.125e-05\n",
      "Epoch 225: Train 3.308, Test 3.772\n",
      "MSE NON-NORMALIZED: Train MSE 170.567, Test MSE 178.315\n",
      "Epoch 250, lr 2.125e-05\n",
      "Epoch 250: Train 3.298, Test 3.756\n",
      "MSE NON-NORMALIZED: Train MSE 170.381, Test MSE 177.499\n",
      "Epoch 275, lr 2.125e-05\n",
      "Epoch 275: Train 3.297, Test 3.752\n",
      "MSE NON-NORMALIZED: Train MSE 169.890, Test MSE 177.931\n",
      "Epoch 300, lr 1.0625e-05\n",
      "Epoch 300: Train 3.272, Test 3.725\n",
      "MSE NON-NORMALIZED: Train MSE 168.964, Test MSE 176.381\n",
      "Epoch 325, lr 1.0625e-05\n",
      "Epoch 325: Train 3.265, Test 3.717\n",
      "MSE NON-NORMALIZED: Train MSE 168.534, Test MSE 176.266\n",
      "Epoch 350, lr 1.0625e-05\n",
      "Epoch 350: Train 3.260, Test 3.712\n",
      "MSE NON-NORMALIZED: Train MSE 168.497, Test MSE 176.125\n",
      "Epoch 375, lr 1.0625e-05\n",
      "Epoch 375: Train 3.255, Test 3.709\n",
      "MSE NON-NORMALIZED: Train MSE 168.338, Test MSE 176.027\n",
      "Epoch 400, lr 5.3125e-06\n",
      "Epoch 400: Train 3.250, Test 3.703\n",
      "MSE NON-NORMALIZED: Train MSE 168.037, Test MSE 175.850\n",
      "Epoch 425, lr 5.3125e-06\n",
      "Epoch 425: Train 3.247, Test 3.700\n",
      "MSE NON-NORMALIZED: Train MSE 167.991, Test MSE 175.765\n",
      "Epoch 450, lr 5.3125e-06\n",
      "Epoch 450: Train 3.246, Test 3.696\n",
      "MSE NON-NORMALIZED: Train MSE 167.871, Test MSE 175.649\n",
      "Epoch 475, lr 2.65625e-06\n",
      "Epoch 475: Train 3.244, Test 3.693\n",
      "MSE NON-NORMALIZED: Train MSE 167.719, Test MSE 175.513\n",
      "MSE of 45.92087173461914 was larger than initial of 19.848587943054202 and was not saved\n",
      "TRAINING MODEL dt_norm_3_7\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 160050\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 14.467, Test 13.393\n",
      "MSE NON-NORMALIZED: Train MSE 1805.443, Test MSE 806.565\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 6.370, Test 4.805\n",
      "MSE NON-NORMALIZED: Train MSE 337.649, Test MSE 313.460\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 6.074, Test 4.209\n",
      "MSE NON-NORMALIZED: Train MSE 248.114, Test MSE 220.022\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 5.905, Test 4.110\n",
      "MSE NON-NORMALIZED: Train MSE 250.683, Test MSE 220.201\n",
      "Epoch 100, lr 8.5e-05\n",
      "Epoch 100: Train 5.724, Test 3.911\n",
      "MSE NON-NORMALIZED: Train MSE 225.880, Test MSE 210.050\n",
      "Epoch 125, lr 8.5e-05\n",
      "Epoch 125: Train 5.612, Test 3.852\n",
      "MSE NON-NORMALIZED: Train MSE 237.235, Test MSE 208.039\n",
      "Epoch 150, lr 8.5e-05\n",
      "Epoch 150: Train 5.433, Test 3.699\n",
      "MSE NON-NORMALIZED: Train MSE 210.164, Test MSE 197.321\n",
      "Epoch 175, lr 8.5e-05\n",
      "Epoch 175: Train 4.984, Test 3.544\n",
      "MSE NON-NORMALIZED: Train MSE 198.881, Test MSE 188.014\n",
      "Epoch 200, lr 4.25e-05\n",
      "Epoch 200: Train 4.926, Test 3.495\n",
      "MSE NON-NORMALIZED: Train MSE 186.951, Test MSE 186.414\n",
      "Epoch 225, lr 2.125e-05\n",
      "Epoch 225: Train 4.900, Test 3.468\n",
      "MSE NON-NORMALIZED: Train MSE 184.332, Test MSE 184.746\n",
      "Epoch 250, lr 1.0625e-05\n",
      "Epoch 250: Train 4.890, Test 3.457\n",
      "MSE NON-NORMALIZED: Train MSE 181.673, Test MSE 184.485\n",
      "Epoch 275, lr 5.3125e-06\n",
      "Epoch 275: Train 4.885, Test 3.451\n",
      "MSE NON-NORMALIZED: Train MSE 181.195, Test MSE 184.320\n",
      "Epoch 300, lr 1.328125e-06\n",
      "Epoch 300: Train 4.882, Test 3.448\n",
      "MSE NON-NORMALIZED: Train MSE 181.010, Test MSE 184.238\n",
      "Epoch 325, lr 3.3203125e-07\n",
      "Epoch 325: Train 4.881, Test 3.447\n",
      "MSE NON-NORMALIZED: Train MSE 180.976, Test MSE 184.212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350, lr 8.30078125e-08\n",
      "Epoch 350: Train 4.881, Test 3.447\n",
      "MSE NON-NORMALIZED: Train MSE 180.968, Test MSE 184.206\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 4.881, Test 3.447\n",
      "MSE NON-NORMALIZED: Train MSE 180.965, Test MSE 184.204\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 4.881, Test 3.447\n",
      "MSE NON-NORMALIZED: Train MSE 180.963, Test MSE 184.204\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 4.881, Test 3.447\n",
      "MSE NON-NORMALIZED: Train MSE 180.962, Test MSE 184.203\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 4.881, Test 3.447\n",
      "MSE NON-NORMALIZED: Train MSE 180.960, Test MSE 184.203\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 4.881, Test 3.447\n",
      "MSE NON-NORMALIZED: Train MSE 180.959, Test MSE 184.202\n",
      "MSE of 42.903743743896484 was larger than initial of 27.628071281707765 and was not saved\n",
      "TRAINING MODEL dt_norm_3_9\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 142159\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 17.329, Test 12.523\n",
      "MSE NON-NORMALIZED: Train MSE 1858.339, Test MSE 905.572\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 9.714, Test 5.733\n",
      "MSE NON-NORMALIZED: Train MSE 334.047, Test MSE 304.485\n",
      "Epoch 50, lr 4.25e-05\n",
      "Epoch 50: Train 9.544, Test 5.423\n",
      "MSE NON-NORMALIZED: Train MSE 302.774, Test MSE 293.672\n",
      "Epoch 75, lr 4.25e-05\n",
      "Epoch 75: Train 9.356, Test 5.103\n",
      "MSE NON-NORMALIZED: Train MSE 294.040, Test MSE 284.901\n",
      "Epoch 100, lr 4.25e-05\n",
      "Epoch 100: Train 9.124, Test 4.750\n",
      "MSE NON-NORMALIZED: Train MSE 285.267, Test MSE 277.219\n",
      "Epoch 125, lr 2.125e-05\n",
      "Epoch 125: Train 9.076, Test 4.701\n",
      "MSE NON-NORMALIZED: Train MSE 277.849, Test MSE 276.137\n",
      "Epoch 150, lr 5.3125e-06\n",
      "Epoch 150: Train 9.059, Test 4.685\n",
      "MSE NON-NORMALIZED: Train MSE 276.049, Test MSE 278.266\n",
      "Epoch 175, lr 5.3125e-06\n",
      "Epoch 175: Train 9.041, Test 4.676\n",
      "MSE NON-NORMALIZED: Train MSE 274.889, Test MSE 279.519\n",
      "Epoch 200, lr 1.328125e-06\n",
      "Epoch 200: Train 9.034, Test 4.645\n",
      "MSE NON-NORMALIZED: Train MSE 273.727, Test MSE 280.759\n",
      "Epoch 225, lr 3.3203125e-07\n",
      "Epoch 225: Train 9.033, Test 4.641\n",
      "MSE NON-NORMALIZED: Train MSE 273.618, Test MSE 280.667\n",
      "Epoch 250, lr 8.30078125e-08\n",
      "Epoch 250: Train 9.032, Test 4.641\n",
      "MSE NON-NORMALIZED: Train MSE 273.598, Test MSE 280.649\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 9.032, Test 4.641\n",
      "MSE NON-NORMALIZED: Train MSE 273.593, Test MSE 280.645\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 9.032, Test 4.640\n",
      "MSE NON-NORMALIZED: Train MSE 273.591, Test MSE 280.643\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 9.032, Test 4.640\n",
      "MSE NON-NORMALIZED: Train MSE 273.589, Test MSE 280.642\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 9.032, Test 4.640\n",
      "MSE NON-NORMALIZED: Train MSE 273.587, Test MSE 280.641\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 9.032, Test 4.640\n",
      "MSE NON-NORMALIZED: Train MSE 273.585, Test MSE 280.640\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 9.032, Test 4.640\n",
      "MSE NON-NORMALIZED: Train MSE 273.584, Test MSE 280.639\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 9.032, Test 4.640\n",
      "MSE NON-NORMALIZED: Train MSE 273.582, Test MSE 280.638\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 9.032, Test 4.640\n",
      "MSE NON-NORMALIZED: Train MSE 273.581, Test MSE 280.637\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 9.032, Test 4.640\n",
      "MSE NON-NORMALIZED: Train MSE 273.579, Test MSE 280.636\n",
      "MSE of 57.7547492980957 was larger than initial of 24.0630680131073 and was not saved\n",
      "TRAINING MODEL dt_norm_3_11\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 118323\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 4.046, Test 6.594\n",
      "MSE NON-NORMALIZED: Train MSE 627.682, Test MSE 253.590\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 1.260, Test 2.876\n",
      "MSE NON-NORMALIZED: Train MSE 139.051, Test MSE 129.752\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 1.222, Test 2.678\n",
      "MSE NON-NORMALIZED: Train MSE 134.887, Test MSE 125.334\n",
      "Epoch 75, lr 4.25e-05\n",
      "Epoch 75: Train 1.192, Test 2.609\n",
      "MSE NON-NORMALIZED: Train MSE 129.612, Test MSE 124.876\n",
      "Epoch 100, lr 4.25e-05\n",
      "Epoch 100: Train 1.213, Test 2.190\n",
      "MSE NON-NORMALIZED: Train MSE 109.737, Test MSE 105.216\n",
      "Epoch 125, lr 1.0625e-05\n",
      "Epoch 125: Train 1.177, Test 2.157\n",
      "MSE NON-NORMALIZED: Train MSE 104.999, Test MSE 103.883\n",
      "Epoch 150, lr 1.328125e-06\n",
      "Epoch 150: Train 1.169, Test 2.149\n",
      "MSE NON-NORMALIZED: Train MSE 104.592, Test MSE 105.100\n",
      "Epoch 175, lr 3.3203125e-07\n",
      "Epoch 175: Train 1.167, Test 2.147\n",
      "MSE NON-NORMALIZED: Train MSE 104.629, Test MSE 106.512\n",
      "Epoch 200, lr 8.30078125e-08\n",
      "Epoch 200: Train 1.166, Test 2.147\n",
      "MSE NON-NORMALIZED: Train MSE 104.713, Test MSE 107.961\n",
      "Epoch 225, lr 2.0751953125e-08\n",
      "Epoch 225: Train 1.166, Test 2.146\n",
      "MSE NON-NORMALIZED: Train MSE 104.709, Test MSE 107.957\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 1.166, Test 2.146\n",
      "MSE NON-NORMALIZED: Train MSE 104.707, Test MSE 107.956\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 1.166, Test 2.146\n",
      "MSE NON-NORMALIZED: Train MSE 104.706, Test MSE 107.955\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 1.166, Test 2.146\n",
      "MSE NON-NORMALIZED: Train MSE 104.705, Test MSE 107.955\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 1.166, Test 2.146\n",
      "MSE NON-NORMALIZED: Train MSE 104.704, Test MSE 107.954\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 1.166, Test 2.146\n",
      "MSE NON-NORMALIZED: Train MSE 104.703, Test MSE 107.954\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 1.166, Test 2.146\n",
      "MSE NON-NORMALIZED: Train MSE 104.702, Test MSE 107.953\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 1.166, Test 2.146\n",
      "MSE NON-NORMALIZED: Train MSE 104.701, Test MSE 107.953\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 1.166, Test 2.146\n",
      "MSE NON-NORMALIZED: Train MSE 104.700, Test MSE 107.952\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 1.165, Test 2.146\n",
      "MSE NON-NORMALIZED: Train MSE 104.699, Test MSE 107.952\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 1.165, Test 2.146\n",
      "MSE NON-NORMALIZED: Train MSE 104.698, Test MSE 107.951\n",
      "MSE of 26.71274757385254 was larger than initial of 17.183335281097413 and was not saved\n",
      "TRAINING MODEL dt_norm_3_13\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 86966\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 4.677, Test 5.934\n",
      "MSE NON-NORMALIZED: Train MSE 536.096, Test MSE 190.810\n",
      "Epoch 25, lr 2.125e-05\n",
      "Epoch 25: Train 2.180, Test 2.309\n",
      "MSE NON-NORMALIZED: Train MSE 113.475, Test MSE 110.769\n",
      "Epoch 50, lr 2.125e-05\n",
      "Epoch 50: Train 1.676, Test 1.895\n",
      "MSE NON-NORMALIZED: Train MSE 69.853, Test MSE 68.905\n",
      "Epoch 75, lr 2.125e-05\n",
      "Epoch 75: Train 1.625, Test 1.841\n",
      "MSE NON-NORMALIZED: Train MSE 68.803, Test MSE 66.482\n",
      "Epoch 100, lr 1.0625e-05\n",
      "Epoch 100: Train 1.610, Test 1.815\n",
      "MSE NON-NORMALIZED: Train MSE 67.622, Test MSE 65.485\n",
      "Epoch 125, lr 2.65625e-06\n",
      "Epoch 125: Train 1.603, Test 1.798\n",
      "MSE NON-NORMALIZED: Train MSE 67.140, Test MSE 66.243\n",
      "Epoch 150, lr 6.640625e-07\n",
      "Epoch 150: Train 1.601, Test 1.795\n",
      "MSE NON-NORMALIZED: Train MSE 67.139, Test MSE 67.364\n",
      "Epoch 175, lr 1.66015625e-07\n",
      "Epoch 175: Train 1.601, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.201, Test MSE 68.524\n",
      "Epoch 200, lr 4.150390625e-08\n",
      "Epoch 200: Train 1.601, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.287, Test MSE 69.700\n",
      "Epoch 225, lr 1.03759765625e-08\n",
      "Epoch 225: Train 1.601, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.285, Test MSE 69.699\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 1.601, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.284, Test MSE 69.698\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 1.601, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.282, Test MSE 69.697\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 1.601, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.281, Test MSE 69.697\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 1.601, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.280, Test MSE 69.696\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 1.600, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.279, Test MSE 69.695\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 1.600, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.278, Test MSE 69.695\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 1.600, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.277, Test MSE 69.694\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 1.600, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.276, Test MSE 69.693\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 1.600, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.275, Test MSE 69.693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 1.600, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 67.274, Test MSE 69.692\n",
      "MSE of 22.328418731689453 was larger than initial of 15.67660311103821 and was not saved\n",
      "TRAINING MODEL dt_norm_3_15\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 90510\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 3.196, Test 4.340\n",
      "MSE NON-NORMALIZED: Train MSE 318.183, Test MSE 122.662\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 1.546, Test 1.771\n",
      "MSE NON-NORMALIZED: Train MSE 58.724, Test MSE 56.861\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 1.651, Test 1.737\n",
      "MSE NON-NORMALIZED: Train MSE 56.239, Test MSE 56.948\n",
      "Epoch 75, lr 4.25e-05\n",
      "Epoch 75: Train 1.405, Test 1.647\n",
      "MSE NON-NORMALIZED: Train MSE 55.156, Test MSE 53.899\n",
      "Epoch 100, lr 2.125e-05\n",
      "Epoch 100: Train 1.385, Test 1.387\n",
      "MSE NON-NORMALIZED: Train MSE 44.669, Test MSE 43.530\n",
      "Epoch 125, lr 5.3125e-06\n",
      "Epoch 125: Train 1.379, Test 1.356\n",
      "MSE NON-NORMALIZED: Train MSE 43.943, Test MSE 43.863\n",
      "Epoch 150, lr 1.328125e-06\n",
      "Epoch 150: Train 1.379, Test 1.355\n",
      "MSE NON-NORMALIZED: Train MSE 43.976, Test MSE 44.920\n",
      "Epoch 175, lr 1.66015625e-07\n",
      "Epoch 175: Train 1.378, Test 1.355\n",
      "MSE NON-NORMALIZED: Train MSE 44.047, Test MSE 45.999\n",
      "Epoch 200, lr 4.150390625e-08\n",
      "Epoch 200: Train 1.378, Test 1.355\n",
      "MSE NON-NORMALIZED: Train MSE 44.126, Test MSE 47.081\n",
      "Epoch 225, lr 1.03759765625e-08\n",
      "Epoch 225: Train 1.378, Test 1.354\n",
      "MSE NON-NORMALIZED: Train MSE 44.125, Test MSE 47.079\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 1.378, Test 1.354\n",
      "MSE NON-NORMALIZED: Train MSE 44.124, Test MSE 47.079\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 1.378, Test 1.354\n",
      "MSE NON-NORMALIZED: Train MSE 44.123, Test MSE 47.078\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 1.378, Test 1.354\n",
      "MSE NON-NORMALIZED: Train MSE 44.122, Test MSE 47.077\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 1.378, Test 1.354\n",
      "MSE NON-NORMALIZED: Train MSE 44.122, Test MSE 47.077\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 1.378, Test 1.354\n",
      "MSE NON-NORMALIZED: Train MSE 44.121, Test MSE 47.077\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 1.378, Test 1.354\n",
      "MSE NON-NORMALIZED: Train MSE 44.121, Test MSE 47.076\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 1.378, Test 1.354\n",
      "MSE NON-NORMALIZED: Train MSE 44.120, Test MSE 47.076\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 1.378, Test 1.354\n",
      "MSE NON-NORMALIZED: Train MSE 44.119, Test MSE 47.075\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 1.378, Test 1.354\n",
      "MSE NON-NORMALIZED: Train MSE 44.119, Test MSE 47.075\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 1.378, Test 1.354\n",
      "MSE NON-NORMALIZED: Train MSE 44.118, Test MSE 47.075\n",
      "MSE of 16.856721878051758 was larger than initial of 10.653197844898225 and was not saved\n",
      "TRAINING MODEL dt_norm_3_17\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 70681\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 3.199, Test 3.966\n",
      "MSE NON-NORMALIZED: Train MSE 236.983, Test MSE 113.662\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 2.044, Test 1.604\n",
      "MSE NON-NORMALIZED: Train MSE 55.647, Test MSE 53.816\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 1.980, Test 1.524\n",
      "MSE NON-NORMALIZED: Train MSE 53.004, Test MSE 51.615\n",
      "Epoch 75, lr 2.125e-05\n",
      "Epoch 75: Train 1.961, Test 1.509\n",
      "MSE NON-NORMALIZED: Train MSE 52.339, Test MSE 51.208\n",
      "Epoch 100, lr 1.0625e-05\n",
      "Epoch 100: Train 1.959, Test 1.506\n",
      "MSE NON-NORMALIZED: Train MSE 52.248, Test MSE 51.145\n",
      "Epoch 125, lr 2.65625e-06\n",
      "Epoch 125: Train 1.958, Test 1.489\n",
      "MSE NON-NORMALIZED: Train MSE 51.876, Test MSE 51.652\n",
      "Epoch 150, lr 6.640625e-07\n",
      "Epoch 150: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 51.935, Test MSE 52.571\n",
      "Epoch 175, lr 1.66015625e-07\n",
      "Epoch 175: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.010, Test MSE 53.500\n",
      "Epoch 200, lr 4.150390625e-08\n",
      "Epoch 200: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.089, Test MSE 54.428\n",
      "Epoch 225, lr 1.03759765625e-08\n",
      "Epoch 225: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.088, Test MSE 54.427\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.087, Test MSE 54.427\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.087, Test MSE 54.427\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.086, Test MSE 54.426\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.086, Test MSE 54.426\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.085, Test MSE 54.426\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.085, Test MSE 54.426\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.085, Test MSE 54.425\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.084, Test MSE 54.425\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.084, Test MSE 54.425\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 1.957, Test 1.488\n",
      "MSE NON-NORMALIZED: Train MSE 52.083, Test MSE 54.425\n",
      "MSE of 18.52094268798828 was larger than initial of 9.346070140514374 and was not saved\n",
      "TRAINING MODEL dt_norm_3_19\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 67884\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 2.254, Test 4.440\n",
      "MSE NON-NORMALIZED: Train MSE 220.663, Test MSE 136.926\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 1.232, Test 2.288\n",
      "MSE NON-NORMALIZED: Train MSE 80.804, Test MSE 79.383\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 0.685, Test 1.758\n",
      "MSE NON-NORMALIZED: Train MSE 64.992, Test MSE 63.835\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 0.667, Test 1.744\n",
      "MSE NON-NORMALIZED: Train MSE 64.551, Test MSE 63.653\n",
      "Epoch 100, lr 4.25e-05\n",
      "Epoch 100: Train 0.658, Test 1.723\n",
      "MSE NON-NORMALIZED: Train MSE 64.089, Test MSE 62.978\n",
      "Epoch 125, lr 1.0625e-05\n",
      "Epoch 125: Train 0.656, Test 1.717\n",
      "MSE NON-NORMALIZED: Train MSE 64.025, Test MSE 63.641\n",
      "Epoch 150, lr 2.65625e-06\n",
      "Epoch 150: Train 0.655, Test 1.716\n",
      "MSE NON-NORMALIZED: Train MSE 64.064, Test MSE 64.459\n",
      "Epoch 175, lr 6.640625e-07\n",
      "Epoch 175: Train 0.655, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.131, Test MSE 65.307\n",
      "Epoch 200, lr 8.30078125e-08\n",
      "Epoch 200: Train 0.654, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.203, Test MSE 66.156\n",
      "Epoch 225, lr 2.0751953125e-08\n",
      "Epoch 225: Train 0.654, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.202, Test MSE 66.155\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 0.654, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.201, Test MSE 66.155\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 0.654, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.201, Test MSE 66.155\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 0.654, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.200, Test MSE 66.154\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 0.654, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.200, Test MSE 66.154\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 0.654, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.199, Test MSE 66.154\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 0.654, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.199, Test MSE 66.154\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 0.654, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.198, Test MSE 66.154\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 0.654, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.198, Test MSE 66.153\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 0.654, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.198, Test MSE 66.153\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 0.654, Test 1.715\n",
      "MSE NON-NORMALIZED: Train MSE 64.197, Test MSE 66.153\n",
      "MSE of 21.349559783935547 was larger than initial of 9.537277938869478 and was not saved\n",
      "TRAINING MODEL dt_norm_3_21\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 53601\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 2.905, Test 3.047\n",
      "MSE NON-NORMALIZED: Train MSE 163.316, Test MSE 72.246\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 0.783, Test 1.529\n",
      "MSE NON-NORMALIZED: Train MSE 37.336, Test MSE 36.000\n",
      "Epoch 50, lr 4.25e-05\n",
      "Epoch 50: Train 0.770, Test 1.510\n",
      "MSE NON-NORMALIZED: Train MSE 36.383, Test MSE 35.585\n",
      "Epoch 75, lr 4.25e-05\n",
      "Epoch 75: Train 0.757, Test 1.496\n",
      "MSE NON-NORMALIZED: Train MSE 36.156, Test MSE 35.287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, lr 4.25e-05\n",
      "Epoch 100: Train 0.754, Test 1.493\n",
      "MSE NON-NORMALIZED: Train MSE 35.970, Test MSE 35.253\n",
      "Epoch 125, lr 1.0625e-05\n",
      "Epoch 125: Train 0.750, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 35.967, Test MSE 35.868\n",
      "Epoch 150, lr 2.65625e-06\n",
      "Epoch 150: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.016, Test MSE 36.586\n",
      "Epoch 175, lr 3.3203125e-07\n",
      "Epoch 175: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.083, Test MSE 37.309\n",
      "Epoch 200, lr 8.30078125e-08\n",
      "Epoch 200: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.154, Test MSE 38.031\n",
      "Epoch 225, lr 2.0751953125e-08\n",
      "Epoch 225: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.153, Test MSE 38.030\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.153, Test MSE 38.029\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.153, Test MSE 38.029\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.152, Test MSE 38.029\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.152, Test MSE 38.029\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.152, Test MSE 38.028\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.152, Test MSE 38.028\n",
      "Epoch 400, lr 1.03759765625e-08\n",
      "Epoch 400: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.152, Test MSE 38.028\n",
      "Epoch 425, lr 1.03759765625e-08\n",
      "Epoch 425: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.151, Test MSE 38.028\n",
      "Epoch 450, lr 1.03759765625e-08\n",
      "Epoch 450: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.151, Test MSE 38.028\n",
      "Epoch 475, lr 1.03759765625e-08\n",
      "Epoch 475: Train 0.749, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 36.151, Test MSE 38.028\n",
      "MSE of 18.54151153564453 was larger than initial of 12.682458969749451 and was not saved\n",
      "TRAINING MODEL dt_norm_3_23\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 51623\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 4.019, Test 3.953\n",
      "MSE NON-NORMALIZED: Train MSE 219.898, Test MSE 139.051\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 3.185, Test 2.542\n",
      "MSE NON-NORMALIZED: Train MSE 107.389, Test MSE 106.765\n",
      "Epoch 50, lr 4.25e-05\n",
      "Epoch 50: Train 3.176, Test 2.485\n",
      "MSE NON-NORMALIZED: Train MSE 105.820, Test MSE 105.250\n",
      "Epoch 75, lr 2.125e-05\n",
      "Epoch 75: Train 3.173, Test 2.480\n",
      "MSE NON-NORMALIZED: Train MSE 105.706, Test MSE 105.106\n",
      "Epoch 100, lr 5.3125e-06\n",
      "Epoch 100: Train 3.167, Test 2.476\n",
      "MSE NON-NORMALIZED: Train MSE 105.650, Test MSE 104.997\n",
      "Epoch 125, lr 6.640625e-07\n",
      "Epoch 125: Train 3.166, Test 2.475\n",
      "MSE NON-NORMALIZED: Train MSE 105.707, Test MSE 105.718\n",
      "Epoch 150, lr 1.66015625e-07\n",
      "Epoch 150: Train 3.166, Test 2.475\n",
      "MSE NON-NORMALIZED: Train MSE 105.777, Test MSE 106.456\n"
     ]
    }
   ],
   "source": [
    "ae_train.retrain_models(data,\n",
    "                        stats_per,\n",
    "             override = False,\n",
    "             mse_threshold = 5,\n",
    "             model_params = 'retrain',\n",
    "             epochs = 500, \n",
    "             lr = 8.5e-5,\n",
    "             max_dt_size = 200000,\n",
    "             dir_label = 'wafer_layer_split_mip_std_1_mean_nonzero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09c9a370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dt_norm_3_36 is being retrained\n",
      "Model dt_norm_3_30 is being retrained\n",
      "Model dt_norm_3_31 is being retrained\n",
      "Model dt_norm_3_33 is being retrained\n",
      "Model dt_norm_3_35 is being retrained\n",
      "Model dt_norm_3_37 is being retrained\n",
      "Model dt_norm_3_32 is being retrained\n",
      "Model dt_norm_3_34 is being retrained\n",
      "Model dt_norm_3_38 is being retrained\n",
      "Model dt_norm_3_39 is being retrained\n",
      "Model dt_norm_3_40 is being retrained\n",
      "Model dt_norm_3_41 is being retrained\n",
      "Model dt_norm_3_42 is being retrained\n",
      "Model dt_norm_3_43 is being retrained\n",
      "Model dt_norm_3_44 is being retrained\n",
      "Model dt_norm_3_45 is being retrained\n",
      "Model dt_norm_3_46 is being retrained\n",
      "Model dt_norm_3_47 is being retrained\n",
      "TRAINING MODEL dt_norm_3_36\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 9900\n",
      "Epoch 0, lr 4.5e-07\n",
      "Epoch 0: Train 2.380, Test 3.867\n",
      "MSE NON-NORMALIZED: Train MSE 69.269, Test MSE 67.813\n",
      "MSE of 45.210750579833984 was larger than initial of 1.0381478893504144 and was not saved\n",
      "TRAINING MODEL dt_norm_3_30\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 9900\n",
      "Epoch 0, lr 4.5e-07\n",
      "Epoch 0: Train 6.986, Test 4.195\n",
      "MSE NON-NORMALIZED: Train MSE 108.030, Test MSE 103.552\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Now\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mae_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrain_models_specified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstats_per\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                         \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_36\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_30\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_31\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_33\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_35\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_37\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_34\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_38\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_39\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_40\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_41\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_42\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_43\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_44\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_45\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_46\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt_norm_3_47\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mappend_ReLU\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mpath_1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/high_layer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mpath_2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/high_layer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mpath_3\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/dt_3_high_occupancy_greater_7\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmax_dt_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4.5e-7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdir_label\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwafer_layer_split_mip_std_1_mean_nonzero\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/Notebooks/AE_Dev/ae_train.py:448\u001b[0m, in \u001b[0;36mretrain_models_specified\u001b[0;34m(data, mse, specified, loss, batch, override, model_params, append_ReLU, max_dt_size, epochs, path_1, path_2, path_3, lr, dir_label, path)\u001b[0m\n\u001b[1;32m    446\u001b[0m i\u001b[38;5;241m=\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m#Training mode\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m \u001b[43mretrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcur_mse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m              \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m              \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m              \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m              \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;66;03m#clear cuda after training each model\u001b[39;00m\n\u001b[1;32m    460\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/Notebooks/AE_Dev/ae_train.py:527\u001b[0m, in \u001b[0;36mretrain_model\u001b[0;34m(model, mse, dt, size_train, size_test, label, cur_directory, path, loss, num_epochs, lr, batch)\u001b[0m\n\u001b[1;32m    525\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    526\u001b[0m     batch_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 527\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(batch_loss)\n\u001b[1;32m    532\u001b[0m data_test \u001b[38;5;241m=\u001b[39m test\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/torch/optim/adam.py:283\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madam\u001b[39m(params: List[Tensor],\n\u001b[1;32m    258\u001b[0m          grads: List[Tensor],\n\u001b[1;32m    259\u001b[0m          exp_avgs: List[Tensor],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m          eps: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m    278\u001b[0m          maximize: \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m    279\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Functional API that performs Adam algorithm computation.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m    See :class:`~torch.optim.Adam` for details.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(t, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m state_steps):\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI has changed, `state_steps` argument must contain a list of singleton tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;66;03m# Placeholder for more complex foreach logic to be added when value is not set\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Now\n",
    "ae_train.retrain_models_specified(data,\n",
    "                        stats_per,\n",
    "                         ['dt_norm_3_36',\n",
    "                         'dt_norm_3_30',\n",
    "                         'dt_norm_3_31',\n",
    "                         'dt_norm_3_33',\n",
    "                         'dt_norm_3_35',\n",
    "                         'dt_norm_3_37',\n",
    "                         'dt_norm_3_32',\n",
    "                         'dt_norm_3_34',\n",
    "                         'dt_norm_3_38',\n",
    "                         'dt_norm_3_39',\n",
    "                         'dt_norm_3_40',\n",
    "                         'dt_norm_3_41',\n",
    "                         'dt_norm_3_42',\n",
    "                         'dt_norm_3_43',\n",
    "                         'dt_norm_3_44',\n",
    "                         'dt_norm_3_45',\n",
    "                         'dt_norm_3_46',\n",
    "                         'dt_norm_3_47'], \n",
    "                         model_params = [],\n",
    "                         append_ReLU = False,\n",
    "                         path_1 = 'models/high_layer',\n",
    "                         path_2 = 'models/high_layer',\n",
    "                         path_3 = 'models/dt_3_high_occupancy_greater_7',\n",
    "                         max_dt_size = 10000,\n",
    "                         epochs = 25,\n",
    "                         lr = 4.5e-7, \n",
    "                         dir_label = 'wafer_layer_split_mip_std_1_mean_nonzero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9a4b735",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_smol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_smol\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_smol' is not defined"
     ]
    }
   ],
   "source": [
    "    data_smol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d078bcfc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL dt_norm_3_36\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 38123\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 5.520, Test 5.067\n",
      "MSE NON-NORMALIZED: Train MSE 208.844, Test MSE 120.356\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 0.655, Test 1.838\n",
      "MSE NON-NORMALIZED: Train MSE 32.926, Test MSE 42.313\n",
      "Epoch 50, lr 0.0001125\n",
      "Epoch 50: Train 0.697, Test 0.900\n",
      "MSE NON-NORMALIZED: Train MSE 15.848, Test MSE 16.699\n",
      "Epoch 75, lr 5.625e-05\n",
      "Epoch 75: Train 0.743, Test 0.838\n",
      "MSE NON-NORMALIZED: Train MSE 13.842, Test MSE 15.685\n",
      "Epoch 100, lr 2.8125e-05\n",
      "Epoch 100: Train 0.583, Test 0.593\n",
      "MSE NON-NORMALIZED: Train MSE 10.649, Test MSE 10.259\n",
      "Epoch 125, lr 2.8125e-05\n",
      "Epoch 125: Train 0.517, Test 0.506\n",
      "MSE NON-NORMALIZED: Train MSE 8.838, Test MSE 8.885\n",
      "Epoch 150, lr 2.8125e-05\n",
      "Epoch 150: Train 0.471, Test 0.483\n",
      "MSE NON-NORMALIZED: Train MSE 8.450, Test MSE 8.757\n",
      "Epoch 175, lr 2.8125e-05\n",
      "Epoch 175: Train 0.438, Test 0.467\n",
      "MSE NON-NORMALIZED: Train MSE 8.250, Test MSE 8.745\n",
      "Epoch 200, lr 2.8125e-05\n",
      "Epoch 200: Train 0.419, Test 0.457\n",
      "MSE NON-NORMALIZED: Train MSE 8.118, Test MSE 8.818\n",
      "Epoch 225, lr 2.8125e-05\n",
      "Epoch 225: Train 0.412, Test 0.452\n",
      "MSE NON-NORMALIZED: Train MSE 7.985, Test MSE 8.777\n",
      "Epoch 250, lr 2.8125e-05\n",
      "Epoch 250: Train 0.407, Test 0.447\n",
      "MSE NON-NORMALIZED: Train MSE 7.920, Test MSE 8.677\n",
      "Epoch 275, lr 2.8125e-05\n",
      "Epoch 275: Train 0.405, Test 0.444\n",
      "MSE NON-NORMALIZED: Train MSE 7.873, Test MSE 8.644\n",
      "TRAINING MODEL dt_norm_3_30\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 15.022, Test 8.294\n",
      "MSE NON-NORMALIZED: Train MSE 428.971, Test MSE 274.222\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 1.904, Test 2.800\n",
      "MSE NON-NORMALIZED: Train MSE 79.196, Test MSE 78.462\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 1.632, Test 2.575\n",
      "MSE NON-NORMALIZED: Train MSE 74.877, Test MSE 72.978\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 1.508, Test 2.397\n",
      "MSE NON-NORMALIZED: Train MSE 70.457, Test MSE 69.038\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 1.384, Test 2.226\n",
      "MSE NON-NORMALIZED: Train MSE 66.753, Test MSE 65.405\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 1.345, Test 2.194\n",
      "MSE NON-NORMALIZED: Train MSE 66.062, Test MSE 65.269\n",
      "Epoch 150, lr 0.0001125\n",
      "Epoch 150: Train 1.317, Test 2.173\n",
      "MSE NON-NORMALIZED: Train MSE 65.604, Test MSE 65.345\n",
      "Epoch 175, lr 2.8125e-05\n",
      "Epoch 175: Train 1.306, Test 2.163\n",
      "MSE NON-NORMALIZED: Train MSE 65.240, Test MSE 65.698\n",
      "Epoch 200, lr 2.8125e-05\n",
      "Epoch 200: Train 1.210, Test 1.357\n",
      "MSE NON-NORMALIZED: Train MSE 36.596, Test MSE 32.224\n",
      "Epoch 225, lr 2.8125e-05\n",
      "Epoch 225: Train 1.107, Test 1.191\n",
      "MSE NON-NORMALIZED: Train MSE 28.060, Test MSE 28.119\n",
      "Epoch 250, lr 2.8125e-05\n",
      "Epoch 250: Train 1.026, Test 1.059\n",
      "MSE NON-NORMALIZED: Train MSE 24.906, Test MSE 25.100\n",
      "Epoch 275, lr 2.8125e-05\n",
      "Epoch 275: Train 0.905, Test 0.981\n",
      "MSE NON-NORMALIZED: Train MSE 23.221, Test MSE 23.480\n",
      "TRAINING MODEL dt_norm_3_31\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 8.915, Test 10.147\n",
      "MSE NON-NORMALIZED: Train MSE 532.283, Test MSE 363.781\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 3.993, Test 4.590\n",
      "MSE NON-NORMALIZED: Train MSE 142.557, Test MSE 130.364\n",
      "Epoch 50, lr 5.625e-05\n",
      "Epoch 50: Train 3.884, Test 3.572\n",
      "MSE NON-NORMALIZED: Train MSE 99.909, Test MSE 91.546\n",
      "Epoch 75, lr 5.625e-05\n",
      "Epoch 75: Train 2.379, Test 2.258\n",
      "MSE NON-NORMALIZED: Train MSE 57.761, Test MSE 50.416\n",
      "Epoch 100, lr 5.625e-05\n",
      "Epoch 100: Train 2.017, Test 2.162\n",
      "MSE NON-NORMALIZED: Train MSE 55.223, Test MSE 48.517\n",
      "Epoch 125, lr 5.625e-05\n",
      "Epoch 125: Train 1.875, Test 2.120\n",
      "MSE NON-NORMALIZED: Train MSE 53.077, Test MSE 48.381\n",
      "Epoch 150, lr 2.8125e-05\n",
      "Epoch 150: Train 1.781, Test 2.061\n",
      "MSE NON-NORMALIZED: Train MSE 51.481, Test MSE 47.659\n",
      "Epoch 175, lr 2.8125e-05\n",
      "Epoch 175: Train 1.432, Test 1.802\n",
      "MSE NON-NORMALIZED: Train MSE 44.234, Test MSE 41.449\n",
      "Epoch 200, lr 2.8125e-05\n",
      "Epoch 200: Train 1.366, Test 1.482\n",
      "MSE NON-NORMALIZED: Train MSE 35.451, Test MSE 33.899\n",
      "Epoch 225, lr 2.8125e-05\n",
      "Epoch 225: Train 1.337, Test 1.424\n",
      "MSE NON-NORMALIZED: Train MSE 34.558, Test MSE 32.402\n",
      "Epoch 250, lr 2.8125e-05\n",
      "Epoch 250: Train 1.299, Test 1.398\n",
      "MSE NON-NORMALIZED: Train MSE 34.258, Test MSE 31.930\n",
      "Epoch 275, lr 2.8125e-05\n",
      "Epoch 275: Train 1.342, Test 1.441\n",
      "MSE NON-NORMALIZED: Train MSE 34.134, Test MSE 33.341\n",
      "TRAINING MODEL dt_norm_3_33\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 10.035, Test 7.845\n",
      "MSE NON-NORMALIZED: Train MSE 273.289, Test MSE 235.954\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 5.088, Test 2.616\n",
      "MSE NON-NORMALIZED: Train MSE 76.875, Test MSE 73.047\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 2.995, Test 3.087\n",
      "MSE NON-NORMALIZED: Train MSE 81.821, Test MSE 78.915\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 1.061, Test 1.973\n",
      "MSE NON-NORMALIZED: Train MSE 50.095, Test MSE 45.781\n",
      "Epoch 100, lr 5.625e-05\n",
      "Epoch 100: Train 1.041, Test 1.680\n",
      "MSE NON-NORMALIZED: Train MSE 41.687, Test MSE 39.529\n",
      "Epoch 125, lr 1.40625e-05\n",
      "Epoch 125: Train 0.971, Test 1.065\n",
      "MSE NON-NORMALIZED: Train MSE 23.382, Test MSE 22.036\n",
      "Epoch 150, lr 7.03125e-06\n",
      "Epoch 150: Train 0.914, Test 1.002\n",
      "MSE NON-NORMALIZED: Train MSE 22.002, Test MSE 21.006\n",
      "Epoch 175, lr 7.03125e-06\n",
      "Epoch 175: Train 0.862, Test 0.934\n",
      "MSE NON-NORMALIZED: Train MSE 20.631, Test MSE 19.906\n",
      "Epoch 200, lr 7.03125e-06\n",
      "Epoch 200: Train 0.785, Test 0.839\n",
      "MSE NON-NORMALIZED: Train MSE 18.760, Test MSE 18.269\n",
      "Epoch 225, lr 7.03125e-06\n",
      "Epoch 225: Train 0.724, Test 0.749\n",
      "MSE NON-NORMALIZED: Train MSE 16.951, Test MSE 16.422\n",
      "Epoch 250, lr 7.03125e-06\n",
      "Epoch 250: Train 0.699, Test 0.683\n",
      "MSE NON-NORMALIZED: Train MSE 15.634, Test MSE 15.089\n",
      "Epoch 275, lr 7.03125e-06\n",
      "Epoch 275: Train 0.682, Test 0.649\n",
      "MSE NON-NORMALIZED: Train MSE 14.941, Test MSE 14.395\n",
      "TRAINING MODEL dt_norm_3_35\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 6.758, Test 5.273\n",
      "MSE NON-NORMALIZED: Train MSE 131.180, Test MSE 130.825\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 6.717, Test 5.229\n",
      "MSE NON-NORMALIZED: Train MSE 129.368, Test MSE 129.508\n",
      "Epoch 50, lr 0.0001125\n",
      "Epoch 50: Train 6.718, Test 5.229\n",
      "MSE NON-NORMALIZED: Train MSE 129.359, Test MSE 129.505\n",
      "Epoch 75, lr 2.8125e-05\n",
      "Epoch 75: Train 6.718, Test 5.229\n",
      "MSE NON-NORMALIZED: Train MSE 129.357, Test MSE 129.505\n",
      "Epoch 100, lr 7.03125e-06\n",
      "Epoch 100: Train 6.718, Test 5.229\n",
      "MSE NON-NORMALIZED: Train MSE 129.356, Test MSE 129.505\n",
      "Epoch 125, lr 8.7890625e-07\n",
      "Epoch 125: Train 6.718, Test 5.229\n",
      "MSE NON-NORMALIZED: Train MSE 129.418, Test MSE 130.044\n",
      "Epoch 150, lr 2.197265625e-07\n",
      "Epoch 150: Train 6.718, Test 5.229\n",
      "MSE NON-NORMALIZED: Train MSE 129.479, Test MSE 130.583\n",
      "Epoch 175, lr 5.4931640625e-08\n",
      "Epoch 175: Train 6.718, Test 5.229\n",
      "MSE NON-NORMALIZED: Train MSE 129.541, Test MSE 131.122\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 6.718, Test 5.229\n",
      "MSE NON-NORMALIZED: Train MSE 129.602, Test MSE 131.661\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 6.718, Test 5.229\n",
      "MSE NON-NORMALIZED: Train MSE 129.602, Test MSE 131.661\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 6.718, Test 5.229\n",
      "MSE NON-NORMALIZED: Train MSE 129.602, Test MSE 131.661\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 6.718, Test 5.229\n",
      "MSE NON-NORMALIZED: Train MSE 129.602, Test MSE 131.661\n",
      "TRAINING MODEL dt_norm_3_37\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39303\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 4.305, Test 6.336\n",
      "MSE NON-NORMALIZED: Train MSE 187.867, Test MSE 162.993\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 1.938, Test 2.310\n",
      "MSE NON-NORMALIZED: Train MSE 45.211, Test MSE 43.957\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 1.916, Test 2.309\n",
      "MSE NON-NORMALIZED: Train MSE 43.822, Test MSE 44.111\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 0.963, Test 1.431\n",
      "MSE NON-NORMALIZED: Train MSE 28.188, Test MSE 26.271\n",
      "Epoch 100, lr 0.000225\n",
      "Epoch 100: Train 0.773, Test 0.993\n",
      "MSE NON-NORMALIZED: Train MSE 17.406, Test MSE 17.449\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 0.763, Test 0.965\n",
      "MSE NON-NORMALIZED: Train MSE 17.101, Test MSE 17.291\n",
      "Epoch 150, lr 0.0001125\n",
      "Epoch 150: Train 0.679, Test 0.820\n",
      "MSE NON-NORMALIZED: Train MSE 14.491, Test MSE 14.866\n",
      "Epoch 175, lr 0.0001125\n",
      "Epoch 175: Train 0.633, Test 0.731\n",
      "MSE NON-NORMALIZED: Train MSE 12.832, Test MSE 13.566\n",
      "Epoch 200, lr 0.0001125\n",
      "Epoch 200: Train 0.593, Test 0.693\n",
      "MSE NON-NORMALIZED: Train MSE 12.122, Test MSE 13.169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225, lr 0.0001125\n",
      "Epoch 225: Train 0.575, Test 0.669\n",
      "MSE NON-NORMALIZED: Train MSE 11.671, Test MSE 12.569\n",
      "Epoch 250, lr 0.0001125\n",
      "Epoch 250: Train 0.558, Test 0.658\n",
      "MSE NON-NORMALIZED: Train MSE 11.486, Test MSE 12.350\n",
      "Epoch 275, lr 0.0001125\n",
      "Epoch 275: Train 0.556, Test 0.656\n",
      "MSE NON-NORMALIZED: Train MSE 11.460, Test MSE 12.314\n",
      "TRAINING MODEL dt_norm_3_27\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 38126\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 9.435, Test 13.713\n",
      "MSE NON-NORMALIZED: Train MSE 570.514, Test MSE 366.340\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 2.215, Test 3.905\n",
      "MSE NON-NORMALIZED: Train MSE 108.228, Test MSE 98.969\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 2.182, Test 3.796\n",
      "MSE NON-NORMALIZED: Train MSE 100.271, Test MSE 96.423\n",
      "Epoch 75, lr 5.625e-05\n",
      "Epoch 75: Train 2.189, Test 3.095\n",
      "MSE NON-NORMALIZED: Train MSE 84.312, Test MSE 76.587\n",
      "Epoch 100, lr 2.8125e-05\n",
      "Epoch 100: Train 2.014, Test 2.418\n",
      "MSE NON-NORMALIZED: Train MSE 66.089, Test MSE 62.426\n",
      "Epoch 125, lr 2.8125e-05\n",
      "Epoch 125: Train 0.466, Test 0.715\n",
      "MSE NON-NORMALIZED: Train MSE 17.290, Test MSE 15.187\n",
      "Epoch 150, lr 2.8125e-05\n",
      "Epoch 150: Train 0.422, Test 0.666\n",
      "MSE NON-NORMALIZED: Train MSE 15.726, Test MSE 14.726\n",
      "Epoch 175, lr 2.8125e-05\n",
      "Epoch 175: Train 0.418, Test 0.661\n",
      "MSE NON-NORMALIZED: Train MSE 15.540, Test MSE 15.105\n",
      "Epoch 200, lr 1.40625e-05\n",
      "Epoch 200: Train 0.416, Test 0.651\n",
      "MSE NON-NORMALIZED: Train MSE 15.301, Test MSE 15.353\n",
      "Epoch 225, lr 1.40625e-05\n",
      "Epoch 225: Train 0.412, Test 0.641\n",
      "MSE NON-NORMALIZED: Train MSE 14.960, Test MSE 15.098\n",
      "Epoch 250, lr 1.40625e-05\n",
      "Epoch 250: Train 0.411, Test 0.637\n",
      "MSE NON-NORMALIZED: Train MSE 14.863, Test MSE 15.010\n",
      "Epoch 275, lr 3.515625e-06\n",
      "Epoch 275: Train 0.410, Test 0.636\n",
      "MSE NON-NORMALIZED: Train MSE 14.771, Test MSE 14.994\n",
      "TRAINING MODEL dt_norm_3_29\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 9.358, Test 7.561\n",
      "MSE NON-NORMALIZED: Train MSE 320.928, Test MSE 287.494\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 5.753, Test 2.618\n",
      "MSE NON-NORMALIZED: Train MSE 83.356, Test MSE 86.414\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 1.313, Test 1.080\n",
      "MSE NON-NORMALIZED: Train MSE 23.171, Test MSE 21.654\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 1.312, Test 1.058\n",
      "MSE NON-NORMALIZED: Train MSE 22.761, Test MSE 21.199\n",
      "Epoch 100, lr 5.625e-05\n",
      "Epoch 100: Train 1.291, Test 1.034\n",
      "MSE NON-NORMALIZED: Train MSE 21.981, Test MSE 20.717\n",
      "Epoch 125, lr 2.8125e-05\n",
      "Epoch 125: Train 1.280, Test 1.001\n",
      "MSE NON-NORMALIZED: Train MSE 21.299, Test MSE 20.398\n",
      "Epoch 150, lr 1.40625e-05\n",
      "Epoch 150: Train 1.265, Test 0.965\n",
      "MSE NON-NORMALIZED: Train MSE 20.456, Test MSE 19.915\n",
      "Epoch 175, lr 1.40625e-05\n",
      "Epoch 175: Train 1.232, Test 0.935\n",
      "MSE NON-NORMALIZED: Train MSE 19.680, Test MSE 19.473\n",
      "Epoch 200, lr 1.40625e-05\n",
      "Epoch 200: Train 1.210, Test 0.914\n",
      "MSE NON-NORMALIZED: Train MSE 19.187, Test MSE 19.311\n",
      "Epoch 225, lr 1.40625e-05\n",
      "Epoch 225: Train 1.188, Test 0.904\n",
      "MSE NON-NORMALIZED: Train MSE 18.876, Test MSE 19.007\n",
      "Epoch 250, lr 1.40625e-05\n",
      "Epoch 250: Train 1.183, Test 0.899\n",
      "MSE NON-NORMALIZED: Train MSE 18.786, Test MSE 18.929\n",
      "Epoch 275, lr 1.40625e-05\n",
      "Epoch 275: Train 1.180, Test 0.893\n",
      "MSE NON-NORMALIZED: Train MSE 18.632, Test MSE 18.766\n",
      "TRAINING MODEL dt_norm_3_32\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 5.950, Test 5.903\n",
      "MSE NON-NORMALIZED: Train MSE 162.019, Test MSE 140.406\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 4.134, Test 3.646\n",
      "MSE NON-NORMALIZED: Train MSE 80.903, Test MSE 77.675\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 4.017, Test 3.787\n",
      "MSE NON-NORMALIZED: Train MSE 79.720, Test MSE 82.565\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 3.908, Test 3.408\n",
      "MSE NON-NORMALIZED: Train MSE 73.446, Test MSE 71.839\n",
      "Epoch 100, lr 0.000225\n",
      "Epoch 100: Train 3.703, Test 3.201\n",
      "MSE NON-NORMALIZED: Train MSE 69.007, Test MSE 66.819\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 2.481, Test 2.439\n",
      "MSE NON-NORMALIZED: Train MSE 51.829, Test MSE 49.894\n",
      "Epoch 150, lr 0.000225\n",
      "Epoch 150: Train 2.162, Test 2.139\n",
      "MSE NON-NORMALIZED: Train MSE 45.313, Test MSE 44.188\n",
      "Epoch 175, lr 0.0001125\n",
      "Epoch 175: Train 2.129, Test 2.042\n",
      "MSE NON-NORMALIZED: Train MSE 42.816, Test MSE 42.549\n",
      "Epoch 200, lr 5.625e-05\n",
      "Epoch 200: Train 2.118, Test 2.007\n",
      "MSE NON-NORMALIZED: Train MSE 42.061, Test MSE 42.404\n",
      "Epoch 225, lr 2.8125e-05\n",
      "Epoch 225: Train 2.071, Test 1.865\n",
      "MSE NON-NORMALIZED: Train MSE 38.253, Test MSE 38.220\n",
      "Epoch 250, lr 2.8125e-05\n",
      "Epoch 250: Train 1.979, Test 1.820\n",
      "MSE NON-NORMALIZED: Train MSE 37.160, Test MSE 37.014\n",
      "Epoch 275, lr 2.8125e-05\n",
      "Epoch 275: Train 1.956, Test 1.804\n",
      "MSE NON-NORMALIZED: Train MSE 36.807, Test MSE 36.636\n",
      "TRAINING MODEL dt_norm_3_34\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 6.531, Test 8.733\n",
      "MSE NON-NORMALIZED: Train MSE 1042.902, Test MSE 312.188\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 5.478, Test 6.991\n",
      "MSE NON-NORMALIZED: Train MSE 261.462, Test MSE 261.862\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 5.311, Test 5.107\n",
      "MSE NON-NORMALIZED: Train MSE 164.913, Test MSE 165.480\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 5.271, Test 5.062\n",
      "MSE NON-NORMALIZED: Train MSE 163.928, Test MSE 164.584\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 5.141, Test 4.869\n",
      "MSE NON-NORMALIZED: Train MSE 159.861, Test MSE 159.022\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 4.885, Test 4.775\n",
      "MSE NON-NORMALIZED: Train MSE 156.389, Test MSE 157.996\n",
      "Epoch 150, lr 2.8125e-05\n",
      "Epoch 150: Train 4.881, Test 4.763\n",
      "MSE NON-NORMALIZED: Train MSE 156.194, Test MSE 158.374\n",
      "Epoch 175, lr 2.8125e-05\n",
      "Epoch 175: Train 1.862, Test 2.392\n",
      "MSE NON-NORMALIZED: Train MSE 54.608, Test MSE 53.207\n",
      "Epoch 200, lr 2.8125e-05\n",
      "Epoch 200: Train 1.405, Test 1.951\n",
      "MSE NON-NORMALIZED: Train MSE 43.120, Test MSE 43.921\n",
      "Epoch 225, lr 2.8125e-05\n",
      "Epoch 225: Train 1.385, Test 1.928\n",
      "MSE NON-NORMALIZED: Train MSE 42.717, Test MSE 43.424\n",
      "Epoch 250, lr 2.8125e-05\n",
      "Epoch 250: Train 1.366, Test 1.918\n",
      "MSE NON-NORMALIZED: Train MSE 42.511, Test MSE 43.221\n",
      "Epoch 275, lr 2.8125e-05\n",
      "Epoch 275: Train 1.265, Test 1.867\n",
      "MSE NON-NORMALIZED: Train MSE 41.395, Test MSE 42.175\n",
      "TRAINING MODEL dt_norm_3_38\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 32933\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 5.380, Test 5.115\n",
      "MSE NON-NORMALIZED: Train MSE 184.590, Test MSE 120.384\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 0.742, Test 0.956\n",
      "MSE NON-NORMALIZED: Train MSE 19.583, Test MSE 18.676\n",
      "Epoch 50, lr 0.0001125\n",
      "Epoch 50: Train 0.646, Test 0.881\n",
      "MSE NON-NORMALIZED: Train MSE 18.083, Test MSE 17.101\n",
      "Epoch 75, lr 2.8125e-05\n",
      "Epoch 75: Train 0.614, Test 0.670\n",
      "MSE NON-NORMALIZED: Train MSE 13.715, Test MSE 12.476\n",
      "Epoch 100, lr 2.8125e-05\n",
      "Epoch 100: Train 0.477, Test 0.564\n",
      "MSE NON-NORMALIZED: Train MSE 11.396, Test MSE 10.196\n",
      "Epoch 125, lr 1.40625e-05\n",
      "Epoch 125: Train 0.476, Test 0.533\n",
      "MSE NON-NORMALIZED: Train MSE 10.896, Test MSE 9.898\n",
      "Epoch 150, lr 3.515625e-06\n",
      "Epoch 150: Train 0.475, Test 0.525\n",
      "MSE NON-NORMALIZED: Train MSE 10.790, Test MSE 10.002\n",
      "Epoch 175, lr 8.7890625e-07\n",
      "Epoch 175: Train 0.475, Test 0.522\n",
      "MSE NON-NORMALIZED: Train MSE 10.780, Test MSE 10.195\n",
      "Epoch 200, lr 1.0986328125e-07\n",
      "Epoch 200: Train 0.474, Test 0.522\n",
      "MSE NON-NORMALIZED: Train MSE 10.797, Test MSE 10.416\n",
      "Epoch 225, lr 2.74658203125e-08\n",
      "Epoch 225: Train 0.474, Test 0.522\n",
      "MSE NON-NORMALIZED: Train MSE 10.795, Test MSE 10.413\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 0.474, Test 0.522\n",
      "MSE NON-NORMALIZED: Train MSE 10.795, Test MSE 10.413\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 0.474, Test 0.521\n",
      "MSE NON-NORMALIZED: Train MSE 10.794, Test MSE 10.412\n",
      "TRAINING MODEL dt_norm_1_1\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 21.320, Test 15.354\n",
      "MSE NON-NORMALIZED: Train MSE 1184.338, Test MSE 512.490\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 3.925, Test 3.781\n",
      "MSE NON-NORMALIZED: Train MSE 107.064, Test MSE 109.082\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 2.973, Test 2.766\n",
      "MSE NON-NORMALIZED: Train MSE 84.105, Test MSE 81.564\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 2.496, Test 2.377\n",
      "MSE NON-NORMALIZED: Train MSE 72.136, Test MSE 69.679\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 2.390, Test 2.294\n",
      "MSE NON-NORMALIZED: Train MSE 68.766, Test MSE 67.021\n",
      "Epoch 125, lr 2.8125e-05\n",
      "Epoch 125: Train 2.330, Test 2.248\n",
      "MSE NON-NORMALIZED: Train MSE 67.436, Test MSE 66.543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, lr 1.40625e-05\n",
      "Epoch 150: Train 2.315, Test 2.239\n",
      "MSE NON-NORMALIZED: Train MSE 67.306, Test MSE 67.451\n",
      "Epoch 175, lr 3.515625e-06\n",
      "Epoch 175: Train 2.309, Test 2.234\n",
      "MSE NON-NORMALIZED: Train MSE 67.321, Test MSE 68.537\n",
      "Epoch 200, lr 8.7890625e-07\n",
      "Epoch 200: Train 2.307, Test 2.233\n",
      "MSE NON-NORMALIZED: Train MSE 67.425, Test MSE 69.697\n",
      "Epoch 225, lr 1.0986328125e-07\n",
      "Epoch 225: Train 2.307, Test 2.232\n",
      "MSE NON-NORMALIZED: Train MSE 67.415, Test MSE 69.680\n",
      "Epoch 250, lr 2.74658203125e-08\n",
      "Epoch 250: Train 2.306, Test 2.232\n",
      "MSE NON-NORMALIZED: Train MSE 67.411, Test MSE 69.674\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 2.306, Test 2.232\n",
      "MSE NON-NORMALIZED: Train MSE 67.411, Test MSE 69.674\n",
      "TRAINING MODEL dt_norm_1_3\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 26.887, Test 28.107\n",
      "MSE NON-NORMALIZED: Train MSE 1450.132, Test MSE 1211.288\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 14.000, Test 15.432\n",
      "MSE NON-NORMALIZED: Train MSE 498.549, Test MSE 483.624\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 13.513, Test 14.786\n",
      "MSE NON-NORMALIZED: Train MSE 444.315, Test MSE 466.557\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 11.082, Test 12.384\n",
      "MSE NON-NORMALIZED: Train MSE 387.480, Test MSE 370.829\n",
      "Epoch 100, lr 0.00045\n",
      "Epoch 100: Train 10.564, Test 11.164\n",
      "MSE NON-NORMALIZED: Train MSE 331.256, Test MSE 332.458\n",
      "Epoch 125, lr 0.00045\n",
      "Epoch 125: Train 9.216, Test 10.237\n",
      "MSE NON-NORMALIZED: Train MSE 307.957, Test MSE 302.771\n",
      "Epoch 150, lr 0.000225\n",
      "Epoch 150: Train 8.448, Test 9.248\n",
      "MSE NON-NORMALIZED: Train MSE 273.149, Test MSE 264.186\n",
      "Epoch 175, lr 0.000225\n",
      "Epoch 175: Train 8.214, Test 8.934\n",
      "MSE NON-NORMALIZED: Train MSE 263.140, Test MSE 256.792\n",
      "Epoch 200, lr 0.000225\n",
      "Epoch 200: Train 7.926, Test 8.657\n",
      "MSE NON-NORMALIZED: Train MSE 254.773, Test MSE 248.817\n",
      "Epoch 225, lr 0.0001125\n",
      "Epoch 225: Train 7.559, Test 8.261\n",
      "MSE NON-NORMALIZED: Train MSE 241.348, Test MSE 234.690\n",
      "Epoch 250, lr 0.0001125\n",
      "Epoch 250: Train 7.509, Test 8.161\n",
      "MSE NON-NORMALIZED: Train MSE 237.387, Test MSE 232.904\n",
      "Epoch 275, lr 0.0001125\n",
      "Epoch 275: Train 7.315, Test 8.006\n",
      "MSE NON-NORMALIZED: Train MSE 233.854, Test MSE 227.523\n",
      "TRAINING MODEL dt_norm_1_5\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 31.816, Test 41.309\n",
      "MSE NON-NORMALIZED: Train MSE 2897.499, Test MSE 2469.179\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 17.859, Test 15.963\n",
      "MSE NON-NORMALIZED: Train MSE 624.831, Test MSE 563.504\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 14.316, Test 12.311\n",
      "MSE NON-NORMALIZED: Train MSE 443.372, Test MSE 423.829\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 12.381, Test 10.622\n",
      "MSE NON-NORMALIZED: Train MSE 377.569, Test MSE 357.579\n",
      "Epoch 100, lr 0.00045\n",
      "Epoch 100: Train 10.594, Test 9.293\n",
      "MSE NON-NORMALIZED: Train MSE 339.553, Test MSE 297.039\n",
      "Epoch 125, lr 0.00045\n",
      "Epoch 125: Train 9.534, Test 8.582\n",
      "MSE NON-NORMALIZED: Train MSE 301.870, Test MSE 277.340\n",
      "Epoch 150, lr 0.00045\n",
      "Epoch 150: Train 8.525, Test 7.734\n",
      "MSE NON-NORMALIZED: Train MSE 266.859, Test MSE 251.818\n",
      "Epoch 175, lr 0.00045\n",
      "Epoch 175: Train 7.746, Test 7.137\n",
      "MSE NON-NORMALIZED: Train MSE 247.225, Test MSE 226.335\n",
      "Epoch 200, lr 0.00045\n",
      "Epoch 200: Train 7.809, Test 7.473\n",
      "MSE NON-NORMALIZED: Train MSE 258.140, Test MSE 244.833\n",
      "Epoch 225, lr 0.00045\n",
      "Epoch 225: Train 7.021, Test 6.483\n",
      "MSE NON-NORMALIZED: Train MSE 219.990, Test MSE 202.591\n",
      "Epoch 250, lr 0.00045\n",
      "Epoch 250: Train 6.569, Test 6.126\n",
      "MSE NON-NORMALIZED: Train MSE 208.740, Test MSE 191.508\n",
      "Epoch 275, lr 0.00045\n",
      "Epoch 275: Train 6.222, Test 5.781\n",
      "MSE NON-NORMALIZED: Train MSE 227.352, Test MSE 179.460\n",
      "TRAINING MODEL dt_norm_1_7\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 46.125, Test 48.723\n",
      "MSE NON-NORMALIZED: Train MSE 4401.338, Test MSE 3527.008\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 13.368, Test 13.883\n",
      "MSE NON-NORMALIZED: Train MSE 567.515, Test MSE 520.013\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 10.470, Test 10.971\n",
      "MSE NON-NORMALIZED: Train MSE 435.936, Test MSE 401.439\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 9.272, Test 9.370\n",
      "MSE NON-NORMALIZED: Train MSE 368.812, Test MSE 321.408\n",
      "Epoch 100, lr 0.00045\n",
      "Epoch 100: Train 8.793, Test 8.934\n",
      "MSE NON-NORMALIZED: Train MSE 362.160, Test MSE 303.684\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 7.958, Test 8.846\n",
      "MSE NON-NORMALIZED: Train MSE 456.532, Test MSE 321.694\n",
      "Epoch 150, lr 0.000225\n",
      "Epoch 150: Train 7.240, Test 7.335\n",
      "MSE NON-NORMALIZED: Train MSE 390.986, Test MSE 247.891\n",
      "Epoch 175, lr 0.0001125\n",
      "Epoch 175: Train 6.593, Test 6.511\n",
      "MSE NON-NORMALIZED: Train MSE 221.105, Test MSE 203.474\n",
      "Epoch 200, lr 0.0001125\n",
      "Epoch 200: Train 6.044, Test 5.952\n",
      "MSE NON-NORMALIZED: Train MSE 214.172, Test MSE 185.647\n",
      "Epoch 225, lr 0.0001125\n",
      "Epoch 225: Train 5.693, Test 5.619\n",
      "MSE NON-NORMALIZED: Train MSE 188.263, Test MSE 174.423\n",
      "Epoch 250, lr 0.0001125\n",
      "Epoch 250: Train 5.443, Test 5.381\n",
      "MSE NON-NORMALIZED: Train MSE 190.007, Test MSE 169.435\n",
      "Epoch 275, lr 0.0001125\n",
      "Epoch 275: Train 5.219, Test 5.113\n",
      "MSE NON-NORMALIZED: Train MSE 180.167, Test MSE 159.454\n",
      "TRAINING MODEL dt_norm_1_9\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 40.083, Test 42.585\n",
      "MSE NON-NORMALIZED: Train MSE 4653.107, Test MSE 3205.093\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 13.235, Test 17.150\n",
      "MSE NON-NORMALIZED: Train MSE 915.714, Test MSE 758.334\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 10.186, Test 11.868\n",
      "MSE NON-NORMALIZED: Train MSE 475.514, Test MSE 455.875\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 8.539, Test 9.048\n",
      "MSE NON-NORMALIZED: Train MSE 425.735, Test MSE 328.678\n",
      "Epoch 100, lr 0.000225\n",
      "Epoch 100: Train 9.439, Test 10.960\n",
      "MSE NON-NORMALIZED: Train MSE 353.291, Test MSE 418.883\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 6.993, Test 7.062\n",
      "MSE NON-NORMALIZED: Train MSE 246.464, Test MSE 237.476\n",
      "Epoch 150, lr 0.0001125\n",
      "Epoch 150: Train 6.680, Test 6.589\n",
      "MSE NON-NORMALIZED: Train MSE 236.485, Test MSE 230.472\n",
      "Epoch 175, lr 0.0001125\n",
      "Epoch 175: Train 6.003, Test 5.780\n",
      "MSE NON-NORMALIZED: Train MSE 212.853, Test MSE 200.348\n",
      "Epoch 200, lr 0.0001125\n",
      "Epoch 200: Train 5.646, Test 5.380\n",
      "MSE NON-NORMALIZED: Train MSE 190.352, Test MSE 187.113\n",
      "Epoch 225, lr 0.0001125\n",
      "Epoch 225: Train 5.520, Test 5.357\n",
      "MSE NON-NORMALIZED: Train MSE 192.466, Test MSE 189.549\n",
      "Epoch 250, lr 5.625e-05\n",
      "Epoch 250: Train 4.957, Test 4.648\n",
      "MSE NON-NORMALIZED: Train MSE 161.954, Test MSE 160.277\n",
      "Epoch 275, lr 5.625e-05\n",
      "Epoch 275: Train 4.808, Test 4.496\n",
      "MSE NON-NORMALIZED: Train MSE 159.808, Test MSE 157.613\n",
      "TRAINING MODEL dt_norm_1_11\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 35.481, Test 33.613\n",
      "MSE NON-NORMALIZED: Train MSE 3086.625, Test MSE 2059.975\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 12.626, Test 11.551\n",
      "MSE NON-NORMALIZED: Train MSE 442.508, Test MSE 463.018\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 8.087, Test 6.855\n",
      "MSE NON-NORMALIZED: Train MSE 281.515, Test MSE 219.178\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 6.691, Test 6.003\n",
      "MSE NON-NORMALIZED: Train MSE 243.843, Test MSE 197.146\n",
      "Epoch 100, lr 0.00045\n",
      "Epoch 100: Train 5.717, Test 5.783\n",
      "MSE NON-NORMALIZED: Train MSE 260.203, Test MSE 197.730\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 5.072, Test 4.680\n",
      "MSE NON-NORMALIZED: Train MSE 152.962, Test MSE 147.835\n",
      "Epoch 150, lr 0.000225\n",
      "Epoch 150: Train 4.720, Test 4.349\n",
      "MSE NON-NORMALIZED: Train MSE 141.553, Test MSE 135.739\n",
      "Epoch 175, lr 0.000225\n",
      "Epoch 175: Train 4.568, Test 4.170\n",
      "MSE NON-NORMALIZED: Train MSE 142.749, Test MSE 131.661\n",
      "Epoch 200, lr 0.000225\n",
      "Epoch 200: Train 4.520, Test 4.093\n",
      "MSE NON-NORMALIZED: Train MSE 157.131, Test MSE 129.739\n",
      "Epoch 225, lr 0.000225\n",
      "Epoch 225: Train 4.219, Test 3.932\n",
      "MSE NON-NORMALIZED: Train MSE 131.296, Test MSE 124.050\n",
      "Epoch 250, lr 0.000225\n",
      "Epoch 250: Train 4.228, Test 3.973\n",
      "MSE NON-NORMALIZED: Train MSE 144.599, Test MSE 128.253\n",
      "Epoch 275, lr 0.0001125\n",
      "Epoch 275: Train 3.895, Test 3.601\n",
      "MSE NON-NORMALIZED: Train MSE 118.008, Test MSE 113.948\n",
      "TRAINING MODEL dt_norm_1_13\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 26.825, Test 30.398\n",
      "MSE NON-NORMALIZED: Train MSE 2314.391, Test MSE 1739.423\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 5.276, Test 6.115\n",
      "MSE NON-NORMALIZED: Train MSE 211.022, Test MSE 200.394\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 4.406, Test 5.024\n",
      "MSE NON-NORMALIZED: Train MSE 177.453, Test MSE 156.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 4.287, Test 4.955\n",
      "MSE NON-NORMALIZED: Train MSE 172.331, Test MSE 160.732\n",
      "Epoch 100, lr 0.000225\n",
      "Epoch 100: Train 3.736, Test 4.404\n",
      "MSE NON-NORMALIZED: Train MSE 143.753, Test MSE 135.711\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 3.560, Test 4.193\n",
      "MSE NON-NORMALIZED: Train MSE 133.827, Test MSE 129.676\n",
      "Epoch 150, lr 0.000225\n",
      "Epoch 150: Train 3.422, Test 4.032\n",
      "MSE NON-NORMALIZED: Train MSE 141.499, Test MSE 125.785\n",
      "Epoch 175, lr 0.000225\n",
      "Epoch 175: Train 3.325, Test 3.922\n",
      "MSE NON-NORMALIZED: Train MSE 130.111, Test MSE 123.132\n",
      "Epoch 200, lr 0.000225\n",
      "Epoch 200: Train 3.256, Test 3.860\n",
      "MSE NON-NORMALIZED: Train MSE 127.275, Test MSE 123.152\n",
      "Epoch 225, lr 0.0001125\n",
      "Epoch 225: Train 3.086, Test 3.693\n",
      "MSE NON-NORMALIZED: Train MSE 116.313, Test MSE 116.624\n",
      "Epoch 250, lr 0.0001125\n",
      "Epoch 250: Train 3.013, Test 3.631\n",
      "MSE NON-NORMALIZED: Train MSE 115.431, Test MSE 115.223\n",
      "Epoch 275, lr 0.0001125\n",
      "Epoch 275: Train 2.954, Test 3.571\n",
      "MSE NON-NORMALIZED: Train MSE 114.643, Test MSE 113.388\n",
      "TRAINING MODEL dt_norm_1_15\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 29.710, Test 25.395\n",
      "MSE NON-NORMALIZED: Train MSE 2010.621, Test MSE 1284.392\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 6.100, Test 5.781\n",
      "MSE NON-NORMALIZED: Train MSE 190.450, Test MSE 188.639\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 5.060, Test 4.888\n",
      "MSE NON-NORMALIZED: Train MSE 160.110, Test MSE 155.000\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 4.868, Test 4.651\n",
      "MSE NON-NORMALIZED: Train MSE 152.304, Test MSE 149.609\n",
      "Epoch 100, lr 0.00045\n",
      "Epoch 100: Train 4.601, Test 4.450\n",
      "MSE NON-NORMALIZED: Train MSE 147.635, Test MSE 143.085\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 4.291, Test 4.199\n",
      "MSE NON-NORMALIZED: Train MSE 138.130, Test MSE 136.923\n",
      "Epoch 150, lr 0.000225\n",
      "Epoch 150: Train 4.179, Test 4.186\n",
      "MSE NON-NORMALIZED: Train MSE 136.560, Test MSE 137.718\n",
      "Epoch 175, lr 0.0001125\n",
      "Epoch 175: Train 3.986, Test 4.019\n",
      "MSE NON-NORMALIZED: Train MSE 129.012, Test MSE 132.527\n",
      "Epoch 200, lr 0.0001125\n",
      "Epoch 200: Train 3.920, Test 3.975\n",
      "MSE NON-NORMALIZED: Train MSE 128.365, Test MSE 132.536\n",
      "Epoch 225, lr 0.0001125\n",
      "Epoch 225: Train 3.863, Test 3.957\n",
      "MSE NON-NORMALIZED: Train MSE 127.080, Test MSE 132.298\n",
      "Epoch 250, lr 5.625e-05\n",
      "Epoch 250: Train 3.817, Test 3.908\n",
      "MSE NON-NORMALIZED: Train MSE 125.674, Test MSE 130.661\n",
      "Epoch 275, lr 5.625e-05\n",
      "Epoch 275: Train 3.803, Test 3.899\n",
      "MSE NON-NORMALIZED: Train MSE 125.299, Test MSE 130.529\n",
      "TRAINING MODEL dt_norm_1_17\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 29.143, Test 22.438\n",
      "MSE NON-NORMALIZED: Train MSE 1558.456, Test MSE 1056.706\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 6.037, Test 5.380\n",
      "MSE NON-NORMALIZED: Train MSE 169.374, Test MSE 160.762\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 5.016, Test 4.394\n",
      "MSE NON-NORMALIZED: Train MSE 143.158, Test MSE 133.320\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 4.666, Test 4.064\n",
      "MSE NON-NORMALIZED: Train MSE 146.089, Test MSE 123.433\n",
      "Epoch 100, lr 0.00045\n",
      "Epoch 100: Train 4.126, Test 3.613\n",
      "MSE NON-NORMALIZED: Train MSE 137.339, Test MSE 107.800\n",
      "Epoch 125, lr 0.00045\n",
      "Epoch 125: Train 3.959, Test 3.431\n",
      "MSE NON-NORMALIZED: Train MSE 111.931, Test MSE 104.470\n",
      "Epoch 150, lr 0.00045\n",
      "Epoch 150: Train 4.096, Test 3.553\n",
      "MSE NON-NORMALIZED: Train MSE 116.980, Test MSE 110.076\n",
      "Epoch 175, lr 0.00045\n",
      "Epoch 175: Train 3.712, Test 3.176\n",
      "MSE NON-NORMALIZED: Train MSE 101.832, Test MSE 99.037\n",
      "Epoch 200, lr 0.000225\n",
      "Epoch 200: Train 3.439, Test 3.027\n",
      "MSE NON-NORMALIZED: Train MSE 96.972, Test MSE 94.571\n",
      "Epoch 225, lr 0.0001125\n",
      "Epoch 225: Train 3.325, Test 2.953\n",
      "MSE NON-NORMALIZED: Train MSE 90.979, Test MSE 92.352\n",
      "Epoch 250, lr 0.0001125\n",
      "Epoch 250: Train 3.267, Test 2.904\n",
      "MSE NON-NORMALIZED: Train MSE 89.223, Test MSE 90.537\n",
      "Epoch 275, lr 0.0001125\n",
      "Epoch 275: Train 3.237, Test 2.883\n",
      "MSE NON-NORMALIZED: Train MSE 88.488, Test MSE 90.031\n",
      "TRAINING MODEL dt_norm_1_19\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 32.702, Test 17.240\n",
      "MSE NON-NORMALIZED: Train MSE 1005.881, Test MSE 670.222\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 3.796, Test 3.828\n",
      "MSE NON-NORMALIZED: Train MSE 115.643, Test MSE 106.743\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 3.431, Test 3.354\n",
      "MSE NON-NORMALIZED: Train MSE 99.362, Test MSE 96.354\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 2.975, Test 3.083\n",
      "MSE NON-NORMALIZED: Train MSE 88.592, Test MSE 86.472\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 2.919, Test 3.054\n",
      "MSE NON-NORMALIZED: Train MSE 86.459, Test MSE 86.079\n",
      "Epoch 125, lr 2.8125e-05\n",
      "Epoch 125: Train 2.855, Test 2.996\n",
      "MSE NON-NORMALIZED: Train MSE 85.171, Test MSE 85.632\n",
      "Epoch 150, lr 7.03125e-06\n",
      "Epoch 150: Train 2.844, Test 2.987\n",
      "MSE NON-NORMALIZED: Train MSE 85.128, Test MSE 86.874\n",
      "Epoch 175, lr 1.7578125e-06\n",
      "Epoch 175: Train 2.841, Test 2.986\n",
      "MSE NON-NORMALIZED: Train MSE 85.237, Test MSE 88.282\n",
      "Epoch 200, lr 4.39453125e-07\n",
      "Epoch 200: Train 2.841, Test 2.985\n",
      "MSE NON-NORMALIZED: Train MSE 85.389, Test MSE 89.724\n",
      "Epoch 225, lr 5.4931640625e-08\n",
      "Epoch 225: Train 2.841, Test 2.985\n",
      "MSE NON-NORMALIZED: Train MSE 85.385, Test MSE 89.721\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 2.840, Test 2.985\n",
      "MSE NON-NORMALIZED: Train MSE 85.385, Test MSE 89.721\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 2.840, Test 2.985\n",
      "MSE NON-NORMALIZED: Train MSE 85.384, Test MSE 89.721\n",
      "TRAINING MODEL dt_norm_1_21\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 12.951, Test 17.080\n",
      "MSE NON-NORMALIZED: Train MSE 742.372, Test MSE 637.012\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 3.569, Test 3.700\n",
      "MSE NON-NORMALIZED: Train MSE 101.313, Test MSE 93.969\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 2.810, Test 3.291\n",
      "MSE NON-NORMALIZED: Train MSE 85.240, Test MSE 83.711\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 2.701, Test 3.179\n",
      "MSE NON-NORMALIZED: Train MSE 81.236, Test MSE 80.679\n",
      "Epoch 100, lr 5.625e-05\n",
      "Epoch 100: Train 2.648, Test 3.120\n",
      "MSE NON-NORMALIZED: Train MSE 80.040, Test MSE 79.166\n",
      "Epoch 125, lr 1.40625e-05\n",
      "Epoch 125: Train 2.629, Test 3.090\n",
      "MSE NON-NORMALIZED: Train MSE 79.673, Test MSE 79.720\n",
      "Epoch 150, lr 1.7578125e-06\n",
      "Epoch 150: Train 2.626, Test 3.086\n",
      "MSE NON-NORMALIZED: Train MSE 79.707, Test MSE 81.008\n",
      "Epoch 175, lr 4.39453125e-07\n",
      "Epoch 175: Train 2.626, Test 3.086\n",
      "MSE NON-NORMALIZED: Train MSE 79.845, Test MSE 82.375\n",
      "Epoch 200, lr 1.0986328125e-07\n",
      "Epoch 200: Train 2.625, Test 3.086\n",
      "MSE NON-NORMALIZED: Train MSE 79.999, Test MSE 83.755\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 2.625, Test 3.085\n",
      "MSE NON-NORMALIZED: Train MSE 79.998, Test MSE 83.754\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 2.625, Test 3.085\n",
      "MSE NON-NORMALIZED: Train MSE 79.997, Test MSE 83.754\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 2.625, Test 3.085\n",
      "MSE NON-NORMALIZED: Train MSE 79.997, Test MSE 83.754\n",
      "TRAINING MODEL dt_norm_1_23\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 11.917, Test 11.858\n",
      "MSE NON-NORMALIZED: Train MSE 421.343, Test MSE 369.355\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 3.678, Test 3.647\n",
      "MSE NON-NORMALIZED: Train MSE 86.852, Test MSE 83.210\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 2.956, Test 3.032\n",
      "MSE NON-NORMALIZED: Train MSE 70.898, Test MSE 68.713\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 2.778, Test 2.902\n",
      "MSE NON-NORMALIZED: Train MSE 68.064, Test MSE 65.654\n",
      "Epoch 100, lr 0.000225\n",
      "Epoch 100: Train 2.724, Test 2.857\n",
      "MSE NON-NORMALIZED: Train MSE 66.989, Test MSE 64.759\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 2.664, Test 2.755\n",
      "MSE NON-NORMALIZED: Train MSE 65.439, Test MSE 63.104\n",
      "Epoch 150, lr 5.625e-05\n",
      "Epoch 150: Train 2.634, Test 2.708\n",
      "MSE NON-NORMALIZED: Train MSE 64.328, Test MSE 63.173\n",
      "Epoch 175, lr 1.40625e-05\n",
      "Epoch 175: Train 2.616, Test 2.689\n",
      "MSE NON-NORMALIZED: Train MSE 63.828, Test MSE 63.955\n",
      "Epoch 200, lr 3.515625e-06\n",
      "Epoch 200: Train 2.611, Test 2.683\n",
      "MSE NON-NORMALIZED: Train MSE 63.796, Test MSE 65.067\n",
      "Epoch 225, lr 8.7890625e-07\n",
      "Epoch 225: Train 2.611, Test 2.681\n",
      "MSE NON-NORMALIZED: Train MSE 63.748, Test MSE 65.036\n",
      "Epoch 250, lr 1.0986328125e-07\n",
      "Epoch 250: Train 2.611, Test 2.681\n",
      "MSE NON-NORMALIZED: Train MSE 63.734, Test MSE 65.031\n",
      "Epoch 275, lr 2.74658203125e-08\n",
      "Epoch 275: Train 2.611, Test 2.681\n",
      "MSE NON-NORMALIZED: Train MSE 63.732, Test MSE 65.030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL dt_norm_1_25\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 9.417, Test 11.781\n",
      "MSE NON-NORMALIZED: Train MSE 448.929, Test MSE 398.025\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 3.363, Test 3.764\n",
      "MSE NON-NORMALIZED: Train MSE 96.920, Test MSE 91.566\n",
      "Epoch 50, lr 0.0001125\n",
      "Epoch 50: Train 3.123, Test 3.133\n",
      "MSE NON-NORMALIZED: Train MSE 78.833, Test MSE 75.450\n",
      "Epoch 75, lr 2.8125e-05\n",
      "Epoch 75: Train 3.018, Test 3.032\n",
      "MSE NON-NORMALIZED: Train MSE 76.319, Test MSE 73.174\n",
      "Epoch 100, lr 3.515625e-06\n",
      "Epoch 100: Train 2.965, Test 3.007\n",
      "MSE NON-NORMALIZED: Train MSE 75.560, Test MSE 72.515\n",
      "Epoch 125, lr 8.7890625e-07\n",
      "Epoch 125: Train 2.955, Test 3.003\n",
      "MSE NON-NORMALIZED: Train MSE 75.571, Test MSE 73.606\n",
      "Epoch 150, lr 2.197265625e-07\n",
      "Epoch 150: Train 2.953, Test 3.002\n",
      "MSE NON-NORMALIZED: Train MSE 75.678, Test MSE 74.779\n",
      "Epoch 175, lr 5.4931640625e-08\n",
      "Epoch 175: Train 2.952, Test 3.002\n",
      "MSE NON-NORMALIZED: Train MSE 75.809, Test MSE 75.971\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 2.952, Test 3.002\n",
      "MSE NON-NORMALIZED: Train MSE 75.945, Test MSE 77.166\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 2.952, Test 3.002\n",
      "MSE NON-NORMALIZED: Train MSE 75.944, Test MSE 77.165\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 2.952, Test 3.002\n",
      "MSE NON-NORMALIZED: Train MSE 75.944, Test MSE 77.164\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 2.952, Test 3.002\n",
      "MSE NON-NORMALIZED: Train MSE 75.943, Test MSE 77.163\n",
      "TRAINING MODEL dt_norm_1_27\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 11.039, Test 8.349\n",
      "MSE NON-NORMALIZED: Train MSE 255.470, Test MSE 234.187\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 2.546, Test 3.765\n",
      "MSE NON-NORMALIZED: Train MSE 95.682, Test MSE 93.185\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 5.225, Test 3.474\n",
      "MSE NON-NORMALIZED: Train MSE 87.606, Test MSE 88.218\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 2.126, Test 2.878\n",
      "MSE NON-NORMALIZED: Train MSE 78.798, Test MSE 69.764\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 1.734, Test 2.137\n",
      "MSE NON-NORMALIZED: Train MSE 48.359, Test MSE 46.501\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 1.694, Test 2.087\n",
      "MSE NON-NORMALIZED: Train MSE 47.289, Test MSE 46.358\n",
      "Epoch 150, lr 0.0001125\n",
      "Epoch 150: Train 1.676, Test 2.068\n",
      "MSE NON-NORMALIZED: Train MSE 47.096, Test MSE 46.843\n",
      "Epoch 175, lr 0.0001125\n",
      "Epoch 175: Train 1.665, Test 2.060\n",
      "MSE NON-NORMALIZED: Train MSE 46.964, Test MSE 47.540\n",
      "Epoch 200, lr 5.625e-05\n",
      "Epoch 200: Train 1.649, Test 2.047\n",
      "MSE NON-NORMALIZED: Train MSE 46.638, Test MSE 48.080\n",
      "Epoch 225, lr 2.8125e-05\n",
      "Epoch 225: Train 1.639, Test 2.037\n",
      "MSE NON-NORMALIZED: Train MSE 46.388, Test MSE 47.868\n",
      "Epoch 250, lr 2.8125e-05\n",
      "Epoch 250: Train 1.635, Test 2.033\n",
      "MSE NON-NORMALIZED: Train MSE 46.317, Test MSE 47.787\n",
      "Epoch 275, lr 2.8125e-05\n",
      "Epoch 275: Train 1.631, Test 2.031\n",
      "MSE NON-NORMALIZED: Train MSE 46.256, Test MSE 47.744\n",
      "TRAINING MODEL dt_norm_1_29\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 3.097, Test 4.448\n",
      "MSE NON-NORMALIZED: Train MSE 168.672, Test MSE 172.302\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 3.101, Test 4.413\n",
      "MSE NON-NORMALIZED: Train MSE 166.234, Test MSE 170.553\n",
      "Epoch 50, lr 5.625e-05\n",
      "Epoch 50: Train 3.102, Test 4.413\n",
      "MSE NON-NORMALIZED: Train MSE 166.211, Test MSE 170.547\n",
      "Epoch 75, lr 7.03125e-06\n",
      "Epoch 75: Train 3.102, Test 4.413\n",
      "MSE NON-NORMALIZED: Train MSE 166.203, Test MSE 170.546\n",
      "Epoch 100, lr 1.7578125e-06\n",
      "Epoch 100: Train 3.102, Test 4.413\n",
      "MSE NON-NORMALIZED: Train MSE 166.202, Test MSE 170.546\n",
      "Epoch 125, lr 4.39453125e-07\n",
      "Epoch 125: Train 3.101, Test 4.413\n",
      "MSE NON-NORMALIZED: Train MSE 166.286, Test MSE 171.308\n",
      "Epoch 150, lr 1.0986328125e-07\n",
      "Epoch 150: Train 3.101, Test 4.413\n",
      "MSE NON-NORMALIZED: Train MSE 166.369, Test MSE 172.069\n",
      "Epoch 175, lr 1.373291015625e-08\n",
      "Epoch 175: Train 3.101, Test 4.413\n",
      "MSE NON-NORMALIZED: Train MSE 166.452, Test MSE 172.830\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 3.101, Test 4.413\n",
      "MSE NON-NORMALIZED: Train MSE 166.536, Test MSE 173.591\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 3.101, Test 4.413\n",
      "MSE NON-NORMALIZED: Train MSE 166.536, Test MSE 173.591\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 3.101, Test 4.413\n",
      "MSE NON-NORMALIZED: Train MSE 166.536, Test MSE 173.591\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 3.101, Test 4.413\n",
      "MSE NON-NORMALIZED: Train MSE 166.536, Test MSE 173.591\n",
      "TRAINING MODEL dt_norm_1_30\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 3.886, Test 6.113\n",
      "MSE NON-NORMALIZED: Train MSE 348.021, Test MSE 333.424\n",
      "Epoch 25, lr 0.0001125\n",
      "Epoch 25: Train 3.946, Test 6.143\n",
      "MSE NON-NORMALIZED: Train MSE 343.157, Test MSE 332.300\n",
      "Epoch 50, lr 2.8125e-05\n",
      "Epoch 50: Train 3.948, Test 6.143\n",
      "MSE NON-NORMALIZED: Train MSE 343.121, Test MSE 332.290\n",
      "Epoch 75, lr 7.03125e-06\n",
      "Epoch 75: Train 3.948, Test 6.143\n",
      "MSE NON-NORMALIZED: Train MSE 343.111, Test MSE 332.289\n",
      "Epoch 100, lr 8.7890625e-07\n",
      "Epoch 100: Train 3.948, Test 6.143\n",
      "MSE NON-NORMALIZED: Train MSE 343.108, Test MSE 332.289\n",
      "Epoch 125, lr 2.197265625e-07\n",
      "Epoch 125: Train 3.948, Test 6.143\n",
      "MSE NON-NORMALIZED: Train MSE 343.199, Test MSE 333.120\n",
      "Epoch 150, lr 5.4931640625e-08\n",
      "Epoch 150: Train 3.948, Test 6.143\n",
      "MSE NON-NORMALIZED: Train MSE 343.290, Test MSE 333.951\n",
      "Epoch 175, lr 1.373291015625e-08\n",
      "Epoch 175: Train 3.948, Test 6.143\n",
      "MSE NON-NORMALIZED: Train MSE 343.382, Test MSE 334.781\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 3.948, Test 6.143\n",
      "MSE NON-NORMALIZED: Train MSE 343.473, Test MSE 335.611\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 3.948, Test 6.143\n",
      "MSE NON-NORMALIZED: Train MSE 343.473, Test MSE 335.611\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 3.948, Test 6.143\n",
      "MSE NON-NORMALIZED: Train MSE 343.473, Test MSE 335.610\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 3.948, Test 6.143\n",
      "MSE NON-NORMALIZED: Train MSE 343.473, Test MSE 335.610\n",
      "TRAINING MODEL dt_norm_1_31\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 6.191, Test 8.008\n",
      "MSE NON-NORMALIZED: Train MSE 618.000, Test MSE 334.036\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 3.590, Test 4.883\n",
      "MSE NON-NORMALIZED: Train MSE 198.860, Test MSE 196.324\n",
      "Epoch 50, lr 0.0001125\n",
      "Epoch 50: Train 3.599, Test 3.686\n",
      "MSE NON-NORMALIZED: Train MSE 143.771, Test MSE 141.014\n",
      "Epoch 75, lr 2.8125e-05\n",
      "Epoch 75: Train 3.518, Test 2.539\n",
      "MSE NON-NORMALIZED: Train MSE 66.826, Test MSE 65.370\n",
      "Epoch 100, lr 3.515625e-06\n",
      "Epoch 100: Train 3.500, Test 2.400\n",
      "MSE NON-NORMALIZED: Train MSE 62.244, Test MSE 60.857\n",
      "Epoch 125, lr 8.7890625e-07\n",
      "Epoch 125: Train 3.498, Test 2.361\n",
      "MSE NON-NORMALIZED: Train MSE 61.114, Test MSE 60.351\n",
      "Epoch 150, lr 2.197265625e-07\n",
      "Epoch 150: Train 3.483, Test 2.332\n",
      "MSE NON-NORMALIZED: Train MSE 60.463, Test MSE 60.197\n",
      "Epoch 175, lr 5.4931640625e-08\n",
      "Epoch 175: Train 3.479, Test 2.327\n",
      "MSE NON-NORMALIZED: Train MSE 60.399, Test MSE 60.641\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 3.479, Test 2.326\n",
      "MSE NON-NORMALIZED: Train MSE 60.443, Test MSE 61.202\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 3.479, Test 2.326\n",
      "MSE NON-NORMALIZED: Train MSE 60.431, Test MSE 61.186\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 3.479, Test 2.325\n",
      "MSE NON-NORMALIZED: Train MSE 60.419, Test MSE 61.170\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 3.478, Test 2.325\n",
      "MSE NON-NORMALIZED: Train MSE 60.407, Test MSE 61.155\n",
      "TRAINING MODEL dt_norm_1_32\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 2.636, Test 3.562\n",
      "MSE NON-NORMALIZED: Train MSE 233.553, Test MSE 88.248\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 2.257, Test 2.438\n",
      "MSE NON-NORMALIZED: Train MSE 57.153, Test MSE 53.109\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 1.912, Test 1.781\n",
      "MSE NON-NORMALIZED: Train MSE 43.958, Test MSE 38.822\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 1.781, Test 1.266\n",
      "MSE NON-NORMALIZED: Train MSE 28.701, Test MSE 25.184\n",
      "Epoch 100, lr 0.00045\n",
      "Epoch 100: Train 1.623, Test 1.226\n",
      "MSE NON-NORMALIZED: Train MSE 27.619, Test MSE 25.301\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 1.615, Test 1.321\n",
      "MSE NON-NORMALIZED: Train MSE 29.286, Test MSE 27.047\n",
      "Epoch 150, lr 0.000225\n",
      "Epoch 150: Train 1.006, Test 1.003\n",
      "MSE NON-NORMALIZED: Train MSE 20.751, Test MSE 18.538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175, lr 0.000225\n",
      "Epoch 175: Train 0.983, Test 0.982\n",
      "MSE NON-NORMALIZED: Train MSE 21.300, Test MSE 18.547\n",
      "Epoch 200, lr 0.0001125\n",
      "Epoch 200: Train 0.973, Test 0.972\n",
      "MSE NON-NORMALIZED: Train MSE 19.941, Test MSE 18.748\n",
      "Epoch 225, lr 0.0001125\n",
      "Epoch 225: Train 0.968, Test 0.967\n",
      "MSE NON-NORMALIZED: Train MSE 19.848, Test MSE 18.628\n",
      "Epoch 250, lr 0.0001125\n",
      "Epoch 250: Train 0.966, Test 0.961\n",
      "MSE NON-NORMALIZED: Train MSE 19.753, Test MSE 18.487\n",
      "Epoch 275, lr 5.625e-05\n",
      "Epoch 275: Train 0.956, Test 0.954\n",
      "MSE NON-NORMALIZED: Train MSE 19.525, Test MSE 18.359\n",
      "TRAINING MODEL dt_norm_1_33\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 4.239, Test 3.694\n",
      "MSE NON-NORMALIZED: Train MSE 121.718, Test MSE 107.756\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 2.274, Test 2.616\n",
      "MSE NON-NORMALIZED: Train MSE 64.084, Test MSE 59.540\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 2.249, Test 2.612\n",
      "MSE NON-NORMALIZED: Train MSE 63.331, Test MSE 59.153\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 2.222, Test 2.554\n",
      "MSE NON-NORMALIZED: Train MSE 61.886, Test MSE 57.810\n",
      "Epoch 100, lr 0.000225\n",
      "Epoch 100: Train 1.969, Test 1.841\n",
      "MSE NON-NORMALIZED: Train MSE 42.488, Test MSE 37.494\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 1.800, Test 1.627\n",
      "MSE NON-NORMALIZED: Train MSE 35.855, Test MSE 32.190\n",
      "Epoch 150, lr 0.000225\n",
      "Epoch 150: Train 1.621, Test 1.457\n",
      "MSE NON-NORMALIZED: Train MSE 31.372, Test MSE 28.071\n",
      "Epoch 175, lr 0.000225\n",
      "Epoch 175: Train 1.489, Test 1.410\n",
      "MSE NON-NORMALIZED: Train MSE 29.925, Test MSE 27.386\n",
      "Epoch 200, lr 0.000225\n",
      "Epoch 200: Train 1.441, Test 1.434\n",
      "MSE NON-NORMALIZED: Train MSE 29.407, Test MSE 28.681\n",
      "Epoch 225, lr 0.000225\n",
      "Epoch 225: Train 1.424, Test 1.448\n",
      "MSE NON-NORMALIZED: Train MSE 29.055, Test MSE 29.598\n",
      "Epoch 250, lr 0.0001125\n",
      "Epoch 250: Train 1.336, Test 1.303\n",
      "MSE NON-NORMALIZED: Train MSE 28.142, Test MSE 25.317\n",
      "Epoch 275, lr 0.0001125\n",
      "Epoch 275: Train 1.316, Test 1.287\n",
      "MSE NON-NORMALIZED: Train MSE 27.737, Test MSE 24.886\n",
      "TRAINING MODEL dt_norm_2_1\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 3972\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 21.016, Test 56.328\n",
      "MSE NON-NORMALIZED: Train MSE 2663.344, Test MSE 2678.661\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 2.059, Test 1.827\n",
      "MSE NON-NORMALIZED: Train MSE 63.642, Test MSE 51.653\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 2.017, Test 1.815\n",
      "MSE NON-NORMALIZED: Train MSE 60.826, Test MSE 51.740\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 1.979, Test 1.775\n",
      "MSE NON-NORMALIZED: Train MSE 57.419, Test MSE 50.313\n",
      "Epoch 100, lr 0.000225\n",
      "Epoch 100: Train 1.409, Test 1.430\n",
      "MSE NON-NORMALIZED: Train MSE 50.067, Test MSE 43.508\n",
      "Epoch 125, lr 5.625e-05\n",
      "Epoch 125: Train 1.401, Test 1.422\n",
      "MSE NON-NORMALIZED: Train MSE 49.282, Test MSE 43.500\n",
      "Epoch 150, lr 1.40625e-05\n",
      "Epoch 150: Train 1.397, Test 1.416\n",
      "MSE NON-NORMALIZED: Train MSE 48.762, Test MSE 43.479\n",
      "Epoch 175, lr 3.515625e-06\n",
      "Epoch 175: Train 1.397, Test 1.416\n",
      "MSE NON-NORMALIZED: Train MSE 48.682, Test MSE 43.695\n",
      "Epoch 200, lr 8.7890625e-07\n",
      "Epoch 200: Train 1.397, Test 1.416\n",
      "MSE NON-NORMALIZED: Train MSE 48.731, Test MSE 43.912\n",
      "Epoch 225, lr 2.197265625e-07\n",
      "Epoch 225: Train 1.397, Test 1.416\n",
      "MSE NON-NORMALIZED: Train MSE 48.723, Test MSE 43.911\n",
      "Epoch 250, lr 2.74658203125e-08\n",
      "Epoch 250: Train 1.397, Test 1.416\n",
      "MSE NON-NORMALIZED: Train MSE 48.721, Test MSE 43.910\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 1.397, Test 1.416\n",
      "MSE NON-NORMALIZED: Train MSE 48.720, Test MSE 43.910\n",
      "TRAINING MODEL dt_norm_2_3\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 32.453, Test 27.505\n",
      "MSE NON-NORMALIZED: Train MSE 1529.084, Test MSE 997.611\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 7.707, Test 10.127\n",
      "MSE NON-NORMALIZED: Train MSE 674.778, Test MSE 313.714\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 6.252, Test 6.643\n",
      "MSE NON-NORMALIZED: Train MSE 199.482, Test MSE 188.328\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 5.204, Test 5.362\n",
      "MSE NON-NORMALIZED: Train MSE 162.610, Test MSE 154.524\n",
      "Epoch 100, lr 0.00045\n",
      "Epoch 100: Train 5.177, Test 5.207\n",
      "MSE NON-NORMALIZED: Train MSE 161.938, Test MSE 151.731\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 4.967, Test 5.061\n",
      "MSE NON-NORMALIZED: Train MSE 151.970, Test MSE 148.637\n",
      "Epoch 150, lr 0.000225\n",
      "Epoch 150: Train 4.909, Test 5.009\n",
      "MSE NON-NORMALIZED: Train MSE 151.945, Test MSE 148.935\n",
      "Epoch 175, lr 0.0001125\n",
      "Epoch 175: Train 4.887, Test 4.984\n",
      "MSE NON-NORMALIZED: Train MSE 150.537, Test MSE 150.158\n",
      "Epoch 200, lr 1.40625e-05\n",
      "Epoch 200: Train 4.867, Test 4.968\n",
      "MSE NON-NORMALIZED: Train MSE 148.556, Test MSE 151.445\n",
      "Epoch 225, lr 1.40625e-05\n",
      "Epoch 225: Train 4.863, Test 4.964\n",
      "MSE NON-NORMALIZED: Train MSE 148.442, Test MSE 151.345\n",
      "Epoch 250, lr 3.515625e-06\n",
      "Epoch 250: Train 4.861, Test 4.961\n",
      "MSE NON-NORMALIZED: Train MSE 148.307, Test MSE 151.274\n",
      "Epoch 275, lr 1.7578125e-06\n",
      "Epoch 275: Train 4.860, Test 4.961\n",
      "MSE NON-NORMALIZED: Train MSE 148.279, Test MSE 151.248\n",
      "TRAINING MODEL dt_norm_2_5\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 39.777, Test 31.514\n",
      "MSE NON-NORMALIZED: Train MSE 2526.550, Test MSE 1578.704\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 10.934, Test 11.310\n",
      "MSE NON-NORMALIZED: Train MSE 566.579, Test MSE 502.394\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 7.940, Test 7.865\n",
      "MSE NON-NORMALIZED: Train MSE 322.631, Test MSE 312.059\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 7.386, Test 7.453\n",
      "MSE NON-NORMALIZED: Train MSE 313.598, Test MSE 297.979\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 7.182, Test 7.290\n",
      "MSE NON-NORMALIZED: Train MSE 301.738, Test MSE 292.518\n",
      "Epoch 125, lr 5.625e-05\n",
      "Epoch 125: Train 7.060, Test 7.166\n",
      "MSE NON-NORMALIZED: Train MSE 292.977, Test MSE 289.545\n",
      "Epoch 150, lr 1.40625e-05\n",
      "Epoch 150: Train 7.025, Test 7.140\n",
      "MSE NON-NORMALIZED: Train MSE 287.591, Test MSE 290.731\n",
      "Epoch 175, lr 1.7578125e-06\n",
      "Epoch 175: Train 7.018, Test 7.132\n",
      "MSE NON-NORMALIZED: Train MSE 287.496, Test MSE 292.570\n",
      "Epoch 200, lr 4.39453125e-07\n",
      "Epoch 200: Train 7.017, Test 7.130\n",
      "MSE NON-NORMALIZED: Train MSE 287.641, Test MSE 294.549\n",
      "Epoch 225, lr 1.0986328125e-07\n",
      "Epoch 225: Train 7.016, Test 7.130\n",
      "MSE NON-NORMALIZED: Train MSE 287.625, Test MSE 294.541\n",
      "Epoch 250, lr 2.74658203125e-08\n",
      "Epoch 250: Train 7.016, Test 7.130\n",
      "MSE NON-NORMALIZED: Train MSE 287.621, Test MSE 294.539\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 7.016, Test 7.130\n",
      "MSE NON-NORMALIZED: Train MSE 287.621, Test MSE 294.539\n",
      "TRAINING MODEL dt_norm_2_7\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 37.353, Test 29.982\n",
      "MSE NON-NORMALIZED: Train MSE 3593.194, Test MSE 1321.014\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 11.481, Test 10.729\n",
      "MSE NON-NORMALIZED: Train MSE 533.959, Test MSE 455.321\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 7.371, Test 6.727\n",
      "MSE NON-NORMALIZED: Train MSE 294.101, Test MSE 273.697\n",
      "Epoch 75, lr 2.8125e-05\n",
      "Epoch 75: Train 6.581, Test 6.170\n",
      "MSE NON-NORMALIZED: Train MSE 273.137, Test MSE 250.540\n",
      "Epoch 100, lr 7.03125e-06\n",
      "Epoch 100: Train 6.519, Test 6.099\n",
      "MSE NON-NORMALIZED: Train MSE 270.265, Test MSE 248.300\n",
      "Epoch 125, lr 1.7578125e-06\n",
      "Epoch 125: Train 6.498, Test 6.079\n",
      "MSE NON-NORMALIZED: Train MSE 269.781, Test MSE 249.728\n",
      "Epoch 150, lr 2.197265625e-07\n",
      "Epoch 150: Train 6.493, Test 6.074\n",
      "MSE NON-NORMALIZED: Train MSE 269.843, Test MSE 251.595\n",
      "Epoch 175, lr 5.4931640625e-08\n",
      "Epoch 175: Train 6.492, Test 6.073\n",
      "MSE NON-NORMALIZED: Train MSE 270.032, Test MSE 253.556\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 6.492, Test 6.072\n",
      "MSE NON-NORMALIZED: Train MSE 270.252, Test MSE 255.540\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 6.492, Test 6.072\n",
      "MSE NON-NORMALIZED: Train MSE 270.249, Test MSE 255.538\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 6.492, Test 6.072\n",
      "MSE NON-NORMALIZED: Train MSE 270.247, Test MSE 255.536\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 6.492, Test 6.072\n",
      "MSE NON-NORMALIZED: Train MSE 270.244, Test MSE 255.535\n",
      "TRAINING MODEL dt_norm_2_9\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 19.254, Test 21.649\n",
      "MSE NON-NORMALIZED: Train MSE 2871.256, Test MSE 872.257\n",
      "Epoch 25, lr 0.0001125\n",
      "Epoch 25: Train 17.366, Test 22.903\n",
      "MSE NON-NORMALIZED: Train MSE 1401.733, Test MSE 1156.726\n",
      "Epoch 50, lr 2.8125e-05\n",
      "Epoch 50: Train 12.893, Test 17.857\n",
      "MSE NON-NORMALIZED: Train MSE 1153.790, Test MSE 908.557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, lr 2.8125e-05\n",
      "Epoch 75: Train 7.771, Test 8.867\n",
      "MSE NON-NORMALIZED: Train MSE 575.805, Test MSE 332.891\n",
      "Epoch 100, lr 2.8125e-05\n",
      "Epoch 100: Train 6.696, Test 7.099\n",
      "MSE NON-NORMALIZED: Train MSE 300.546, Test MSE 267.582\n",
      "Epoch 125, lr 2.8125e-05\n",
      "Epoch 125: Train 6.258, Test 5.588\n",
      "MSE NON-NORMALIZED: Train MSE 243.202, Test MSE 211.093\n",
      "Epoch 150, lr 2.8125e-05\n",
      "Epoch 150: Train 5.947, Test 5.312\n",
      "MSE NON-NORMALIZED: Train MSE 224.458, Test MSE 203.307\n",
      "Epoch 175, lr 2.8125e-05\n",
      "Epoch 175: Train 5.744, Test 5.132\n",
      "MSE NON-NORMALIZED: Train MSE 219.731, Test MSE 197.639\n",
      "Epoch 200, lr 2.8125e-05\n",
      "Epoch 200: Train 5.660, Test 5.093\n",
      "MSE NON-NORMALIZED: Train MSE 216.044, Test MSE 199.119\n",
      "Epoch 225, lr 2.8125e-05\n",
      "Epoch 225: Train 5.618, Test 5.016\n",
      "MSE NON-NORMALIZED: Train MSE 212.728, Test MSE 195.554\n",
      "Epoch 250, lr 2.8125e-05\n",
      "Epoch 250: Train 5.601, Test 5.002\n",
      "MSE NON-NORMALIZED: Train MSE 212.587, Test MSE 195.297\n",
      "Epoch 275, lr 2.8125e-05\n",
      "Epoch 275: Train 5.560, Test 4.960\n",
      "MSE NON-NORMALIZED: Train MSE 209.669, Test MSE 194.245\n",
      "TRAINING MODEL dt_norm_2_11\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 26.761, Test 36.642\n",
      "MSE NON-NORMALIZED: Train MSE 2792.456, Test MSE 2261.198\n",
      "Epoch 25, lr 0.0001125\n",
      "Epoch 25: Train 21.227, Test 23.987\n",
      "MSE NON-NORMALIZED: Train MSE 1946.712, Test MSE 1816.023\n",
      "Epoch 50, lr 2.8125e-05\n",
      "Epoch 50: Train 18.595, Test 10.614\n",
      "MSE NON-NORMALIZED: Train MSE 690.797, Test MSE 524.514\n",
      "Epoch 75, lr 2.8125e-05\n",
      "Epoch 75: Train 6.234, Test 7.577\n",
      "MSE NON-NORMALIZED: Train MSE 469.527, Test MSE 297.490\n",
      "Epoch 100, lr 1.40625e-05\n",
      "Epoch 100: Train 5.975, Test 5.218\n",
      "MSE NON-NORMALIZED: Train MSE 196.874, Test MSE 187.836\n",
      "Epoch 125, lr 7.03125e-06\n",
      "Epoch 125: Train 5.915, Test 5.153\n",
      "MSE NON-NORMALIZED: Train MSE 195.542, Test MSE 188.320\n",
      "Epoch 150, lr 7.03125e-06\n",
      "Epoch 150: Train 5.785, Test 5.091\n",
      "MSE NON-NORMALIZED: Train MSE 193.247, Test MSE 187.879\n",
      "Epoch 175, lr 7.03125e-06\n",
      "Epoch 175: Train 5.676, Test 5.034\n",
      "MSE NON-NORMALIZED: Train MSE 191.698, Test MSE 187.526\n",
      "Epoch 200, lr 7.03125e-06\n",
      "Epoch 200: Train 5.573, Test 4.999\n",
      "MSE NON-NORMALIZED: Train MSE 189.907, Test MSE 187.506\n",
      "Epoch 225, lr 7.03125e-06\n",
      "Epoch 225: Train 5.518, Test 4.964\n",
      "MSE NON-NORMALIZED: Train MSE 189.319, Test MSE 186.327\n",
      "Epoch 250, lr 1.7578125e-06\n",
      "Epoch 250: Train 5.479, Test 4.939\n",
      "MSE NON-NORMALIZED: Train MSE 188.741, Test MSE 185.368\n",
      "Epoch 275, lr 1.7578125e-06\n",
      "Epoch 275: Train 5.475, Test 4.937\n",
      "MSE NON-NORMALIZED: Train MSE 188.634, Test MSE 185.382\n",
      "TRAINING MODEL dt_norm_2_13\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 17.381, Test 16.266\n",
      "MSE NON-NORMALIZED: Train MSE 978.913, Test MSE 519.916\n",
      "Epoch 25, lr 0.0001125\n",
      "Epoch 25: Train 15.819, Test 16.290\n",
      "MSE NON-NORMALIZED: Train MSE 530.851, Test MSE 538.418\n",
      "Epoch 50, lr 2.8125e-05\n",
      "Epoch 50: Train 9.794, Test 10.439\n",
      "MSE NON-NORMALIZED: Train MSE 337.952, Test MSE 331.538\n",
      "Epoch 75, lr 2.8125e-05\n",
      "Epoch 75: Train 7.624, Test 7.406\n",
      "MSE NON-NORMALIZED: Train MSE 231.157, Test MSE 226.077\n",
      "Epoch 100, lr 2.8125e-05\n",
      "Epoch 100: Train 5.623, Test 5.093\n",
      "MSE NON-NORMALIZED: Train MSE 150.442, Test MSE 145.476\n",
      "Epoch 125, lr 2.8125e-05\n",
      "Epoch 125: Train 5.190, Test 4.516\n",
      "MSE NON-NORMALIZED: Train MSE 133.759, Test MSE 131.721\n",
      "Epoch 150, lr 2.8125e-05\n",
      "Epoch 150: Train 5.058, Test 4.377\n",
      "MSE NON-NORMALIZED: Train MSE 132.115, Test MSE 129.259\n",
      "Epoch 175, lr 1.40625e-05\n",
      "Epoch 175: Train 4.931, Test 4.236\n",
      "MSE NON-NORMALIZED: Train MSE 129.188, Test MSE 126.141\n",
      "Epoch 200, lr 1.40625e-05\n",
      "Epoch 200: Train 4.570, Test 4.132\n",
      "MSE NON-NORMALIZED: Train MSE 126.930, Test MSE 124.938\n",
      "Epoch 225, lr 7.03125e-06\n",
      "Epoch 225: Train 4.533, Test 4.102\n",
      "MSE NON-NORMALIZED: Train MSE 126.139, Test MSE 124.071\n",
      "Epoch 250, lr 3.515625e-06\n",
      "Epoch 250: Train 4.523, Test 4.092\n",
      "MSE NON-NORMALIZED: Train MSE 125.843, Test MSE 123.832\n",
      "Epoch 275, lr 1.7578125e-06\n",
      "Epoch 275: Train 4.518, Test 4.086\n",
      "MSE NON-NORMALIZED: Train MSE 125.678, Test MSE 123.713\n",
      "TRAINING MODEL dt_norm_2_15\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 9.681, Test 10.750\n",
      "MSE NON-NORMALIZED: Train MSE 496.213, Test MSE 286.594\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 2.932, Test 3.085\n",
      "MSE NON-NORMALIZED: Train MSE 89.978, Test MSE 77.478\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 2.531, Test 2.796\n",
      "MSE NON-NORMALIZED: Train MSE 76.550, Test MSE 70.746\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 2.508, Test 2.735\n",
      "MSE NON-NORMALIZED: Train MSE 76.412, Test MSE 69.332\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 2.232, Test 2.274\n",
      "MSE NON-NORMALIZED: Train MSE 63.813, Test MSE 57.108\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 2.200, Test 2.258\n",
      "MSE NON-NORMALIZED: Train MSE 63.120, Test MSE 58.004\n",
      "Epoch 150, lr 0.0001125\n",
      "Epoch 150: Train 2.177, Test 2.233\n",
      "MSE NON-NORMALIZED: Train MSE 60.659, Test MSE 58.504\n",
      "Epoch 175, lr 2.8125e-05\n",
      "Epoch 175: Train 2.163, Test 2.218\n",
      "MSE NON-NORMALIZED: Train MSE 59.826, Test MSE 59.126\n",
      "Epoch 200, lr 7.03125e-06\n",
      "Epoch 200: Train 2.158, Test 2.214\n",
      "MSE NON-NORMALIZED: Train MSE 59.735, Test MSE 60.088\n",
      "Epoch 225, lr 1.7578125e-06\n",
      "Epoch 225: Train 2.157, Test 2.212\n",
      "MSE NON-NORMALIZED: Train MSE 59.680, Test MSE 60.065\n",
      "Epoch 250, lr 4.39453125e-07\n",
      "Epoch 250: Train 2.156, Test 2.212\n",
      "MSE NON-NORMALIZED: Train MSE 59.665, Test MSE 60.058\n",
      "Epoch 275, lr 5.4931640625e-08\n",
      "Epoch 275: Train 2.156, Test 2.212\n",
      "MSE NON-NORMALIZED: Train MSE 59.660, Test MSE 60.056\n",
      "TRAINING MODEL dt_norm_2_17\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 15.672, Test 16.342\n",
      "MSE NON-NORMALIZED: Train MSE 773.648, Test MSE 535.971\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 2.961, Test 2.925\n",
      "MSE NON-NORMALIZED: Train MSE 88.462, Test MSE 82.463\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 2.776, Test 2.265\n",
      "MSE NON-NORMALIZED: Train MSE 64.498, Test MSE 56.425\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 2.716, Test 2.235\n",
      "MSE NON-NORMALIZED: Train MSE 58.087, Test MSE 55.517\n",
      "Epoch 100, lr 0.00045\n",
      "Epoch 100: Train 2.661, Test 2.211\n",
      "MSE NON-NORMALIZED: Train MSE 59.003, Test MSE 54.942\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 2.659, Test 2.204\n",
      "MSE NON-NORMALIZED: Train MSE 56.710, Test MSE 55.762\n",
      "Epoch 150, lr 5.625e-05\n",
      "Epoch 150: Train 2.442, Test 2.020\n",
      "MSE NON-NORMALIZED: Train MSE 53.391, Test MSE 51.832\n",
      "Epoch 175, lr 5.625e-05\n",
      "Epoch 175: Train 2.247, Test 1.807\n",
      "MSE NON-NORMALIZED: Train MSE 47.222, Test MSE 47.721\n",
      "Epoch 200, lr 5.625e-05\n",
      "Epoch 200: Train 2.236, Test 1.787\n",
      "MSE NON-NORMALIZED: Train MSE 46.905, Test MSE 48.184\n",
      "Epoch 225, lr 1.40625e-05\n",
      "Epoch 225: Train 2.230, Test 1.780\n",
      "MSE NON-NORMALIZED: Train MSE 46.614, Test MSE 48.006\n",
      "Epoch 250, lr 7.03125e-06\n",
      "Epoch 250: Train 2.229, Test 1.778\n",
      "MSE NON-NORMALIZED: Train MSE 46.541, Test MSE 47.965\n",
      "Epoch 275, lr 7.03125e-06\n",
      "Epoch 275: Train 2.228, Test 1.776\n",
      "MSE NON-NORMALIZED: Train MSE 46.493, Test MSE 47.931\n",
      "TRAINING MODEL dt_norm_2_19\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 25.967, Test 15.881\n",
      "MSE NON-NORMALIZED: Train MSE 1235.710, Test MSE 711.316\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 8.522, Test 5.097\n",
      "MSE NON-NORMALIZED: Train MSE 159.548, Test MSE 157.112\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 8.418, Test 5.018\n",
      "MSE NON-NORMALIZED: Train MSE 156.632, Test MSE 153.880\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 3.691, Test 2.726\n",
      "MSE NON-NORMALIZED: Train MSE 77.835, Test MSE 75.813\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 3.169, Test 2.496\n",
      "MSE NON-NORMALIZED: Train MSE 71.828, Test MSE 70.637\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 2.897, Test 2.353\n",
      "MSE NON-NORMALIZED: Train MSE 68.110, Test MSE 67.749\n",
      "Epoch 150, lr 2.8125e-05\n",
      "Epoch 150: Train 2.884, Test 2.343\n",
      "MSE NON-NORMALIZED: Train MSE 67.796, Test MSE 68.523\n",
      "Epoch 175, lr 1.40625e-05\n",
      "Epoch 175: Train 2.800, Test 2.268\n",
      "MSE NON-NORMALIZED: Train MSE 66.324, Test MSE 67.349\n",
      "Epoch 200, lr 1.40625e-05\n",
      "Epoch 200: Train 2.575, Test 1.942\n",
      "MSE NON-NORMALIZED: Train MSE 58.460, Test MSE 60.610\n",
      "Epoch 225, lr 1.40625e-05\n",
      "Epoch 225: Train 2.490, Test 1.855\n",
      "MSE NON-NORMALIZED: Train MSE 56.650, Test MSE 58.868\n",
      "Epoch 250, lr 1.40625e-05\n",
      "Epoch 250: Train 2.466, Test 1.832\n",
      "MSE NON-NORMALIZED: Train MSE 56.169, Test MSE 58.423\n",
      "Epoch 275, lr 1.40625e-05\n",
      "Epoch 275: Train 2.458, Test 1.824\n",
      "MSE NON-NORMALIZED: Train MSE 56.025, Test MSE 58.289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL dt_norm_2_21\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 5.304, Test 5.722\n",
      "MSE NON-NORMALIZED: Train MSE 558.603, Test MSE 149.270\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 3.077, Test 3.558\n",
      "MSE NON-NORMALIZED: Train MSE 95.238, Test MSE 92.341\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 2.812, Test 3.301\n",
      "MSE NON-NORMALIZED: Train MSE 84.910, Test MSE 83.254\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 2.481, Test 3.014\n",
      "MSE NON-NORMALIZED: Train MSE 77.890, Test MSE 76.281\n",
      "Epoch 100, lr 0.000225\n",
      "Epoch 100: Train 2.416, Test 2.319\n",
      "MSE NON-NORMALIZED: Train MSE 58.041, Test MSE 56.433\n",
      "Epoch 125, lr 5.625e-05\n",
      "Epoch 125: Train 2.411, Test 2.313\n",
      "MSE NON-NORMALIZED: Train MSE 57.619, Test MSE 57.166\n",
      "Epoch 150, lr 5.625e-05\n",
      "Epoch 150: Train 2.194, Test 2.134\n",
      "MSE NON-NORMALIZED: Train MSE 53.346, Test MSE 53.542\n",
      "Epoch 175, lr 5.625e-05\n",
      "Epoch 175: Train 1.791, Test 1.694\n",
      "MSE NON-NORMALIZED: Train MSE 42.610, Test MSE 43.562\n",
      "Epoch 200, lr 5.625e-05\n",
      "Epoch 200: Train 1.774, Test 1.678\n",
      "MSE NON-NORMALIZED: Train MSE 42.384, Test MSE 43.995\n",
      "Epoch 225, lr 5.625e-05\n",
      "Epoch 225: Train 1.767, Test 1.673\n",
      "MSE NON-NORMALIZED: Train MSE 42.277, Test MSE 43.844\n",
      "Epoch 250, lr 2.8125e-05\n",
      "Epoch 250: Train 1.763, Test 1.670\n",
      "MSE NON-NORMALIZED: Train MSE 42.112, Test MSE 43.784\n",
      "Epoch 275, lr 1.40625e-05\n",
      "Epoch 275: Train 1.762, Test 1.668\n",
      "MSE NON-NORMALIZED: Train MSE 42.052, Test MSE 43.750\n",
      "TRAINING MODEL dt_norm_2_23\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 35333\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 8.851, Test 8.540\n",
      "MSE NON-NORMALIZED: Train MSE 708.832, Test MSE 234.499\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 4.207, Test 4.564\n",
      "MSE NON-NORMALIZED: Train MSE 134.881, Test MSE 130.708\n",
      "Epoch 50, lr 5.625e-05\n",
      "Epoch 50: Train 2.555, Test 3.065\n",
      "MSE NON-NORMALIZED: Train MSE 84.133, Test MSE 82.383\n",
      "Epoch 75, lr 5.625e-05\n",
      "Epoch 75: Train 1.637, Test 1.862\n",
      "MSE NON-NORMALIZED: Train MSE 47.596, Test MSE 45.754\n",
      "Epoch 100, lr 5.625e-05\n",
      "Epoch 100: Train 1.561, Test 1.755\n",
      "MSE NON-NORMALIZED: Train MSE 44.971, Test MSE 43.381\n",
      "Epoch 125, lr 5.625e-05\n",
      "Epoch 125: Train 1.251, Test 1.653\n",
      "MSE NON-NORMALIZED: Train MSE 43.157, Test MSE 42.200\n",
      "Epoch 150, lr 5.625e-05\n",
      "Epoch 150: Train 1.215, Test 1.637\n",
      "MSE NON-NORMALIZED: Train MSE 42.932, Test MSE 42.334\n",
      "Epoch 175, lr 2.8125e-05\n",
      "Epoch 175: Train 1.215, Test 1.619\n",
      "MSE NON-NORMALIZED: Train MSE 41.994, Test MSE 42.721\n",
      "Epoch 200, lr 2.8125e-05\n",
      "Epoch 200: Train 1.196, Test 1.562\n",
      "MSE NON-NORMALIZED: Train MSE 40.886, Test MSE 42.032\n",
      "Epoch 225, lr 2.8125e-05\n",
      "Epoch 225: Train 1.189, Test 1.523\n",
      "MSE NON-NORMALIZED: Train MSE 40.096, Test MSE 41.301\n",
      "Epoch 250, lr 2.8125e-05\n",
      "Epoch 250: Train 1.181, Test 1.503\n",
      "MSE NON-NORMALIZED: Train MSE 39.724, Test MSE 40.928\n",
      "Epoch 275, lr 2.8125e-05\n",
      "Epoch 275: Train 1.177, Test 1.496\n",
      "MSE NON-NORMALIZED: Train MSE 39.603, Test MSE 40.807\n",
      "TRAINING MODEL dt_norm_2_25\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 21845\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 9.237, Test 9.430\n",
      "MSE NON-NORMALIZED: Train MSE 350.276, Test MSE 226.818\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 1.762, Test 2.605\n",
      "MSE NON-NORMALIZED: Train MSE 53.560, Test MSE 56.535\n",
      "Epoch 50, lr 5.625e-05\n",
      "Epoch 50: Train 1.452, Test 2.281\n",
      "MSE NON-NORMALIZED: Train MSE 50.709, Test MSE 49.475\n",
      "Epoch 75, lr 2.8125e-05\n",
      "Epoch 75: Train 1.300, Test 2.091\n",
      "MSE NON-NORMALIZED: Train MSE 48.116, Test MSE 45.766\n",
      "Epoch 100, lr 2.8125e-05\n",
      "Epoch 100: Train 0.922, Test 1.340\n",
      "MSE NON-NORMALIZED: Train MSE 32.280, Test MSE 30.682\n",
      "Epoch 125, lr 2.8125e-05\n",
      "Epoch 125: Train 0.877, Test 0.719\n",
      "MSE NON-NORMALIZED: Train MSE 16.086, Test MSE 14.892\n",
      "Epoch 150, lr 2.8125e-05\n",
      "Epoch 150: Train 0.857, Test 0.677\n",
      "MSE NON-NORMALIZED: Train MSE 15.306, Test MSE 14.556\n",
      "Epoch 175, lr 1.40625e-05\n",
      "Epoch 175: Train 0.848, Test 0.665\n",
      "MSE NON-NORMALIZED: Train MSE 15.151, Test MSE 14.739\n",
      "Epoch 200, lr 3.515625e-06\n",
      "Epoch 200: Train 0.845, Test 0.661\n",
      "MSE NON-NORMALIZED: Train MSE 15.134, Test MSE 15.050\n",
      "Epoch 225, lr 8.7890625e-07\n",
      "Epoch 225: Train 0.844, Test 0.660\n",
      "MSE NON-NORMALIZED: Train MSE 15.114, Test MSE 15.028\n",
      "Epoch 250, lr 2.197265625e-07\n",
      "Epoch 250: Train 0.844, Test 0.660\n",
      "MSE NON-NORMALIZED: Train MSE 15.109, Test MSE 15.021\n",
      "Epoch 275, lr 5.4931640625e-08\n",
      "Epoch 275: Train 0.844, Test 0.660\n",
      "MSE NON-NORMALIZED: Train MSE 15.107, Test MSE 15.020\n",
      "TRAINING MODEL dt_norm_2_27\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 19047\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 16.071, Test 14.241\n",
      "MSE NON-NORMALIZED: Train MSE 517.072, Test MSE 408.595\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 3.117, Test 3.559\n",
      "MSE NON-NORMALIZED: Train MSE 78.928, Test MSE 78.487\n",
      "Epoch 50, lr 5.625e-05\n",
      "Epoch 50: Train 3.109, Test 3.551\n",
      "MSE NON-NORMALIZED: Train MSE 78.623, Test MSE 78.224\n",
      "Epoch 75, lr 1.40625e-05\n",
      "Epoch 75: Train 3.107, Test 3.550\n",
      "MSE NON-NORMALIZED: Train MSE 78.602, Test MSE 78.203\n",
      "Epoch 100, lr 1.7578125e-06\n",
      "Epoch 100: Train 3.107, Test 3.550\n",
      "MSE NON-NORMALIZED: Train MSE 78.597, Test MSE 78.196\n",
      "Epoch 125, lr 4.39453125e-07\n",
      "Epoch 125: Train 3.102, Test 3.545\n",
      "MSE NON-NORMALIZED: Train MSE 78.625, Test MSE 78.754\n",
      "Epoch 150, lr 1.0986328125e-07\n",
      "Epoch 150: Train 3.101, Test 3.545\n",
      "MSE NON-NORMALIZED: Train MSE 78.719, Test MSE 79.379\n",
      "Epoch 175, lr 2.74658203125e-08\n",
      "Epoch 175: Train 3.093, Test 3.536\n",
      "MSE NON-NORMALIZED: Train MSE 78.609, Test MSE 79.773\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 3.080, Test 3.526\n",
      "MSE NON-NORMALIZED: Train MSE 78.398, Test MSE 80.070\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 3.065, Test 3.511\n",
      "MSE NON-NORMALIZED: Train MSE 78.011, Test MSE 79.648\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 3.049, Test 3.496\n",
      "MSE NON-NORMALIZED: Train MSE 77.633, Test MSE 79.240\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 3.037, Test 3.485\n",
      "MSE NON-NORMALIZED: Train MSE 77.349, Test MSE 78.939\n",
      "TRAINING MODEL dt_norm_2_29\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 36150\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 1.263, Test 1.953\n",
      "MSE NON-NORMALIZED: Train MSE 68.605, Test MSE 38.475\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 0.605, Test 0.648\n",
      "MSE NON-NORMALIZED: Train MSE 13.536, Test MSE 11.087\n",
      "Epoch 50, lr 0.0001125\n",
      "Epoch 50: Train 0.580, Test 0.589\n",
      "MSE NON-NORMALIZED: Train MSE 12.594, Test MSE 9.949\n",
      "Epoch 75, lr 5.625e-05\n",
      "Epoch 75: Train 0.570, Test 0.528\n",
      "MSE NON-NORMALIZED: Train MSE 11.083, Test MSE 8.677\n",
      "Epoch 100, lr 5.625e-05\n",
      "Epoch 100: Train 0.537, Test 0.522\n",
      "MSE NON-NORMALIZED: Train MSE 10.969, Test MSE 8.562\n",
      "Epoch 125, lr 5.625e-05\n",
      "Epoch 125: Train 0.525, Test 0.520\n",
      "MSE NON-NORMALIZED: Train MSE 10.939, Test MSE 8.760\n",
      "Epoch 150, lr 2.8125e-05\n",
      "Epoch 150: Train 0.520, Test 0.516\n",
      "MSE NON-NORMALIZED: Train MSE 10.908, Test MSE 8.909\n",
      "Epoch 175, lr 2.8125e-05\n",
      "Epoch 175: Train 0.519, Test 0.515\n",
      "MSE NON-NORMALIZED: Train MSE 10.916, Test MSE 9.108\n",
      "Epoch 200, lr 7.03125e-06\n",
      "Epoch 200: Train 0.517, Test 0.513\n",
      "MSE NON-NORMALIZED: Train MSE 10.913, Test MSE 9.280\n",
      "Epoch 225, lr 3.515625e-06\n",
      "Epoch 225: Train 0.516, Test 0.512\n",
      "MSE NON-NORMALIZED: Train MSE 10.905, Test MSE 9.267\n",
      "Epoch 250, lr 3.515625e-06\n",
      "Epoch 250: Train 0.516, Test 0.512\n",
      "MSE NON-NORMALIZED: Train MSE 10.902, Test MSE 9.264\n",
      "Epoch 275, lr 8.7890625e-07\n",
      "Epoch 275: Train 0.516, Test 0.512\n",
      "MSE NON-NORMALIZED: Train MSE 10.897, Test MSE 9.254\n",
      "TRAINING MODEL dt_norm_2_30\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 24996\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 9.263, Test 7.990\n",
      "MSE NON-NORMALIZED: Train MSE 570.451, Test MSE 240.634\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 2.768, Test 2.151\n",
      "MSE NON-NORMALIZED: Train MSE 40.559, Test MSE 46.493\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 2.611, Test 1.879\n",
      "MSE NON-NORMALIZED: Train MSE 43.287, Test MSE 38.814\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 2.594, Test 1.859\n",
      "MSE NON-NORMALIZED: Train MSE 38.592, Test MSE 38.265\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 1.461, Test 1.296\n",
      "MSE NON-NORMALIZED: Train MSE 25.549, Test MSE 25.107\n",
      "Epoch 125, lr 2.8125e-05\n",
      "Epoch 125: Train 1.460, Test 1.295\n",
      "MSE NON-NORMALIZED: Train MSE 25.345, Test MSE 25.499\n",
      "Epoch 150, lr 7.03125e-06\n",
      "Epoch 150: Train 1.458, Test 1.293\n",
      "MSE NON-NORMALIZED: Train MSE 25.324, Test MSE 25.825\n",
      "Epoch 175, lr 1.7578125e-06\n",
      "Epoch 175: Train 1.458, Test 1.292\n",
      "MSE NON-NORMALIZED: Train MSE 25.380, Test MSE 26.231\n",
      "Epoch 200, lr 2.197265625e-07\n",
      "Epoch 200: Train 1.454, Test 1.289\n",
      "MSE NON-NORMALIZED: Train MSE 25.366, Test MSE 26.544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225, lr 2.197265625e-07\n",
      "Epoch 225: Train 1.445, Test 1.277\n",
      "MSE NON-NORMALIZED: Train MSE 25.084, Test MSE 26.199\n",
      "Epoch 250, lr 2.197265625e-07\n",
      "Epoch 250: Train 1.430, Test 1.259\n",
      "MSE NON-NORMALIZED: Train MSE 24.722, Test MSE 25.759\n",
      "Epoch 275, lr 2.197265625e-07\n",
      "Epoch 275: Train 1.421, Test 1.249\n",
      "MSE NON-NORMALIZED: Train MSE 24.507, Test MSE 25.503\n",
      "TRAINING MODEL dt_norm_2_31\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 9924\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 1.277, Test 1.953\n",
      "MSE NON-NORMALIZED: Train MSE 145.792, Test MSE 34.518\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 0.634, Test 0.912\n",
      "MSE NON-NORMALIZED: Train MSE 15.277, Test MSE 15.105\n",
      "Epoch 50, lr 5.625e-05\n",
      "Epoch 50: Train 0.627, Test 0.889\n",
      "MSE NON-NORMALIZED: Train MSE 14.890, Test MSE 14.701\n",
      "Epoch 75, lr 1.40625e-05\n",
      "Epoch 75: Train 0.625, Test 0.883\n",
      "MSE NON-NORMALIZED: Train MSE 14.782, Test MSE 14.595\n",
      "Epoch 100, lr 1.7578125e-06\n",
      "Epoch 100: Train 0.624, Test 0.882\n",
      "MSE NON-NORMALIZED: Train MSE 14.754, Test MSE 14.568\n",
      "Epoch 125, lr 4.39453125e-07\n",
      "Epoch 125: Train 0.623, Test 0.882\n",
      "MSE NON-NORMALIZED: Train MSE 14.778, Test MSE 14.700\n",
      "Epoch 150, lr 1.0986328125e-07\n",
      "Epoch 150: Train 0.623, Test 0.882\n",
      "MSE NON-NORMALIZED: Train MSE 14.807, Test MSE 14.836\n",
      "Epoch 175, lr 2.74658203125e-08\n",
      "Epoch 175: Train 0.623, Test 0.881\n",
      "MSE NON-NORMALIZED: Train MSE 14.838, Test MSE 14.973\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 0.623, Test 0.881\n",
      "MSE NON-NORMALIZED: Train MSE 14.869, Test MSE 15.111\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 0.623, Test 0.881\n",
      "MSE NON-NORMALIZED: Train MSE 14.869, Test MSE 15.110\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 0.623, Test 0.881\n",
      "MSE NON-NORMALIZED: Train MSE 14.868, Test MSE 15.110\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 0.623, Test 0.881\n",
      "MSE NON-NORMALIZED: Train MSE 14.868, Test MSE 15.109\n",
      "TRAINING MODEL dt_norm_2_32\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 8327\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 1.332, Test 3.078\n",
      "MSE NON-NORMALIZED: Train MSE 68.930, Test MSE 69.659\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 1.549, Test 2.913\n",
      "MSE NON-NORMALIZED: Train MSE 62.432, Test MSE 63.227\n",
      "Epoch 50, lr 2.8125e-05\n",
      "Epoch 50: Train 1.536, Test 2.909\n",
      "MSE NON-NORMALIZED: Train MSE 62.405, Test MSE 63.229\n",
      "Epoch 75, lr 7.03125e-06\n",
      "Epoch 75: Train 1.534, Test 2.909\n",
      "MSE NON-NORMALIZED: Train MSE 62.402, Test MSE 63.230\n",
      "Epoch 100, lr 1.7578125e-06\n",
      "Epoch 100: Train 1.533, Test 2.909\n",
      "MSE NON-NORMALIZED: Train MSE 62.401, Test MSE 63.230\n",
      "Epoch 125, lr 2.197265625e-07\n",
      "Epoch 125: Train 1.533, Test 2.909\n",
      "MSE NON-NORMALIZED: Train MSE 62.448, Test MSE 63.422\n",
      "Epoch 150, lr 5.4931640625e-08\n",
      "Epoch 150: Train 1.533, Test 2.909\n",
      "MSE NON-NORMALIZED: Train MSE 62.496, Test MSE 63.614\n",
      "Epoch 175, lr 1.373291015625e-08\n",
      "Epoch 175: Train 1.533, Test 2.909\n",
      "MSE NON-NORMALIZED: Train MSE 62.543, Test MSE 63.805\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 1.533, Test 2.909\n",
      "MSE NON-NORMALIZED: Train MSE 62.590, Test MSE 63.997\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 1.533, Test 2.909\n",
      "MSE NON-NORMALIZED: Train MSE 62.590, Test MSE 63.997\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 1.533, Test 2.909\n",
      "MSE NON-NORMALIZED: Train MSE 62.590, Test MSE 63.997\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 1.533, Test 2.909\n",
      "MSE NON-NORMALIZED: Train MSE 62.590, Test MSE 63.997\n",
      "TRAINING MODEL dt_norm_2_34\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 1.839, Test 4.483\n",
      "MSE NON-NORMALIZED: Train MSE 170.423, Test MSE 124.110\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 1.147, Test 1.595\n",
      "MSE NON-NORMALIZED: Train MSE 35.309, Test MSE 32.039\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 1.186, Test 1.850\n",
      "MSE NON-NORMALIZED: Train MSE 36.837, Test MSE 38.962\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 1.098, Test 1.679\n",
      "MSE NON-NORMALIZED: Train MSE 35.613, Test MSE 34.520\n",
      "Epoch 100, lr 5.625e-05\n",
      "Epoch 100: Train 1.045, Test 1.375\n",
      "MSE NON-NORMALIZED: Train MSE 28.125, Test MSE 26.827\n",
      "Epoch 125, lr 5.625e-05\n",
      "Epoch 125: Train 0.774, Test 0.965\n",
      "MSE NON-NORMALIZED: Train MSE 18.212, Test MSE 17.358\n",
      "Epoch 150, lr 5.625e-05\n",
      "Epoch 150: Train 0.749, Test 0.935\n",
      "MSE NON-NORMALIZED: Train MSE 17.640, Test MSE 17.303\n",
      "Epoch 175, lr 5.625e-05\n",
      "Epoch 175: Train 0.741, Test 0.919\n",
      "MSE NON-NORMALIZED: Train MSE 17.432, Test MSE 17.384\n",
      "Epoch 200, lr 5.625e-05\n",
      "Epoch 200: Train 0.726, Test 0.905\n",
      "MSE NON-NORMALIZED: Train MSE 17.221, Test MSE 17.507\n",
      "Epoch 225, lr 5.625e-05\n",
      "Epoch 225: Train 0.722, Test 0.895\n",
      "MSE NON-NORMALIZED: Train MSE 17.063, Test MSE 17.326\n",
      "Epoch 250, lr 5.625e-05\n",
      "Epoch 250: Train 0.712, Test 0.887\n",
      "MSE NON-NORMALIZED: Train MSE 16.929, Test MSE 17.225\n",
      "Epoch 275, lr 5.625e-05\n",
      "Epoch 275: Train 0.707, Test 0.881\n",
      "MSE NON-NORMALIZED: Train MSE 16.869, Test MSE 17.118\n",
      "TRAINING MODEL dt_norm_2_35\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 3.693, Test 2.756\n",
      "MSE NON-NORMALIZED: Train MSE 83.471, Test MSE 69.189\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 1.491, Test 1.349\n",
      "MSE NON-NORMALIZED: Train MSE 25.828, Test MSE 25.166\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 0.931, Test 0.877\n",
      "MSE NON-NORMALIZED: Train MSE 15.551, Test MSE 15.134\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 0.706, Test 0.712\n",
      "MSE NON-NORMALIZED: Train MSE 12.019, Test MSE 11.790\n",
      "Epoch 100, lr 0.000225\n",
      "Epoch 100: Train 0.693, Test 0.687\n",
      "MSE NON-NORMALIZED: Train MSE 11.352, Test MSE 11.168\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 0.672, Test 0.669\n",
      "MSE NON-NORMALIZED: Train MSE 11.019, Test MSE 10.965\n",
      "Epoch 150, lr 0.000225\n",
      "Epoch 150: Train 0.662, Test 0.662\n",
      "MSE NON-NORMALIZED: Train MSE 10.964, Test MSE 11.059\n",
      "Epoch 175, lr 0.0001125\n",
      "Epoch 175: Train 0.653, Test 0.656\n",
      "MSE NON-NORMALIZED: Train MSE 10.857, Test MSE 11.175\n",
      "Epoch 200, lr 0.0001125\n",
      "Epoch 200: Train 0.646, Test 0.647\n",
      "MSE NON-NORMALIZED: Train MSE 10.702, Test MSE 11.207\n",
      "Epoch 225, lr 0.0001125\n",
      "Epoch 225: Train 0.638, Test 0.640\n",
      "MSE NON-NORMALIZED: Train MSE 10.559, Test MSE 11.114\n",
      "Epoch 250, lr 0.0001125\n",
      "Epoch 250: Train 0.629, Test 0.631\n",
      "MSE NON-NORMALIZED: Train MSE 10.423, Test MSE 10.906\n",
      "Epoch 275, lr 0.0001125\n",
      "Epoch 275: Train 0.617, Test 0.620\n",
      "MSE NON-NORMALIZED: Train MSE 10.225, Test MSE 10.687\n",
      "TRAINING MODEL dt_norm_2_36\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 4.185, Test 3.067\n",
      "MSE NON-NORMALIZED: Train MSE 114.350, Test MSE 76.049\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 1.062, Test 1.083\n",
      "MSE NON-NORMALIZED: Train MSE 20.412, Test MSE 19.798\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 1.044, Test 1.228\n",
      "MSE NON-NORMALIZED: Train MSE 25.409, Test MSE 22.908\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 0.947, Test 1.057\n",
      "MSE NON-NORMALIZED: Train MSE 20.368, Test MSE 19.566\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 0.704, Test 0.682\n",
      "MSE NON-NORMALIZED: Train MSE 11.945, Test MSE 11.250\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 0.663, Test 0.633\n",
      "MSE NON-NORMALIZED: Train MSE 11.064, Test MSE 10.613\n",
      "Epoch 150, lr 0.0001125\n",
      "Epoch 150: Train 0.639, Test 0.605\n",
      "MSE NON-NORMALIZED: Train MSE 10.567, Test MSE 10.336\n",
      "Epoch 175, lr 0.0001125\n",
      "Epoch 175: Train 0.613, Test 0.561\n",
      "MSE NON-NORMALIZED: Train MSE 9.778, Test MSE 9.740\n",
      "Epoch 200, lr 0.0001125\n",
      "Epoch 200: Train 0.567, Test 0.526\n",
      "MSE NON-NORMALIZED: Train MSE 9.123, Test MSE 9.297\n",
      "Epoch 225, lr 0.0001125\n",
      "Epoch 225: Train 0.549, Test 0.517\n",
      "MSE NON-NORMALIZED: Train MSE 8.978, Test MSE 9.158\n",
      "Epoch 250, lr 0.0001125\n",
      "Epoch 250: Train 0.543, Test 0.513\n",
      "MSE NON-NORMALIZED: Train MSE 8.911, Test MSE 9.098\n",
      "Epoch 275, lr 0.0001125\n",
      "Epoch 275: Train 0.536, Test 0.509\n",
      "MSE NON-NORMALIZED: Train MSE 8.809, Test MSE 9.043\n",
      "TRAINING MODEL dt_norm_2_37\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 3.110, Test 2.638\n",
      "MSE NON-NORMALIZED: Train MSE 90.336, Test MSE 58.871\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 2.153, Test 1.794\n",
      "MSE NON-NORMALIZED: Train MSE 33.701, Test MSE 34.300\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 1.648, Test 1.009\n",
      "MSE NON-NORMALIZED: Train MSE 18.877, Test MSE 18.505\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 0.946, Test 0.753\n",
      "MSE NON-NORMALIZED: Train MSE 13.703, Test MSE 13.648\n",
      "Epoch 100, lr 0.00045\n",
      "Epoch 100: Train 0.883, Test 0.687\n",
      "MSE NON-NORMALIZED: Train MSE 12.560, Test MSE 12.468\n",
      "Epoch 125, lr 0.00045\n",
      "Epoch 125: Train 0.829, Test 0.651\n",
      "MSE NON-NORMALIZED: Train MSE 11.894, Test MSE 12.184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, lr 0.00045\n",
      "Epoch 150: Train 0.716, Test 0.535\n",
      "MSE NON-NORMALIZED: Train MSE 9.859, Test MSE 10.328\n",
      "Epoch 175, lr 0.00045\n",
      "Epoch 175: Train 0.707, Test 0.509\n",
      "MSE NON-NORMALIZED: Train MSE 9.026, Test MSE 9.834\n",
      "Epoch 200, lr 0.00045\n",
      "Epoch 200: Train 0.683, Test 0.500\n",
      "MSE NON-NORMALIZED: Train MSE 9.174, Test MSE 10.049\n",
      "Epoch 225, lr 0.000225\n",
      "Epoch 225: Train 0.681, Test 0.487\n",
      "MSE NON-NORMALIZED: Train MSE 8.769, Test MSE 9.646\n",
      "Epoch 250, lr 0.000225\n",
      "Epoch 250: Train 0.672, Test 0.480\n",
      "MSE NON-NORMALIZED: Train MSE 8.555, Test MSE 9.388\n",
      "Epoch 275, lr 0.000225\n",
      "Epoch 275: Train 0.670, Test 0.479\n",
      "MSE NON-NORMALIZED: Train MSE 8.534, Test MSE 9.362\n",
      "TRAINING MODEL dt_norm_2_38\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 13487\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 2.364, Test 3.420\n",
      "MSE NON-NORMALIZED: Train MSE 117.130, Test MSE 88.777\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 0.337, Test 0.373\n",
      "MSE NON-NORMALIZED: Train MSE 5.766, Test MSE 5.722\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 0.335, Test 0.364\n",
      "MSE NON-NORMALIZED: Train MSE 5.657, Test MSE 5.568\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 0.330, Test 0.358\n",
      "MSE NON-NORMALIZED: Train MSE 5.580, Test MSE 5.463\n",
      "Epoch 100, lr 5.625e-05\n",
      "Epoch 100: Train 0.328, Test 0.354\n",
      "MSE NON-NORMALIZED: Train MSE 5.532, Test MSE 5.397\n",
      "Epoch 125, lr 1.40625e-05\n",
      "Epoch 125: Train 0.325, Test 0.352\n",
      "MSE NON-NORMALIZED: Train MSE 5.518, Test MSE 5.429\n",
      "Epoch 150, lr 1.40625e-05\n",
      "Epoch 150: Train 0.322, Test 0.350\n",
      "MSE NON-NORMALIZED: Train MSE 5.494, Test MSE 5.451\n",
      "Epoch 175, lr 7.03125e-06\n",
      "Epoch 175: Train 0.319, Test 0.348\n",
      "MSE NON-NORMALIZED: Train MSE 5.474, Test MSE 5.476\n",
      "Epoch 200, lr 1.7578125e-06\n",
      "Epoch 200: Train 0.319, Test 0.347\n",
      "MSE NON-NORMALIZED: Train MSE 5.483, Test MSE 5.532\n",
      "Epoch 225, lr 4.39453125e-07\n",
      "Epoch 225: Train 0.318, Test 0.347\n",
      "MSE NON-NORMALIZED: Train MSE 5.482, Test MSE 5.531\n",
      "Epoch 250, lr 5.4931640625e-08\n",
      "Epoch 250: Train 0.318, Test 0.347\n",
      "MSE NON-NORMALIZED: Train MSE 5.481, Test MSE 5.531\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 0.318, Test 0.347\n",
      "MSE NON-NORMALIZED: Train MSE 5.481, Test MSE 5.531\n",
      "TRAINING MODEL dt_norm_2_39\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 8335\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 5.016, Test 3.773\n",
      "MSE NON-NORMALIZED: Train MSE 87.423, Test MSE 86.955\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 4.668, Test 3.641\n",
      "MSE NON-NORMALIZED: Train MSE 81.496, Test MSE 81.150\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 4.668, Test 3.642\n",
      "MSE NON-NORMALIZED: Train MSE 81.477, Test MSE 81.126\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 4.668, Test 3.643\n",
      "MSE NON-NORMALIZED: Train MSE 81.471, Test MSE 81.116\n",
      "Epoch 100, lr 0.00045\n",
      "Epoch 100: Train 4.668, Test 3.645\n",
      "MSE NON-NORMALIZED: Train MSE 81.464, Test MSE 81.108\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 4.669, Test 3.650\n",
      "MSE NON-NORMALIZED: Train MSE 81.502, Test MSE 81.328\n",
      "Epoch 150, lr 5.625e-05\n",
      "Epoch 150: Train 4.668, Test 3.652\n",
      "MSE NON-NORMALIZED: Train MSE 81.547, Test MSE 81.559\n",
      "Epoch 175, lr 1.40625e-05\n",
      "Epoch 175: Train 4.668, Test 3.653\n",
      "MSE NON-NORMALIZED: Train MSE 81.603, Test MSE 81.795\n",
      "Epoch 200, lr 1.7578125e-06\n",
      "Epoch 200: Train 4.668, Test 3.653\n",
      "MSE NON-NORMALIZED: Train MSE 81.661, Test MSE 82.032\n",
      "Epoch 225, lr 4.39453125e-07\n",
      "Epoch 225: Train 4.668, Test 3.653\n",
      "MSE NON-NORMALIZED: Train MSE 81.660, Test MSE 82.032\n",
      "Epoch 250, lr 1.0986328125e-07\n",
      "Epoch 250: Train 4.668, Test 3.653\n",
      "MSE NON-NORMALIZED: Train MSE 81.660, Test MSE 82.032\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 4.668, Test 3.653\n",
      "MSE NON-NORMALIZED: Train MSE 81.660, Test MSE 82.032\n",
      "TRAINING MODEL dt_norm_2_40\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 11106\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 2.916, Test 2.188\n",
      "MSE NON-NORMALIZED: Train MSE 42.040, Test MSE 41.960\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 2.725, Test 2.094\n",
      "MSE NON-NORMALIZED: Train MSE 39.612, Test MSE 39.559\n",
      "Epoch 50, lr 2.8125e-05\n",
      "Epoch 50: Train 2.725, Test 2.094\n",
      "MSE NON-NORMALIZED: Train MSE 39.603, Test MSE 39.556\n",
      "Epoch 75, lr 7.03125e-06\n",
      "Epoch 75: Train 2.724, Test 2.094\n",
      "MSE NON-NORMALIZED: Train MSE 39.602, Test MSE 39.556\n",
      "Epoch 100, lr 1.7578125e-06\n",
      "Epoch 100: Train 2.724, Test 2.094\n",
      "MSE NON-NORMALIZED: Train MSE 39.601, Test MSE 39.556\n",
      "Epoch 125, lr 4.39453125e-07\n",
      "Epoch 125: Train 2.724, Test 2.094\n",
      "MSE NON-NORMALIZED: Train MSE 39.635, Test MSE 39.711\n",
      "Epoch 150, lr 5.4931640625e-08\n",
      "Epoch 150: Train 2.724, Test 2.094\n",
      "MSE NON-NORMALIZED: Train MSE 39.668, Test MSE 39.867\n",
      "Epoch 175, lr 1.373291015625e-08\n",
      "Epoch 175: Train 2.724, Test 2.094\n",
      "MSE NON-NORMALIZED: Train MSE 39.702, Test MSE 40.022\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 2.724, Test 2.094\n",
      "MSE NON-NORMALIZED: Train MSE 39.735, Test MSE 40.177\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 2.724, Test 2.094\n",
      "MSE NON-NORMALIZED: Train MSE 39.735, Test MSE 40.177\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 2.724, Test 2.094\n",
      "MSE NON-NORMALIZED: Train MSE 39.735, Test MSE 40.177\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 2.724, Test 2.094\n",
      "MSE NON-NORMALIZED: Train MSE 39.735, Test MSE 40.177\n",
      "TRAINING MODEL dt_norm_2_41\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 12696\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 0.752, Test 1.860\n",
      "MSE NON-NORMALIZED: Train MSE 37.141, Test MSE 36.333\n",
      "Epoch 25, lr 0.0001125\n",
      "Epoch 25: Train 0.771, Test 1.850\n",
      "MSE NON-NORMALIZED: Train MSE 35.970, Test MSE 36.021\n",
      "Epoch 50, lr 2.8125e-05\n",
      "Epoch 50: Train 0.770, Test 1.850\n",
      "MSE NON-NORMALIZED: Train MSE 35.966, Test MSE 36.021\n",
      "Epoch 75, lr 7.03125e-06\n",
      "Epoch 75: Train 0.770, Test 1.850\n",
      "MSE NON-NORMALIZED: Train MSE 35.965, Test MSE 36.021\n",
      "Epoch 100, lr 8.7890625e-07\n",
      "Epoch 100: Train 0.770, Test 1.850\n",
      "MSE NON-NORMALIZED: Train MSE 35.965, Test MSE 36.021\n",
      "Epoch 125, lr 2.197265625e-07\n",
      "Epoch 125: Train 0.770, Test 1.850\n",
      "MSE NON-NORMALIZED: Train MSE 35.998, Test MSE 36.184\n",
      "Epoch 150, lr 5.4931640625e-08\n",
      "Epoch 150: Train 0.770, Test 1.850\n",
      "MSE NON-NORMALIZED: Train MSE 36.030, Test MSE 36.346\n",
      "Epoch 175, lr 1.373291015625e-08\n",
      "Epoch 175: Train 0.770, Test 1.850\n",
      "MSE NON-NORMALIZED: Train MSE 36.063, Test MSE 36.509\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 0.770, Test 1.850\n",
      "MSE NON-NORMALIZED: Train MSE 36.096, Test MSE 36.671\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 0.770, Test 1.850\n",
      "MSE NON-NORMALIZED: Train MSE 36.096, Test MSE 36.671\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 0.770, Test 1.850\n",
      "MSE NON-NORMALIZED: Train MSE 36.096, Test MSE 36.671\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 0.770, Test 1.850\n",
      "MSE NON-NORMALIZED: Train MSE 36.096, Test MSE 36.671\n",
      "TRAINING MODEL dt_norm_2_42\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 5153\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 0.600, Test 0.594\n",
      "MSE NON-NORMALIZED: Train MSE 9.406, Test MSE 9.334\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 0.581, Test 0.577\n",
      "MSE NON-NORMALIZED: Train MSE 9.075, Test MSE 9.087\n",
      "Epoch 50, lr 0.0001125\n",
      "Epoch 50: Train 0.581, Test 0.577\n",
      "MSE NON-NORMALIZED: Train MSE 9.072, Test MSE 9.087\n",
      "Epoch 75, lr 2.8125e-05\n",
      "Epoch 75: Train 0.581, Test 0.578\n",
      "MSE NON-NORMALIZED: Train MSE 9.071, Test MSE 9.086\n",
      "Epoch 100, lr 7.03125e-06\n",
      "Epoch 100: Train 0.581, Test 0.578\n",
      "MSE NON-NORMALIZED: Train MSE 9.071, Test MSE 9.086\n",
      "Epoch 125, lr 1.7578125e-06\n",
      "Epoch 125: Train 0.581, Test 0.578\n",
      "MSE NON-NORMALIZED: Train MSE 9.091, Test MSE 9.148\n",
      "Epoch 150, lr 4.39453125e-07\n",
      "Epoch 150: Train 0.581, Test 0.578\n",
      "MSE NON-NORMALIZED: Train MSE 9.110, Test MSE 9.209\n",
      "Epoch 175, lr 5.4931640625e-08\n",
      "Epoch 175: Train 0.581, Test 0.578\n",
      "MSE NON-NORMALIZED: Train MSE 9.130, Test MSE 9.271\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 0.581, Test 0.578\n",
      "MSE NON-NORMALIZED: Train MSE 9.149, Test MSE 9.332\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 0.581, Test 0.578\n",
      "MSE NON-NORMALIZED: Train MSE 9.149, Test MSE 9.332\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 0.581, Test 0.578\n",
      "MSE NON-NORMALIZED: Train MSE 9.149, Test MSE 9.332\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 0.581, Test 0.578\n",
      "MSE NON-NORMALIZED: Train MSE 9.149, Test MSE 9.332\n",
      "TRAINING MODEL dt_norm_2_43\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 3968\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 2.137, Test 1.048\n",
      "MSE NON-NORMALIZED: Train MSE 19.925, Test MSE 18.767\n",
      "Epoch 25, lr 0.0001125\n",
      "Epoch 25: Train 2.155, Test 1.028\n",
      "MSE NON-NORMALIZED: Train MSE 19.210, Test MSE 18.516\n",
      "Epoch 50, lr 2.8125e-05\n",
      "Epoch 50: Train 2.152, Test 1.029\n",
      "MSE NON-NORMALIZED: Train MSE 19.207, Test MSE 18.516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, lr 7.03125e-06\n",
      "Epoch 75: Train 2.151, Test 1.029\n",
      "MSE NON-NORMALIZED: Train MSE 19.206, Test MSE 18.516\n",
      "Epoch 100, lr 8.7890625e-07\n",
      "Epoch 100: Train 2.151, Test 1.029\n",
      "MSE NON-NORMALIZED: Train MSE 19.206, Test MSE 18.516\n",
      "Epoch 125, lr 2.197265625e-07\n",
      "Epoch 125: Train 2.151, Test 1.029\n",
      "MSE NON-NORMALIZED: Train MSE 19.232, Test MSE 18.589\n",
      "Epoch 150, lr 5.4931640625e-08\n",
      "Epoch 150: Train 2.151, Test 1.029\n",
      "MSE NON-NORMALIZED: Train MSE 19.257, Test MSE 18.661\n",
      "Epoch 175, lr 1.373291015625e-08\n",
      "Epoch 175: Train 2.151, Test 1.029\n",
      "MSE NON-NORMALIZED: Train MSE 19.283, Test MSE 18.734\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 2.151, Test 1.029\n",
      "MSE NON-NORMALIZED: Train MSE 19.309, Test MSE 18.806\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 2.151, Test 1.029\n",
      "MSE NON-NORMALIZED: Train MSE 19.309, Test MSE 18.806\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 2.151, Test 1.029\n",
      "MSE NON-NORMALIZED: Train MSE 19.309, Test MSE 18.806\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 2.151, Test 1.029\n",
      "MSE NON-NORMALIZED: Train MSE 19.309, Test MSE 18.806\n",
      "TRAINING MODEL dt_norm_2_44\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 2380\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 0.357, Test 0.340\n",
      "MSE NON-NORMALIZED: Train MSE 5.136, Test MSE 5.059\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 0.315, Test 0.299\n",
      "MSE NON-NORMALIZED: Train MSE 4.382, Test MSE 4.352\n",
      "Epoch 50, lr 0.0001125\n",
      "Epoch 50: Train 0.315, Test 0.299\n",
      "MSE NON-NORMALIZED: Train MSE 4.380, Test MSE 4.351\n",
      "Epoch 75, lr 2.8125e-05\n",
      "Epoch 75: Train 0.315, Test 0.299\n",
      "MSE NON-NORMALIZED: Train MSE 4.379, Test MSE 4.351\n",
      "Epoch 100, lr 7.03125e-06\n",
      "Epoch 100: Train 0.315, Test 0.299\n",
      "MSE NON-NORMALIZED: Train MSE 4.379, Test MSE 4.351\n",
      "Epoch 125, lr 8.7890625e-07\n",
      "Epoch 125: Train 0.315, Test 0.299\n",
      "MSE NON-NORMALIZED: Train MSE 4.390, Test MSE 4.374\n",
      "Epoch 150, lr 2.197265625e-07\n",
      "Epoch 150: Train 0.315, Test 0.299\n",
      "MSE NON-NORMALIZED: Train MSE 4.400, Test MSE 4.397\n",
      "Epoch 175, lr 5.4931640625e-08\n",
      "Epoch 175: Train 0.315, Test 0.299\n",
      "MSE NON-NORMALIZED: Train MSE 4.411, Test MSE 4.420\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 0.315, Test 0.299\n",
      "MSE NON-NORMALIZED: Train MSE 4.421, Test MSE 4.443\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 0.315, Test 0.299\n",
      "MSE NON-NORMALIZED: Train MSE 4.421, Test MSE 4.443\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 0.315, Test 0.299\n",
      "MSE NON-NORMALIZED: Train MSE 4.421, Test MSE 4.443\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 0.315, Test 0.299\n",
      "MSE NON-NORMALIZED: Train MSE 4.421, Test MSE 4.443\n",
      "TRAINING MODEL dt_norm_2_45\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 3969\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 1.995, Test 1.613\n",
      "MSE NON-NORMALIZED: Train MSE 32.485, Test MSE 30.562\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 0.103, Test 0.158\n",
      "MSE NON-NORMALIZED: Train MSE 2.285, Test MSE 2.205\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 0.099, Test 0.157\n",
      "MSE NON-NORMALIZED: Train MSE 2.252, Test MSE 2.174\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 0.100, Test 0.157\n",
      "MSE NON-NORMALIZED: Train MSE 2.246, Test MSE 2.183\n",
      "Epoch 100, lr 2.8125e-05\n",
      "Epoch 100: Train 0.100, Test 0.157\n",
      "MSE NON-NORMALIZED: Train MSE 2.245, Test MSE 2.186\n",
      "Epoch 125, lr 7.03125e-06\n",
      "Epoch 125: Train 0.100, Test 0.157\n",
      "MSE NON-NORMALIZED: Train MSE 2.251, Test MSE 2.202\n",
      "Epoch 150, lr 8.7890625e-07\n",
      "Epoch 150: Train 0.100, Test 0.157\n",
      "MSE NON-NORMALIZED: Train MSE 2.257, Test MSE 2.218\n",
      "Epoch 175, lr 2.197265625e-07\n",
      "Epoch 175: Train 0.100, Test 0.157\n",
      "MSE NON-NORMALIZED: Train MSE 2.263, Test MSE 2.235\n",
      "Epoch 200, lr 5.4931640625e-08\n",
      "Epoch 200: Train 0.100, Test 0.157\n",
      "MSE NON-NORMALIZED: Train MSE 2.269, Test MSE 2.251\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 0.100, Test 0.157\n",
      "MSE NON-NORMALIZED: Train MSE 2.269, Test MSE 2.251\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 0.100, Test 0.157\n",
      "MSE NON-NORMALIZED: Train MSE 2.269, Test MSE 2.251\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 0.100, Test 0.157\n",
      "MSE NON-NORMALIZED: Train MSE 2.269, Test MSE 2.251\n",
      "TRAINING MODEL dt_norm_3_1\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 21828\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 87.579, Test 90.665\n",
      "MSE NON-NORMALIZED: Train MSE 10292.687, Test MSE 4747.121\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 41.879, Test 47.031\n",
      "MSE NON-NORMALIZED: Train MSE 2777.321, Test MSE 2799.824\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 41.905, Test 47.044\n",
      "MSE NON-NORMALIZED: Train MSE 2775.453, Test MSE 2802.146\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 41.344, Test 44.513\n",
      "MSE NON-NORMALIZED: Train MSE 2685.422, Test MSE 2707.724\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 37.361, Test 17.226\n",
      "MSE NON-NORMALIZED: Train MSE 964.058, Test MSE 956.061\n",
      "Epoch 125, lr 5.625e-05\n",
      "Epoch 125: Train 35.606, Test 15.951\n",
      "MSE NON-NORMALIZED: Train MSE 923.161, Test MSE 916.919\n",
      "Epoch 150, lr 1.40625e-05\n",
      "Epoch 150: Train 35.592, Test 15.933\n",
      "MSE NON-NORMALIZED: Train MSE 921.854, Test MSE 917.388\n",
      "Epoch 175, lr 3.515625e-06\n",
      "Epoch 175: Train 35.592, Test 15.932\n",
      "MSE NON-NORMALIZED: Train MSE 921.989, Test MSE 918.740\n",
      "Epoch 200, lr 8.7890625e-07\n",
      "Epoch 200: Train 35.591, Test 15.932\n",
      "MSE NON-NORMALIZED: Train MSE 922.186, Test MSE 920.149\n",
      "Epoch 225, lr 1.0986328125e-07\n",
      "Epoch 225: Train 35.590, Test 15.931\n",
      "MSE NON-NORMALIZED: Train MSE 922.167, Test MSE 920.132\n",
      "Epoch 250, lr 2.74658203125e-08\n",
      "Epoch 250: Train 35.590, Test 15.930\n",
      "MSE NON-NORMALIZED: Train MSE 922.152, Test MSE 920.108\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 35.585, Test 15.925\n",
      "MSE NON-NORMALIZED: Train MSE 921.990, Test MSE 919.931\n",
      "TRAINING MODEL dt_norm_3_3\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 30.552, Test 32.653\n",
      "MSE NON-NORMALIZED: Train MSE 3312.873, Test MSE 1489.374\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 9.098, Test 9.812\n",
      "MSE NON-NORMALIZED: Train MSE 342.854, Test MSE 376.008\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 8.098, Test 8.818\n",
      "MSE NON-NORMALIZED: Train MSE 312.510, Test MSE 326.330\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 6.883, Test 7.369\n",
      "MSE NON-NORMALIZED: Train MSE 274.416, Test MSE 268.141\n",
      "Epoch 100, lr 5.625e-05\n",
      "Epoch 100: Train 6.623, Test 6.995\n",
      "MSE NON-NORMALIZED: Train MSE 258.279, Test MSE 255.662\n",
      "Epoch 125, lr 1.40625e-05\n",
      "Epoch 125: Train 6.599, Test 6.943\n",
      "MSE NON-NORMALIZED: Train MSE 256.890, Test MSE 255.412\n",
      "Epoch 150, lr 3.515625e-06\n",
      "Epoch 150: Train 6.590, Test 6.924\n",
      "MSE NON-NORMALIZED: Train MSE 256.076, Test MSE 256.201\n",
      "Epoch 175, lr 8.7890625e-07\n",
      "Epoch 175: Train 6.587, Test 6.921\n",
      "MSE NON-NORMALIZED: Train MSE 256.154, Test MSE 257.953\n",
      "Epoch 200, lr 2.197265625e-07\n",
      "Epoch 200: Train 6.586, Test 6.920\n",
      "MSE NON-NORMALIZED: Train MSE 256.338, Test MSE 259.768\n",
      "Epoch 225, lr 5.4931640625e-08\n",
      "Epoch 225: Train 6.586, Test 6.920\n",
      "MSE NON-NORMALIZED: Train MSE 256.332, Test MSE 259.763\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 6.586, Test 6.920\n",
      "MSE NON-NORMALIZED: Train MSE 256.330, Test MSE 259.762\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 6.586, Test 6.920\n",
      "MSE NON-NORMALIZED: Train MSE 256.330, Test MSE 259.762\n",
      "TRAINING MODEL dt_norm_3_5\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 49.104, Test 59.928\n",
      "MSE NON-NORMALIZED: Train MSE 10939.490, Test MSE 4305.979\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 29.876, Test 26.875\n",
      "MSE NON-NORMALIZED: Train MSE 1845.923, Test MSE 1749.912\n",
      "Epoch 50, lr 5.625e-05\n",
      "Epoch 50: Train 24.794, Test 21.674\n",
      "MSE NON-NORMALIZED: Train MSE 1571.045, Test MSE 1366.434\n",
      "Epoch 75, lr 7.03125e-06\n",
      "Epoch 75: Train 22.795, Test 17.679\n",
      "MSE NON-NORMALIZED: Train MSE 1236.802, Test MSE 1041.534\n",
      "Epoch 100, lr 1.7578125e-06\n",
      "Epoch 100: Train 22.059, Test 16.682\n",
      "MSE NON-NORMALIZED: Train MSE 1159.809, Test MSE 987.602\n",
      "Epoch 125, lr 4.39453125e-07\n",
      "Epoch 125: Train 21.772, Test 15.425\n",
      "MSE NON-NORMALIZED: Train MSE 1083.169, Test MSE 914.707\n",
      "Epoch 150, lr 1.0986328125e-07\n",
      "Epoch 150: Train 21.717, Test 15.280\n",
      "MSE NON-NORMALIZED: Train MSE 1074.234, Test MSE 908.621\n",
      "Epoch 175, lr 1.373291015625e-08\n",
      "Epoch 175: Train 21.706, Test 15.253\n",
      "MSE NON-NORMALIZED: Train MSE 1072.780, Test MSE 909.330\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 21.702, Test 15.246\n",
      "MSE NON-NORMALIZED: Train MSE 1072.571, Test MSE 911.119\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 21.699, Test 15.238\n",
      "MSE NON-NORMALIZED: Train MSE 1072.113, Test MSE 910.696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 21.696, Test 15.231\n",
      "MSE NON-NORMALIZED: Train MSE 1071.664, Test MSE 910.280\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 21.692, Test 15.224\n",
      "MSE NON-NORMALIZED: Train MSE 1071.221, Test MSE 909.870\n",
      "TRAINING MODEL dt_norm_3_7\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 69.040, Test 64.903\n",
      "MSE NON-NORMALIZED: Train MSE 18348.966, Test MSE 6052.513\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 29.158, Test 39.641\n",
      "MSE NON-NORMALIZED: Train MSE 3775.450, Test MSE 3085.091\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 21.334, Test 30.214\n",
      "MSE NON-NORMALIZED: Train MSE 2938.730, Test MSE 2293.831\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 19.814, Test 29.818\n",
      "MSE NON-NORMALIZED: Train MSE 2605.086, Test MSE 2194.142\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 17.774, Test 28.909\n",
      "MSE NON-NORMALIZED: Train MSE 2611.328, Test MSE 2123.559\n",
      "Epoch 125, lr 5.625e-05\n",
      "Epoch 125: Train 14.393, Test 17.095\n",
      "MSE NON-NORMALIZED: Train MSE 1179.566, Test MSE 1052.053\n",
      "Epoch 150, lr 5.625e-05\n",
      "Epoch 150: Train 7.244, Test 8.704\n",
      "MSE NON-NORMALIZED: Train MSE 580.734, Test MSE 538.581\n",
      "Epoch 175, lr 5.625e-05\n",
      "Epoch 175: Train 4.712, Test 7.304\n",
      "MSE NON-NORMALIZED: Train MSE 500.250, Test MSE 478.180\n",
      "Epoch 200, lr 5.625e-05\n",
      "Epoch 200: Train 4.367, Test 7.057\n",
      "MSE NON-NORMALIZED: Train MSE 489.690, Test MSE 495.718\n",
      "Epoch 225, lr 5.625e-05\n",
      "Epoch 225: Train 4.156, Test 6.762\n",
      "MSE NON-NORMALIZED: Train MSE 496.600, Test MSE 460.394\n",
      "Epoch 250, lr 5.625e-05\n",
      "Epoch 250: Train 3.897, Test 6.536\n",
      "MSE NON-NORMALIZED: Train MSE 466.824, Test MSE 455.291\n",
      "Epoch 275, lr 2.8125e-05\n",
      "Epoch 275: Train 3.754, Test 6.420\n",
      "MSE NON-NORMALIZED: Train MSE 451.611, Test MSE 458.533\n",
      "TRAINING MODEL dt_norm_3_9\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 170.539, Test 100.372\n",
      "MSE NON-NORMALIZED: Train MSE 23047.685, Test MSE 12318.787\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 70.057, Test 32.006\n",
      "MSE NON-NORMALIZED: Train MSE 4458.163, Test MSE 4918.666\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 14.618, Test 10.247\n",
      "MSE NON-NORMALIZED: Train MSE 1331.802, Test MSE 1151.983\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 7.074, Test 7.918\n",
      "MSE NON-NORMALIZED: Train MSE 970.823, Test MSE 973.165\n",
      "Epoch 100, lr 0.000225\n",
      "Epoch 100: Train 4.991, Test 5.767\n",
      "MSE NON-NORMALIZED: Train MSE 520.867, Test MSE 445.705\n",
      "Epoch 125, lr 0.000225\n",
      "Epoch 125: Train 4.151, Test 4.987\n",
      "MSE NON-NORMALIZED: Train MSE 328.341, Test MSE 291.008\n",
      "Epoch 150, lr 5.625e-05\n",
      "Epoch 150: Train 4.059, Test 4.869\n",
      "MSE NON-NORMALIZED: Train MSE 301.792, Test MSE 287.248\n",
      "Epoch 175, lr 2.8125e-05\n",
      "Epoch 175: Train 3.998, Test 4.825\n",
      "MSE NON-NORMALIZED: Train MSE 298.019, Test MSE 287.034\n",
      "Epoch 200, lr 1.40625e-05\n",
      "Epoch 200: Train 4.004, Test 4.604\n",
      "MSE NON-NORMALIZED: Train MSE 279.274, Test MSE 274.552\n",
      "Epoch 225, lr 3.515625e-06\n",
      "Epoch 225: Train 4.011, Test 4.522\n",
      "MSE NON-NORMALIZED: Train MSE 275.804, Test MSE 271.525\n",
      "Epoch 250, lr 8.7890625e-07\n",
      "Epoch 250: Train 4.010, Test 4.496\n",
      "MSE NON-NORMALIZED: Train MSE 274.780, Test MSE 270.515\n",
      "Epoch 275, lr 1.0986328125e-07\n",
      "Epoch 275: Train 4.010, Test 4.489\n",
      "MSE NON-NORMALIZED: Train MSE 274.537, Test MSE 270.300\n",
      "TRAINING MODEL dt_norm_3_11\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 29.385, Test 39.810\n",
      "MSE NON-NORMALIZED: Train MSE 7899.090, Test MSE 2424.715\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 14.920, Test 19.213\n",
      "MSE NON-NORMALIZED: Train MSE 1404.832, Test MSE 1241.114\n",
      "Epoch 50, lr 0.0001125\n",
      "Epoch 50: Train 6.339, Test 10.548\n",
      "MSE NON-NORMALIZED: Train MSE 778.705, Test MSE 757.317\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 5.572, Test 5.363\n",
      "MSE NON-NORMALIZED: Train MSE 346.063, Test MSE 324.816\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 5.569, Test 5.453\n",
      "MSE NON-NORMALIZED: Train MSE 333.128, Test MSE 334.888\n",
      "Epoch 125, lr 5.625e-05\n",
      "Epoch 125: Train 5.094, Test 4.810\n",
      "MSE NON-NORMALIZED: Train MSE 312.674, Test MSE 296.566\n",
      "Epoch 150, lr 2.8125e-05\n",
      "Epoch 150: Train 5.059, Test 4.776\n",
      "MSE NON-NORMALIZED: Train MSE 306.405, Test MSE 295.336\n",
      "Epoch 175, lr 7.03125e-06\n",
      "Epoch 175: Train 5.020, Test 4.723\n",
      "MSE NON-NORMALIZED: Train MSE 304.638, Test MSE 293.622\n",
      "Epoch 200, lr 7.03125e-06\n",
      "Epoch 200: Train 5.008, Test 4.714\n",
      "MSE NON-NORMALIZED: Train MSE 304.506, Test MSE 294.869\n",
      "Epoch 225, lr 7.03125e-06\n",
      "Epoch 225: Train 5.000, Test 4.709\n",
      "MSE NON-NORMALIZED: Train MSE 304.433, Test MSE 294.802\n",
      "Epoch 250, lr 7.03125e-06\n",
      "Epoch 250: Train 4.994, Test 4.705\n",
      "MSE NON-NORMALIZED: Train MSE 304.275, Test MSE 294.680\n",
      "Epoch 275, lr 7.03125e-06\n",
      "Epoch 275: Train 4.988, Test 4.699\n",
      "MSE NON-NORMALIZED: Train MSE 304.130, Test MSE 294.518\n",
      "TRAINING MODEL dt_norm_3_13\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 41.942, Test 33.403\n",
      "MSE NON-NORMALIZED: Train MSE 4554.468, Test MSE 1610.937\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 8.761, Test 11.816\n",
      "MSE NON-NORMALIZED: Train MSE 656.195, Test MSE 600.396\n",
      "Epoch 50, lr 5.625e-05\n",
      "Epoch 50: Train 7.269, Test 8.069\n",
      "MSE NON-NORMALIZED: Train MSE 389.040, Test MSE 355.491\n",
      "Epoch 75, lr 5.625e-05\n",
      "Epoch 75: Train 6.341, Test 5.280\n",
      "MSE NON-NORMALIZED: Train MSE 245.969, Test MSE 234.349\n",
      "Epoch 100, lr 5.625e-05\n",
      "Epoch 100: Train 5.806, Test 4.766\n",
      "MSE NON-NORMALIZED: Train MSE 188.702, Test MSE 179.969\n",
      "Epoch 125, lr 5.625e-05\n",
      "Epoch 125: Train 5.027, Test 4.375\n",
      "MSE NON-NORMALIZED: Train MSE 177.123, Test MSE 170.072\n",
      "Epoch 150, lr 5.625e-05\n",
      "Epoch 150: Train 4.959, Test 4.311\n",
      "MSE NON-NORMALIZED: Train MSE 175.674, Test MSE 169.776\n",
      "Epoch 175, lr 5.625e-05\n",
      "Epoch 175: Train 4.931, Test 4.278\n",
      "MSE NON-NORMALIZED: Train MSE 175.395, Test MSE 170.461\n",
      "Epoch 200, lr 5.625e-05\n",
      "Epoch 200: Train 4.896, Test 4.246\n",
      "MSE NON-NORMALIZED: Train MSE 174.685, Test MSE 170.468\n",
      "Epoch 225, lr 5.625e-05\n",
      "Epoch 225: Train 4.881, Test 4.233\n",
      "MSE NON-NORMALIZED: Train MSE 174.494, Test MSE 170.476\n",
      "Epoch 250, lr 5.625e-05\n",
      "Epoch 250: Train 4.848, Test 4.208\n",
      "MSE NON-NORMALIZED: Train MSE 171.909, Test MSE 169.994\n",
      "Epoch 275, lr 5.625e-05\n",
      "Epoch 275: Train 4.821, Test 4.182\n",
      "MSE NON-NORMALIZED: Train MSE 171.774, Test MSE 168.724\n",
      "TRAINING MODEL dt_norm_3_15\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 15.597, Test 18.098\n",
      "MSE NON-NORMALIZED: Train MSE 1786.834, Test MSE 700.371\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 3.066, Test 5.919\n",
      "MSE NON-NORMALIZED: Train MSE 256.598, Test MSE 249.836\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 3.090, Test 5.946\n",
      "MSE NON-NORMALIZED: Train MSE 243.177, Test MSE 242.324\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 2.593, Test 5.286\n",
      "MSE NON-NORMALIZED: Train MSE 218.067, Test MSE 213.597\n",
      "Epoch 100, lr 0.000225\n",
      "Epoch 100: Train 2.419, Test 4.641\n",
      "MSE NON-NORMALIZED: Train MSE 189.451, Test MSE 185.014\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 2.347, Test 4.530\n",
      "MSE NON-NORMALIZED: Train MSE 183.476, Test MSE 181.158\n",
      "Epoch 150, lr 0.0001125\n",
      "Epoch 150: Train 1.201, Test 3.604\n",
      "MSE NON-NORMALIZED: Train MSE 159.578, Test MSE 157.906\n",
      "Epoch 175, lr 5.625e-05\n",
      "Epoch 175: Train 1.124, Test 3.538\n",
      "MSE NON-NORMALIZED: Train MSE 157.677, Test MSE 156.904\n",
      "Epoch 200, lr 1.40625e-05\n",
      "Epoch 200: Train 1.118, Test 3.530\n",
      "MSE NON-NORMALIZED: Train MSE 157.491, Test MSE 157.648\n",
      "Epoch 225, lr 1.40625e-05\n",
      "Epoch 225: Train 1.114, Test 3.527\n",
      "MSE NON-NORMALIZED: Train MSE 157.324, Test MSE 157.547\n",
      "Epoch 250, lr 1.40625e-05\n",
      "Epoch 250: Train 1.112, Test 3.525\n",
      "MSE NON-NORMALIZED: Train MSE 157.267, Test MSE 157.508\n",
      "Epoch 275, lr 1.40625e-05\n",
      "Epoch 275: Train 1.111, Test 3.523\n",
      "MSE NON-NORMALIZED: Train MSE 157.223, Test MSE 157.472\n",
      "TRAINING MODEL dt_norm_3_17\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 10.333, Test 17.850\n",
      "MSE NON-NORMALIZED: Train MSE 1352.698, Test MSE 783.584\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 3.773, Test 4.883\n",
      "MSE NON-NORMALIZED: Train MSE 163.020, Test MSE 158.720\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 2.600, Test 3.799\n",
      "MSE NON-NORMALIZED: Train MSE 122.065, Test MSE 116.762\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 2.587, Test 3.781\n",
      "MSE NON-NORMALIZED: Train MSE 120.839, Test MSE 116.494\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 2.553, Test 3.493\n",
      "MSE NON-NORMALIZED: Train MSE 110.567, Test MSE 104.872\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 2.463, Test 3.201\n",
      "MSE NON-NORMALIZED: Train MSE 99.287, Test MSE 97.872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, lr 0.0001125\n",
      "Epoch 150: Train 2.454, Test 3.189\n",
      "MSE NON-NORMALIZED: Train MSE 98.954, Test MSE 98.683\n",
      "Epoch 175, lr 5.625e-05\n",
      "Epoch 175: Train 2.444, Test 3.178\n",
      "MSE NON-NORMALIZED: Train MSE 98.350, Test MSE 99.373\n",
      "Epoch 200, lr 1.40625e-05\n",
      "Epoch 200: Train 2.439, Test 3.172\n",
      "MSE NON-NORMALIZED: Train MSE 98.187, Test MSE 100.246\n",
      "Epoch 225, lr 1.40625e-05\n",
      "Epoch 225: Train 2.423, Test 3.142\n",
      "MSE NON-NORMALIZED: Train MSE 97.523, Test MSE 99.531\n",
      "Epoch 250, lr 1.40625e-05\n",
      "Epoch 250: Train 2.418, Test 3.136\n",
      "MSE NON-NORMALIZED: Train MSE 97.397, Test MSE 99.412\n",
      "Epoch 275, lr 1.40625e-05\n",
      "Epoch 275: Train 2.415, Test 3.133\n",
      "MSE NON-NORMALIZED: Train MSE 97.332, Test MSE 99.346\n",
      "TRAINING MODEL dt_norm_3_19\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 10.330, Test 10.300\n",
      "MSE NON-NORMALIZED: Train MSE 810.476, Test MSE 322.816\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 5.679, Test 5.660\n",
      "MSE NON-NORMALIZED: Train MSE 190.049, Test MSE 189.113\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 5.598, Test 5.513\n",
      "MSE NON-NORMALIZED: Train MSE 187.826, Test MSE 184.666\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 2.860, Test 3.463\n",
      "MSE NON-NORMALIZED: Train MSE 96.685, Test MSE 93.533\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 2.843, Test 3.445\n",
      "MSE NON-NORMALIZED: Train MSE 95.481, Test MSE 93.207\n",
      "Epoch 125, lr 5.625e-05\n",
      "Epoch 125: Train 1.882, Test 2.291\n",
      "MSE NON-NORMALIZED: Train MSE 65.400, Test MSE 64.255\n",
      "Epoch 150, lr 5.625e-05\n",
      "Epoch 150: Train 1.838, Test 2.254\n",
      "MSE NON-NORMALIZED: Train MSE 64.776, Test MSE 64.374\n",
      "Epoch 175, lr 2.8125e-05\n",
      "Epoch 175: Train 1.830, Test 2.247\n",
      "MSE NON-NORMALIZED: Train MSE 64.427, Test MSE 65.122\n",
      "Epoch 200, lr 3.515625e-06\n",
      "Epoch 200: Train 1.828, Test 2.246\n",
      "MSE NON-NORMALIZED: Train MSE 64.418, Test MSE 65.997\n",
      "Epoch 225, lr 8.7890625e-07\n",
      "Epoch 225: Train 1.827, Test 2.245\n",
      "MSE NON-NORMALIZED: Train MSE 64.387, Test MSE 65.983\n",
      "Epoch 250, lr 2.197265625e-07\n",
      "Epoch 250: Train 1.827, Test 2.245\n",
      "MSE NON-NORMALIZED: Train MSE 64.383, Test MSE 65.982\n",
      "Epoch 275, lr 5.4931640625e-08\n",
      "Epoch 275: Train 1.827, Test 2.245\n",
      "MSE NON-NORMALIZED: Train MSE 64.382, Test MSE 65.982\n",
      "TRAINING MODEL dt_norm_3_21\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 14.437, Test 15.500\n",
      "MSE NON-NORMALIZED: Train MSE 1064.147, Test MSE 452.659\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 4.709, Test 4.861\n",
      "MSE NON-NORMALIZED: Train MSE 144.485, Test MSE 141.211\n",
      "Epoch 50, lr 0.0001125\n",
      "Epoch 50: Train 4.361, Test 4.143\n",
      "MSE NON-NORMALIZED: Train MSE 123.167, Test MSE 117.412\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 4.113, Test 3.332\n",
      "MSE NON-NORMALIZED: Train MSE 96.915, Test MSE 93.924\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 4.086, Test 3.283\n",
      "MSE NON-NORMALIZED: Train MSE 94.480, Test MSE 92.658\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 3.938, Test 3.078\n",
      "MSE NON-NORMALIZED: Train MSE 90.163, Test MSE 88.859\n",
      "Epoch 150, lr 0.0001125\n",
      "Epoch 150: Train 3.910, Test 3.031\n",
      "MSE NON-NORMALIZED: Train MSE 88.873, Test MSE 88.696\n",
      "Epoch 175, lr 5.625e-05\n",
      "Epoch 175: Train 3.870, Test 2.899\n",
      "MSE NON-NORMALIZED: Train MSE 84.579, Test MSE 86.383\n",
      "Epoch 200, lr 1.40625e-05\n",
      "Epoch 200: Train 3.868, Test 2.894\n",
      "MSE NON-NORMALIZED: Train MSE 84.468, Test MSE 87.187\n",
      "Epoch 225, lr 1.40625e-05\n",
      "Epoch 225: Train 2.192, Test 1.830\n",
      "MSE NON-NORMALIZED: Train MSE 48.560, Test MSE 50.030\n",
      "Epoch 250, lr 1.40625e-05\n",
      "Epoch 250: Train 2.144, Test 1.775\n",
      "MSE NON-NORMALIZED: Train MSE 46.909, Test MSE 48.784\n",
      "Epoch 275, lr 1.40625e-05\n",
      "Epoch 275: Train 2.140, Test 1.770\n",
      "MSE NON-NORMALIZED: Train MSE 46.835, Test MSE 48.693\n",
      "TRAINING MODEL dt_norm_3_23\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 7.724, Test 8.268\n",
      "MSE NON-NORMALIZED: Train MSE 712.414, Test MSE 245.853\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 3.949, Test 5.280\n",
      "MSE NON-NORMALIZED: Train MSE 171.991, Test MSE 170.558\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 3.831, Test 3.481\n",
      "MSE NON-NORMALIZED: Train MSE 91.078, Test MSE 89.602\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 4.003, Test 3.223\n",
      "MSE NON-NORMALIZED: Train MSE 84.214, Test MSE 82.228\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 3.512, Test 2.973\n",
      "MSE NON-NORMALIZED: Train MSE 76.893, Test MSE 75.532\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 3.008, Test 2.282\n",
      "MSE NON-NORMALIZED: Train MSE 59.389, Test MSE 58.573\n",
      "Epoch 150, lr 5.625e-05\n",
      "Epoch 150: Train 2.911, Test 2.240\n",
      "MSE NON-NORMALIZED: Train MSE 57.878, Test MSE 58.064\n",
      "Epoch 175, lr 5.625e-05\n",
      "Epoch 175: Train 2.875, Test 2.224\n",
      "MSE NON-NORMALIZED: Train MSE 57.486, Test MSE 58.445\n",
      "Epoch 200, lr 1.40625e-05\n",
      "Epoch 200: Train 2.870, Test 2.220\n",
      "MSE NON-NORMALIZED: Train MSE 57.397, Test MSE 59.132\n",
      "Epoch 225, lr 1.40625e-05\n",
      "Epoch 225: Train 2.159, Test 1.725\n",
      "MSE NON-NORMALIZED: Train MSE 43.010, Test MSE 44.462\n",
      "Epoch 250, lr 1.40625e-05\n",
      "Epoch 250: Train 1.956, Test 1.571\n",
      "MSE NON-NORMALIZED: Train MSE 38.594, Test MSE 40.103\n",
      "Epoch 275, lr 1.40625e-05\n",
      "Epoch 275: Train 1.953, Test 1.569\n",
      "MSE NON-NORMALIZED: Train MSE 38.559, Test MSE 40.068\n",
      "TRAINING MODEL dt_norm_3_25\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 39600\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 9.620, Test 8.965\n",
      "MSE NON-NORMALIZED: Train MSE 691.749, Test MSE 256.153\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 4.692, Test 4.747\n",
      "MSE NON-NORMALIZED: Train MSE 130.126, Test MSE 129.460\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 4.493, Test 4.400\n",
      "MSE NON-NORMALIZED: Train MSE 120.029, Test MSE 120.232\n",
      "Epoch 75, lr 0.00045\n",
      "Epoch 75: Train 4.498, Test 4.387\n",
      "MSE NON-NORMALIZED: Train MSE 119.897, Test MSE 119.759\n",
      "Epoch 100, lr 0.000225\n",
      "Epoch 100: Train 2.937, Test 2.944\n",
      "MSE NON-NORMALIZED: Train MSE 74.804, Test MSE 73.846\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 2.834, Test 2.708\n",
      "MSE NON-NORMALIZED: Train MSE 69.175, Test MSE 69.145\n",
      "Epoch 150, lr 5.625e-05\n",
      "Epoch 150: Train 2.198, Test 1.944\n",
      "MSE NON-NORMALIZED: Train MSE 47.331, Test MSE 46.916\n",
      "Epoch 175, lr 5.625e-05\n",
      "Epoch 175: Train 1.384, Test 1.426\n",
      "MSE NON-NORMALIZED: Train MSE 34.166, Test MSE 35.139\n",
      "Epoch 200, lr 5.625e-05\n",
      "Epoch 200: Train 1.281, Test 1.344\n",
      "MSE NON-NORMALIZED: Train MSE 32.050, Test MSE 33.643\n",
      "Epoch 225, lr 5.625e-05\n",
      "Epoch 225: Train 1.260, Test 1.325\n",
      "MSE NON-NORMALIZED: Train MSE 31.623, Test MSE 33.250\n",
      "Epoch 250, lr 5.625e-05\n",
      "Epoch 250: Train 1.250, Test 1.316\n",
      "MSE NON-NORMALIZED: Train MSE 31.415, Test MSE 33.034\n",
      "Epoch 275, lr 5.625e-05\n",
      "Epoch 275: Train 1.243, Test 1.308\n",
      "MSE NON-NORMALIZED: Train MSE 31.223, Test MSE 32.816\n",
      "TRAINING MODEL dt_norm_3_39\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 28168\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 4.718, Test 3.648\n",
      "MSE NON-NORMALIZED: Train MSE 100.324, Test MSE 75.881\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 1.286, Test 1.095\n",
      "MSE NON-NORMALIZED: Train MSE 19.725, Test MSE 19.144\n",
      "Epoch 50, lr 0.00045\n",
      "Epoch 50: Train 1.211, Test 1.037\n",
      "MSE NON-NORMALIZED: Train MSE 18.686, Test MSE 18.096\n",
      "Epoch 75, lr 0.000225\n",
      "Epoch 75: Train 1.211, Test 1.026\n",
      "MSE NON-NORMALIZED: Train MSE 18.178, Test MSE 17.869\n",
      "Epoch 100, lr 0.0001125\n",
      "Epoch 100: Train 1.192, Test 1.006\n",
      "MSE NON-NORMALIZED: Train MSE 17.853, Test MSE 17.538\n",
      "Epoch 125, lr 0.0001125\n",
      "Epoch 125: Train 1.060, Test 0.942\n",
      "MSE NON-NORMALIZED: Train MSE 16.796, Test MSE 16.722\n",
      "Epoch 150, lr 0.0001125\n",
      "Epoch 150: Train 0.884, Test 0.882\n",
      "MSE NON-NORMALIZED: Train MSE 15.740, Test MSE 15.896\n",
      "Epoch 175, lr 0.0001125\n",
      "Epoch 175: Train 0.751, Test 0.826\n",
      "MSE NON-NORMALIZED: Train MSE 14.761, Test MSE 15.139\n",
      "Epoch 200, lr 0.0001125\n",
      "Epoch 200: Train 0.700, Test 0.802\n",
      "MSE NON-NORMALIZED: Train MSE 14.367, Test MSE 14.939\n",
      "Epoch 225, lr 0.0001125\n",
      "Epoch 225: Train 0.644, Test 0.779\n",
      "MSE NON-NORMALIZED: Train MSE 13.945, Test MSE 14.482\n",
      "Epoch 250, lr 0.0001125\n",
      "Epoch 250: Train 0.615, Test 0.766\n",
      "MSE NON-NORMALIZED: Train MSE 13.687, Test MSE 14.217\n",
      "Epoch 275, lr 0.0001125\n",
      "Epoch 275: Train 0.605, Test 0.761\n",
      "MSE NON-NORMALIZED: Train MSE 13.593, Test MSE 14.127\n",
      "TRAINING MODEL dt_norm_3_40\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 30947\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 1.087, Test 3.409\n",
      "MSE NON-NORMALIZED: Train MSE 91.228, Test MSE 90.138\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 1.082, Test 3.394\n",
      "MSE NON-NORMALIZED: Train MSE 89.210, Test MSE 89.965\n",
      "Epoch 50, lr 2.8125e-05\n",
      "Epoch 50: Train 1.090, Test 3.397\n",
      "MSE NON-NORMALIZED: Train MSE 89.192, Test MSE 89.950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, lr 7.03125e-06\n",
      "Epoch 75: Train 1.090, Test 3.397\n",
      "MSE NON-NORMALIZED: Train MSE 89.190, Test MSE 89.949\n",
      "Epoch 100, lr 1.7578125e-06\n",
      "Epoch 100: Train 1.090, Test 3.397\n",
      "MSE NON-NORMALIZED: Train MSE 89.190, Test MSE 89.949\n",
      "Epoch 125, lr 2.197265625e-07\n",
      "Epoch 125: Train 1.090, Test 3.397\n",
      "MSE NON-NORMALIZED: Train MSE 89.237, Test MSE 90.321\n",
      "Epoch 150, lr 5.4931640625e-08\n",
      "Epoch 150: Train 1.090, Test 3.397\n",
      "MSE NON-NORMALIZED: Train MSE 89.285, Test MSE 90.694\n",
      "Epoch 175, lr 1.373291015625e-08\n",
      "Epoch 175: Train 1.090, Test 3.397\n",
      "MSE NON-NORMALIZED: Train MSE 89.332, Test MSE 91.066\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 1.090, Test 3.397\n",
      "MSE NON-NORMALIZED: Train MSE 89.380, Test MSE 91.438\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 1.090, Test 3.397\n",
      "MSE NON-NORMALIZED: Train MSE 89.380, Test MSE 91.438\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 1.090, Test 3.397\n",
      "MSE NON-NORMALIZED: Train MSE 89.380, Test MSE 91.438\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 1.090, Test 3.397\n",
      "MSE NON-NORMALIZED: Train MSE 89.380, Test MSE 91.438\n",
      "TRAINING MODEL dt_norm_3_41\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 26195\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 3.287, Test 3.010\n",
      "MSE NON-NORMALIZED: Train MSE 69.267, Test MSE 69.423\n",
      "Epoch 25, lr 0.0001125\n",
      "Epoch 25: Train 3.294, Test 3.016\n",
      "MSE NON-NORMALIZED: Train MSE 68.954, Test MSE 69.287\n",
      "Epoch 50, lr 2.8125e-05\n",
      "Epoch 50: Train 3.295, Test 3.017\n",
      "MSE NON-NORMALIZED: Train MSE 68.948, Test MSE 69.282\n",
      "Epoch 75, lr 7.03125e-06\n",
      "Epoch 75: Train 3.295, Test 3.017\n",
      "MSE NON-NORMALIZED: Train MSE 68.947, Test MSE 69.282\n",
      "Epoch 100, lr 8.7890625e-07\n",
      "Epoch 100: Train 3.295, Test 3.017\n",
      "MSE NON-NORMALIZED: Train MSE 68.947, Test MSE 69.281\n",
      "Epoch 125, lr 2.197265625e-07\n",
      "Epoch 125: Train 3.295, Test 3.017\n",
      "MSE NON-NORMALIZED: Train MSE 68.990, Test MSE 69.590\n",
      "Epoch 150, lr 5.4931640625e-08\n",
      "Epoch 150: Train 3.295, Test 3.017\n",
      "MSE NON-NORMALIZED: Train MSE 69.033, Test MSE 69.898\n",
      "Epoch 175, lr 1.373291015625e-08\n",
      "Epoch 175: Train 3.295, Test 3.017\n",
      "MSE NON-NORMALIZED: Train MSE 69.076, Test MSE 70.207\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 3.295, Test 3.017\n",
      "MSE NON-NORMALIZED: Train MSE 69.119, Test MSE 70.515\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 3.295, Test 3.017\n",
      "MSE NON-NORMALIZED: Train MSE 69.119, Test MSE 70.515\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 3.295, Test 3.017\n",
      "MSE NON-NORMALIZED: Train MSE 69.119, Test MSE 70.515\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 3.295, Test 3.017\n",
      "MSE NON-NORMALIZED: Train MSE 69.119, Test MSE 70.515\n",
      "TRAINING MODEL dt_norm_3_42\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 27786\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 1.492, Test 1.224\n",
      "MSE NON-NORMALIZED: Train MSE 22.516, Test MSE 22.327\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 1.451, Test 1.201\n",
      "MSE NON-NORMALIZED: Train MSE 21.911, Test MSE 21.817\n",
      "Epoch 50, lr 5.625e-05\n",
      "Epoch 50: Train 1.450, Test 1.201\n",
      "MSE NON-NORMALIZED: Train MSE 21.910, Test MSE 21.817\n",
      "Epoch 75, lr 1.40625e-05\n",
      "Epoch 75: Train 1.450, Test 1.201\n",
      "MSE NON-NORMALIZED: Train MSE 21.909, Test MSE 21.817\n",
      "Epoch 100, lr 1.7578125e-06\n",
      "Epoch 100: Train 1.450, Test 1.201\n",
      "MSE NON-NORMALIZED: Train MSE 21.909, Test MSE 21.817\n",
      "Epoch 125, lr 4.39453125e-07\n",
      "Epoch 125: Train 1.450, Test 1.201\n",
      "MSE NON-NORMALIZED: Train MSE 21.936, Test MSE 22.012\n",
      "Epoch 150, lr 1.0986328125e-07\n",
      "Epoch 150: Train 1.450, Test 1.201\n",
      "MSE NON-NORMALIZED: Train MSE 21.962, Test MSE 22.208\n",
      "Epoch 175, lr 2.74658203125e-08\n",
      "Epoch 175: Train 1.450, Test 1.201\n",
      "MSE NON-NORMALIZED: Train MSE 21.989, Test MSE 22.403\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 1.450, Test 1.201\n",
      "MSE NON-NORMALIZED: Train MSE 22.016, Test MSE 22.599\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 1.450, Test 1.201\n",
      "MSE NON-NORMALIZED: Train MSE 22.016, Test MSE 22.599\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 1.450, Test 1.201\n",
      "MSE NON-NORMALIZED: Train MSE 22.016, Test MSE 22.599\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 1.450, Test 1.201\n",
      "MSE NON-NORMALIZED: Train MSE 22.016, Test MSE 22.599\n",
      "TRAINING MODEL dt_norm_3_43\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 23805\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 0.889, Test 1.194\n",
      "MSE NON-NORMALIZED: Train MSE 32.561, Test MSE 20.748\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 0.730, Test 0.926\n",
      "MSE NON-NORMALIZED: Train MSE 16.608, Test MSE 15.812\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 0.727, Test 0.927\n",
      "MSE NON-NORMALIZED: Train MSE 16.491, Test MSE 15.820\n",
      "Epoch 75, lr 5.625e-05\n",
      "Epoch 75: Train 0.727, Test 0.922\n",
      "MSE NON-NORMALIZED: Train MSE 16.446, Test MSE 15.703\n",
      "Epoch 100, lr 1.40625e-05\n",
      "Epoch 100: Train 0.725, Test 0.919\n",
      "MSE NON-NORMALIZED: Train MSE 16.436, Test MSE 15.659\n",
      "Epoch 125, lr 3.515625e-06\n",
      "Epoch 125: Train 0.725, Test 0.919\n",
      "MSE NON-NORMALIZED: Train MSE 16.456, Test MSE 15.816\n",
      "Epoch 150, lr 8.7890625e-07\n",
      "Epoch 150: Train 0.725, Test 0.919\n",
      "MSE NON-NORMALIZED: Train MSE 16.479, Test MSE 15.973\n",
      "Epoch 175, lr 1.0986328125e-07\n",
      "Epoch 175: Train 0.725, Test 0.919\n",
      "MSE NON-NORMALIZED: Train MSE 16.502, Test MSE 16.131\n",
      "Epoch 200, lr 2.74658203125e-08\n",
      "Epoch 200: Train 0.725, Test 0.919\n",
      "MSE NON-NORMALIZED: Train MSE 16.526, Test MSE 16.289\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 0.725, Test 0.919\n",
      "MSE NON-NORMALIZED: Train MSE 16.526, Test MSE 16.289\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 0.725, Test 0.919\n",
      "MSE NON-NORMALIZED: Train MSE 16.526, Test MSE 16.288\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 0.725, Test 0.919\n",
      "MSE NON-NORMALIZED: Train MSE 16.526, Test MSE 16.288\n",
      "TRAINING MODEL dt_norm_3_44\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 24190\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 0.640, Test 1.124\n",
      "MSE NON-NORMALIZED: Train MSE 20.379, Test MSE 20.312\n",
      "Epoch 25, lr 0.0001125\n",
      "Epoch 25: Train 0.649, Test 1.110\n",
      "MSE NON-NORMALIZED: Train MSE 19.964, Test MSE 19.985\n",
      "Epoch 50, lr 2.8125e-05\n",
      "Epoch 50: Train 0.650, Test 1.110\n",
      "MSE NON-NORMALIZED: Train MSE 19.963, Test MSE 19.985\n",
      "Epoch 75, lr 7.03125e-06\n",
      "Epoch 75: Train 0.650, Test 1.110\n",
      "MSE NON-NORMALIZED: Train MSE 19.963, Test MSE 19.985\n",
      "Epoch 100, lr 8.7890625e-07\n",
      "Epoch 100: Train 0.650, Test 1.110\n",
      "MSE NON-NORMALIZED: Train MSE 19.963, Test MSE 19.985\n",
      "Epoch 125, lr 2.197265625e-07\n",
      "Epoch 125: Train 0.650, Test 1.110\n",
      "MSE NON-NORMALIZED: Train MSE 19.991, Test MSE 20.178\n",
      "Epoch 150, lr 5.4931640625e-08\n",
      "Epoch 150: Train 0.650, Test 1.110\n",
      "MSE NON-NORMALIZED: Train MSE 20.019, Test MSE 20.371\n",
      "Epoch 175, lr 1.373291015625e-08\n",
      "Epoch 175: Train 0.650, Test 1.110\n",
      "MSE NON-NORMALIZED: Train MSE 20.047, Test MSE 20.564\n",
      "Epoch 200, lr 1.373291015625e-08\n",
      "Epoch 200: Train 0.650, Test 1.110\n",
      "MSE NON-NORMALIZED: Train MSE 20.075, Test MSE 20.756\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 0.650, Test 1.110\n",
      "MSE NON-NORMALIZED: Train MSE 20.075, Test MSE 20.756\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 0.650, Test 1.110\n",
      "MSE NON-NORMALIZED: Train MSE 20.075, Test MSE 20.756\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 0.650, Test 1.110\n",
      "MSE NON-NORMALIZED: Train MSE 20.075, Test MSE 20.756\n",
      "TRAINING MODEL dt_norm_3_45\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 18646\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 1.607, Test 1.953\n",
      "MSE NON-NORMALIZED: Train MSE 37.385, Test MSE 37.302\n",
      "Epoch 25, lr 0.000225\n",
      "Epoch 25: Train 1.581, Test 1.910\n",
      "MSE NON-NORMALIZED: Train MSE 36.398, Test MSE 36.330\n",
      "Epoch 50, lr 0.0001125\n",
      "Epoch 50: Train 1.580, Test 1.910\n",
      "MSE NON-NORMALIZED: Train MSE 36.395, Test MSE 36.329\n",
      "Epoch 75, lr 5.625e-05\n",
      "Epoch 75: Train 1.580, Test 1.910\n",
      "MSE NON-NORMALIZED: Train MSE 36.395, Test MSE 36.329\n",
      "Epoch 100, lr 1.40625e-05\n",
      "Epoch 100: Train 1.579, Test 1.910\n",
      "MSE NON-NORMALIZED: Train MSE 36.394, Test MSE 36.329\n",
      "Epoch 125, lr 3.515625e-06\n",
      "Epoch 125: Train 1.579, Test 1.910\n",
      "MSE NON-NORMALIZED: Train MSE 36.434, Test MSE 36.571\n",
      "Epoch 150, lr 4.39453125e-07\n",
      "Epoch 150: Train 1.579, Test 1.910\n",
      "MSE NON-NORMALIZED: Train MSE 36.474, Test MSE 36.813\n",
      "Epoch 175, lr 1.0986328125e-07\n",
      "Epoch 175: Train 1.579, Test 1.910\n",
      "MSE NON-NORMALIZED: Train MSE 36.514, Test MSE 37.054\n",
      "Epoch 200, lr 2.74658203125e-08\n",
      "Epoch 200: Train 1.579, Test 1.910\n",
      "MSE NON-NORMALIZED: Train MSE 36.554, Test MSE 37.296\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 1.579, Test 1.910\n",
      "MSE NON-NORMALIZED: Train MSE 36.554, Test MSE 37.296\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 1.579, Test 1.910\n",
      "MSE NON-NORMALIZED: Train MSE 36.554, Test MSE 37.296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 1.579, Test 1.910\n",
      "MSE NON-NORMALIZED: Train MSE 36.554, Test MSE 37.296\n",
      "TRAINING MODEL dt_norm_3_46\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 19839\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 0.804, Test 0.995\n",
      "MSE NON-NORMALIZED: Train MSE 27.546, Test MSE 16.843\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 0.690, Test 0.816\n",
      "MSE NON-NORMALIZED: Train MSE 13.699, Test MSE 13.656\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 0.690, Test 0.816\n",
      "MSE NON-NORMALIZED: Train MSE 13.670, Test MSE 13.661\n",
      "Epoch 75, lr 5.625e-05\n",
      "Epoch 75: Train 0.689, Test 0.815\n",
      "MSE NON-NORMALIZED: Train MSE 13.655, Test MSE 13.624\n",
      "Epoch 100, lr 2.8125e-05\n",
      "Epoch 100: Train 0.688, Test 0.814\n",
      "MSE NON-NORMALIZED: Train MSE 13.652, Test MSE 13.620\n",
      "Epoch 125, lr 7.03125e-06\n",
      "Epoch 125: Train 0.688, Test 0.814\n",
      "MSE NON-NORMALIZED: Train MSE 13.666, Test MSE 13.731\n",
      "Epoch 150, lr 1.7578125e-06\n",
      "Epoch 150: Train 0.688, Test 0.814\n",
      "MSE NON-NORMALIZED: Train MSE 13.684, Test MSE 13.843\n",
      "Epoch 175, lr 4.39453125e-07\n",
      "Epoch 175: Train 0.688, Test 0.814\n",
      "MSE NON-NORMALIZED: Train MSE 13.702, Test MSE 13.955\n",
      "Epoch 200, lr 5.4931640625e-08\n",
      "Epoch 200: Train 0.688, Test 0.814\n",
      "MSE NON-NORMALIZED: Train MSE 13.720, Test MSE 14.067\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 0.688, Test 0.814\n",
      "MSE NON-NORMALIZED: Train MSE 13.720, Test MSE 14.067\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 0.688, Test 0.814\n",
      "MSE NON-NORMALIZED: Train MSE 13.720, Test MSE 14.067\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 0.688, Test 0.814\n",
      "MSE NON-NORMALIZED: Train MSE 13.720, Test MSE 14.067\n",
      "TRAINING MODEL dt_norm_3_47\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 17061\n",
      "Epoch 0, lr 0.00045\n",
      "Epoch 0: Train 1.285, Test 1.151\n",
      "MSE NON-NORMALIZED: Train MSE 44.032, Test MSE 20.412\n",
      "Epoch 25, lr 0.00045\n",
      "Epoch 25: Train 1.051, Test 0.981\n",
      "MSE NON-NORMALIZED: Train MSE 17.354, Test MSE 17.216\n",
      "Epoch 50, lr 0.000225\n",
      "Epoch 50: Train 1.049, Test 0.974\n",
      "MSE NON-NORMALIZED: Train MSE 17.183, Test MSE 17.100\n",
      "Epoch 75, lr 0.0001125\n",
      "Epoch 75: Train 1.046, Test 0.974\n",
      "MSE NON-NORMALIZED: Train MSE 17.167, Test MSE 17.085\n",
      "Epoch 100, lr 2.8125e-05\n",
      "Epoch 100: Train 1.045, Test 0.974\n",
      "MSE NON-NORMALIZED: Train MSE 17.162, Test MSE 17.085\n",
      "Epoch 125, lr 7.03125e-06\n",
      "Epoch 125: Train 1.045, Test 0.974\n",
      "MSE NON-NORMALIZED: Train MSE 17.173, Test MSE 17.186\n",
      "Epoch 150, lr 1.7578125e-06\n",
      "Epoch 150: Train 1.045, Test 0.974\n",
      "MSE NON-NORMALIZED: Train MSE 17.190, Test MSE 17.286\n",
      "Epoch 175, lr 4.39453125e-07\n",
      "Epoch 175: Train 1.045, Test 0.974\n",
      "MSE NON-NORMALIZED: Train MSE 17.207, Test MSE 17.386\n",
      "Epoch 200, lr 5.4931640625e-08\n",
      "Epoch 200: Train 1.045, Test 0.974\n",
      "MSE NON-NORMALIZED: Train MSE 17.224, Test MSE 17.486\n",
      "Epoch 225, lr 1.373291015625e-08\n",
      "Epoch 225: Train 1.045, Test 0.974\n",
      "MSE NON-NORMALIZED: Train MSE 17.224, Test MSE 17.486\n",
      "Epoch 250, lr 1.373291015625e-08\n",
      "Epoch 250: Train 1.045, Test 0.974\n",
      "MSE NON-NORMALIZED: Train MSE 17.224, Test MSE 17.486\n",
      "Epoch 275, lr 1.373291015625e-08\n",
      "Epoch 275: Train 1.045, Test 0.974\n",
      "MSE NON-NORMALIZED: Train MSE 17.224, Test MSE 17.486\n"
     ]
    }
   ],
   "source": [
    "#17.735867005586623\n",
    "ae_train.train_models(data,\n",
    "            override = False,\n",
    "            model_params = [48,450,250,100,16],\n",
    "            epochs = 300, \n",
    "            lr = 4.5e-4,\n",
    "            max_dt_size = 40000, \n",
    "            dir_label = 'wafer_layer_split_mip_std_1_mean_nonzero_450_250_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b6632df0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL dt_norm_3_36\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.188, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 3.452, Test MSE 3.603\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.219, Test 0.239\n",
      "MSE NON-NORMALIZED: Train MSE 4.270, Test MSE 3.927\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.219, Test 0.238\n",
      "MSE NON-NORMALIZED: Train MSE 4.248, Test MSE 3.919\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.220, Test 0.239\n",
      "MSE NON-NORMALIZED: Train MSE 4.243, Test MSE 3.923\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.220, Test 0.239\n",
      "MSE NON-NORMALIZED: Train MSE 4.241, Test MSE 3.925\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.220, Test 0.239\n",
      "MSE NON-NORMALIZED: Train MSE 4.260, Test MSE 4.064\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.220, Test 0.239\n",
      "MSE NON-NORMALIZED: Train MSE 4.278, Test MSE 4.201\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.220, Test 0.239\n",
      "MSE NON-NORMALIZED: Train MSE 4.296, Test MSE 4.338\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.220, Test 0.239\n",
      "MSE NON-NORMALIZED: Train MSE 4.314, Test MSE 4.474\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.220, Test 0.239\n",
      "MSE NON-NORMALIZED: Train MSE 4.314, Test MSE 4.473\n",
      "TRAINING MODEL dt_norm_3_30\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.306, Test 0.289\n",
      "MSE NON-NORMALIZED: Train MSE 6.874, Test MSE 6.444\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.298, Test 0.273\n",
      "MSE NON-NORMALIZED: Train MSE 6.525, Test MSE 5.784\n",
      "Epoch 50, lr 0.00010625\n",
      "Epoch 50: Train 0.291, Test 0.264\n",
      "MSE NON-NORMALIZED: Train MSE 6.017, Test MSE 5.518\n",
      "Epoch 75, lr 0.00010625\n",
      "Epoch 75: Train 0.286, Test 0.258\n",
      "MSE NON-NORMALIZED: Train MSE 5.768, Test MSE 5.267\n",
      "Epoch 100, lr 2.65625e-05\n",
      "Epoch 100: Train 0.284, Test 0.257\n",
      "MSE NON-NORMALIZED: Train MSE 5.695, Test MSE 5.234\n",
      "Epoch 125, lr 6.640625e-06\n",
      "Epoch 125: Train 0.283, Test 0.256\n",
      "MSE NON-NORMALIZED: Train MSE 5.706, Test MSE 5.449\n",
      "Epoch 150, lr 1.66015625e-06\n",
      "Epoch 150: Train 0.283, Test 0.256\n",
      "MSE NON-NORMALIZED: Train MSE 5.730, Test MSE 5.668\n",
      "Epoch 175, lr 4.150390625e-07\n",
      "Epoch 175: Train 0.283, Test 0.256\n",
      "MSE NON-NORMALIZED: Train MSE 5.758, Test MSE 5.889\n",
      "Epoch 200, lr 5.18798828125e-08\n",
      "Epoch 200: Train 0.283, Test 0.256\n",
      "MSE NON-NORMALIZED: Train MSE 5.786, Test MSE 6.110\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.283, Test 0.256\n",
      "MSE NON-NORMALIZED: Train MSE 5.785, Test MSE 6.109\n",
      "TRAINING MODEL dt_norm_3_31\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.302, Test 0.322\n",
      "MSE NON-NORMALIZED: Train MSE 10.221, Test MSE 7.284\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 0.325, Test 0.282\n",
      "MSE NON-NORMALIZED: Train MSE 6.767, Test MSE 6.080\n",
      "Epoch 50, lr 0.00010625\n",
      "Epoch 50: Train 0.305, Test 0.272\n",
      "MSE NON-NORMALIZED: Train MSE 6.291, Test MSE 5.731\n",
      "Epoch 75, lr 0.00010625\n",
      "Epoch 75: Train 0.302, Test 0.266\n",
      "MSE NON-NORMALIZED: Train MSE 6.101, Test MSE 5.588\n",
      "Epoch 100, lr 5.3125e-05\n",
      "Epoch 100: Train 0.301, Test 0.263\n",
      "MSE NON-NORMALIZED: Train MSE 5.984, Test MSE 5.502\n",
      "Epoch 125, lr 1.328125e-05\n",
      "Epoch 125: Train 0.299, Test 0.262\n",
      "MSE NON-NORMALIZED: Train MSE 5.962, Test MSE 5.713\n",
      "Epoch 150, lr 3.3203125e-06\n",
      "Epoch 150: Train 0.299, Test 0.262\n",
      "MSE NON-NORMALIZED: Train MSE 5.982, Test MSE 5.947\n",
      "Epoch 175, lr 4.150390625e-07\n",
      "Epoch 175: Train 0.299, Test 0.262\n",
      "MSE NON-NORMALIZED: Train MSE 6.010, Test MSE 6.183\n",
      "Epoch 200, lr 1.03759765625e-07\n",
      "Epoch 200: Train 0.299, Test 0.262\n",
      "MSE NON-NORMALIZED: Train MSE 6.041, Test MSE 6.420\n",
      "Epoch 225, lr 2.593994140625e-08\n",
      "Epoch 225: Train 0.298, Test 0.262\n",
      "MSE NON-NORMALIZED: Train MSE 6.040, Test MSE 6.419\n",
      "TRAINING MODEL dt_norm_3_33\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.205, Test 0.271\n",
      "MSE NON-NORMALIZED: Train MSE 6.496, Test MSE 5.949\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.250, Test 0.288\n",
      "MSE NON-NORMALIZED: Train MSE 6.458, Test MSE 5.789\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.245, Test 0.281\n",
      "MSE NON-NORMALIZED: Train MSE 6.271, Test MSE 5.627\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.244, Test 0.279\n",
      "MSE NON-NORMALIZED: Train MSE 6.237, Test MSE 5.592\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.244, Test 0.279\n",
      "MSE NON-NORMALIZED: Train MSE 6.227, Test MSE 5.584\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.244, Test 0.279\n",
      "MSE NON-NORMALIZED: Train MSE 6.254, Test MSE 5.804\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.244, Test 0.279\n",
      "MSE NON-NORMALIZED: Train MSE 6.283, Test MSE 6.024\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.244, Test 0.279\n",
      "MSE NON-NORMALIZED: Train MSE 6.311, Test MSE 6.243\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.244, Test 0.279\n",
      "MSE NON-NORMALIZED: Train MSE 6.340, Test MSE 6.462\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.244, Test 0.279\n",
      "MSE NON-NORMALIZED: Train MSE 6.339, Test MSE 6.461\n",
      "TRAINING MODEL dt_norm_3_35\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.252, Test 0.252\n",
      "MSE NON-NORMALIZED: Train MSE 4.167, Test MSE 4.408\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 0.227, Test 0.245\n",
      "MSE NON-NORMALIZED: Train MSE 4.293, Test MSE 3.961\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 0.221, Test 0.240\n",
      "MSE NON-NORMALIZED: Train MSE 4.222, Test MSE 3.873\n",
      "Epoch 75, lr 0.00010625\n",
      "Epoch 75: Train 0.219, Test 0.237\n",
      "MSE NON-NORMALIZED: Train MSE 4.143, Test MSE 3.814\n",
      "Epoch 100, lr 2.65625e-05\n",
      "Epoch 100: Train 0.219, Test 0.237\n",
      "MSE NON-NORMALIZED: Train MSE 4.127, Test MSE 3.812\n",
      "Epoch 125, lr 3.3203125e-06\n",
      "Epoch 125: Train 0.219, Test 0.237\n",
      "MSE NON-NORMALIZED: Train MSE 4.141, Test MSE 3.954\n",
      "Epoch 150, lr 8.30078125e-07\n",
      "Epoch 150: Train 0.219, Test 0.237\n",
      "MSE NON-NORMALIZED: Train MSE 4.158, Test MSE 4.097\n",
      "Epoch 175, lr 2.0751953125e-07\n",
      "Epoch 175: Train 0.219, Test 0.237\n",
      "MSE NON-NORMALIZED: Train MSE 4.177, Test MSE 4.241\n",
      "Epoch 200, lr 5.18798828125e-08\n",
      "Epoch 200: Train 0.219, Test 0.237\n",
      "MSE NON-NORMALIZED: Train MSE 4.196, Test MSE 4.385\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.219, Test 0.237\n",
      "MSE NON-NORMALIZED: Train MSE 4.196, Test MSE 4.385\n",
      "TRAINING MODEL dt_norm_3_37\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.165, Test 0.168\n",
      "MSE NON-NORMALIZED: Train MSE 2.697, Test MSE 2.857\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.181, Test 0.213\n",
      "MSE NON-NORMALIZED: Train MSE 3.661, Test MSE 3.474\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.176, Test 0.209\n",
      "MSE NON-NORMALIZED: Train MSE 3.587, Test MSE 3.398\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.175, Test 0.208\n",
      "MSE NON-NORMALIZED: Train MSE 3.570, Test MSE 3.384\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.175, Test 0.208\n",
      "MSE NON-NORMALIZED: Train MSE 3.565, Test MSE 3.380\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.175, Test 0.208\n",
      "MSE NON-NORMALIZED: Train MSE 3.582, Test MSE 3.521\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.175, Test 0.208\n",
      "MSE NON-NORMALIZED: Train MSE 3.600, Test MSE 3.661\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.175, Test 0.208\n",
      "MSE NON-NORMALIZED: Train MSE 3.619, Test MSE 3.801\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.175, Test 0.208\n",
      "MSE NON-NORMALIZED: Train MSE 3.637, Test MSE 3.941\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.175, Test 0.208\n",
      "MSE NON-NORMALIZED: Train MSE 3.637, Test MSE 3.940\n",
      "TRAINING MODEL dt_norm_3_27\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.409, Test 0.480\n",
      "MSE NON-NORMALIZED: Train MSE 12.310, Test MSE 10.353\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.314, Test 0.366\n",
      "MSE NON-NORMALIZED: Train MSE 8.730, Test MSE 7.643\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 0.304, Test 0.351\n",
      "MSE NON-NORMALIZED: Train MSE 8.109, Test MSE 7.259\n",
      "Epoch 75, lr 0.00010625\n",
      "Epoch 75: Train 0.302, Test 0.349\n",
      "MSE NON-NORMALIZED: Train MSE 7.904, Test MSE 7.215\n",
      "Epoch 100, lr 0.00010625\n",
      "Epoch 100: Train 0.297, Test 0.336\n",
      "MSE NON-NORMALIZED: Train MSE 7.685, Test MSE 6.974\n",
      "Epoch 125, lr 0.00010625\n",
      "Epoch 125: Train 0.294, Test 0.329\n",
      "MSE NON-NORMALIZED: Train MSE 7.597, Test MSE 7.134\n",
      "Epoch 150, lr 2.65625e-05\n",
      "Epoch 150: Train 0.292, Test 0.326\n",
      "MSE NON-NORMALIZED: Train MSE 7.533, Test MSE 7.323\n",
      "Epoch 175, lr 6.640625e-06\n",
      "Epoch 175: Train 0.291, Test 0.325\n",
      "MSE NON-NORMALIZED: Train MSE 7.546, Test MSE 7.568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, lr 8.30078125e-07\n",
      "Epoch 200: Train 0.291, Test 0.324\n",
      "MSE NON-NORMALIZED: Train MSE 7.574, Test MSE 7.827\n",
      "Epoch 225, lr 2.0751953125e-07\n",
      "Epoch 225: Train 0.291, Test 0.324\n",
      "MSE NON-NORMALIZED: Train MSE 7.573, Test MSE 7.826\n",
      "TRAINING MODEL dt_norm_3_29\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.213, Test 0.229\n",
      "MSE NON-NORMALIZED: Train MSE 5.892, Test MSE 4.461\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.248, Test 0.249\n",
      "MSE NON-NORMALIZED: Train MSE 5.005, Test MSE 4.533\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.246, Test 0.245\n",
      "MSE NON-NORMALIZED: Train MSE 4.867, Test MSE 4.449\n",
      "Epoch 75, lr 5.3125e-05\n",
      "Epoch 75: Train 0.246, Test 0.245\n",
      "MSE NON-NORMALIZED: Train MSE 4.855, Test MSE 4.437\n",
      "Epoch 100, lr 5.3125e-05\n",
      "Epoch 100: Train 0.246, Test 0.245\n",
      "MSE NON-NORMALIZED: Train MSE 4.849, Test MSE 4.433\n",
      "Epoch 125, lr 1.328125e-05\n",
      "Epoch 125: Train 0.246, Test 0.244\n",
      "MSE NON-NORMALIZED: Train MSE 4.841, Test MSE 4.617\n",
      "Epoch 150, lr 1.66015625e-06\n",
      "Epoch 150: Train 0.246, Test 0.244\n",
      "MSE NON-NORMALIZED: Train MSE 4.856, Test MSE 4.815\n",
      "Epoch 175, lr 4.150390625e-07\n",
      "Epoch 175: Train 0.246, Test 0.244\n",
      "MSE NON-NORMALIZED: Train MSE 4.880, Test MSE 5.013\n",
      "Epoch 200, lr 1.03759765625e-07\n",
      "Epoch 200: Train 0.246, Test 0.244\n",
      "MSE NON-NORMALIZED: Train MSE 4.906, Test MSE 5.210\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.246, Test 0.244\n",
      "MSE NON-NORMALIZED: Train MSE 4.905, Test MSE 5.209\n",
      "TRAINING MODEL dt_norm_3_32\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.222, Test 0.314\n",
      "MSE NON-NORMALIZED: Train MSE 6.872, Test MSE 6.487\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.202, Test 0.228\n",
      "MSE NON-NORMALIZED: Train MSE 4.710, Test MSE 4.067\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 0.200, Test 0.228\n",
      "MSE NON-NORMALIZED: Train MSE 4.618, Test MSE 4.081\n",
      "Epoch 75, lr 0.00085\n",
      "Epoch 75: Train 0.196, Test 0.225\n",
      "MSE NON-NORMALIZED: Train MSE 4.566, Test MSE 4.020\n",
      "Epoch 100, lr 0.00085\n",
      "Epoch 100: Train 0.194, Test 0.219\n",
      "MSE NON-NORMALIZED: Train MSE 4.465, Test MSE 3.896\n",
      "Epoch 125, lr 0.000425\n",
      "Epoch 125: Train 0.190, Test 0.212\n",
      "MSE NON-NORMALIZED: Train MSE 4.275, Test MSE 3.952\n",
      "Epoch 150, lr 0.00010625\n",
      "Epoch 150: Train 0.187, Test 0.209\n",
      "MSE NON-NORMALIZED: Train MSE 4.212, Test MSE 4.100\n",
      "Epoch 175, lr 5.3125e-05\n",
      "Epoch 175: Train 0.186, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 4.173, Test MSE 4.243\n",
      "Epoch 200, lr 6.640625e-06\n",
      "Epoch 200: Train 0.185, Test 0.206\n",
      "MSE NON-NORMALIZED: Train MSE 4.176, Test MSE 4.413\n",
      "Epoch 225, lr 1.66015625e-06\n",
      "Epoch 225: Train 0.185, Test 0.206\n",
      "MSE NON-NORMALIZED: Train MSE 4.174, Test MSE 4.412\n",
      "TRAINING MODEL dt_norm_3_34\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.181, Test 0.175\n",
      "MSE NON-NORMALIZED: Train MSE 4.875, Test MSE 3.139\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.232, Test 0.212\n",
      "MSE NON-NORMALIZED: Train MSE 3.951, Test MSE 3.627\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.229, Test 0.208\n",
      "MSE NON-NORMALIZED: Train MSE 3.828, Test MSE 3.534\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.228, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.796, Test MSE 3.520\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.228, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.787, Test MSE 3.517\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.228, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.808, Test MSE 3.691\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.228, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.830, Test MSE 3.865\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.228, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.853, Test MSE 4.039\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.228, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.875, Test MSE 4.213\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.228, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.875, Test MSE 4.212\n",
      "TRAINING MODEL dt_norm_3_38\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.266, Test 0.307\n",
      "MSE NON-NORMALIZED: Train MSE 7.828, Test MSE 7.675\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.292, Test 0.336\n",
      "MSE NON-NORMALIZED: Train MSE 8.072, Test MSE 7.910\n",
      "Epoch 50, lr 0.00010625\n",
      "Epoch 50: Train 0.180, Test 0.202\n",
      "MSE NON-NORMALIZED: Train MSE 3.791, Test MSE 3.670\n",
      "Epoch 75, lr 0.00010625\n",
      "Epoch 75: Train 0.180, Test 0.202\n",
      "MSE NON-NORMALIZED: Train MSE 3.789, Test MSE 3.670\n",
      "Epoch 100, lr 0.00010625\n",
      "Epoch 100: Train 0.179, Test 0.203\n",
      "MSE NON-NORMALIZED: Train MSE 3.791, Test MSE 3.674\n",
      "Epoch 125, lr 0.00010625\n",
      "Epoch 125: Train 0.175, Test 0.195\n",
      "MSE NON-NORMALIZED: Train MSE 3.691, Test MSE 3.712\n",
      "Epoch 150, lr 0.00010625\n",
      "Epoch 150: Train 0.173, Test 0.192\n",
      "MSE NON-NORMALIZED: Train MSE 3.661, Test MSE 3.828\n",
      "Epoch 175, lr 2.65625e-05\n",
      "Epoch 175: Train 0.172, Test 0.191\n",
      "MSE NON-NORMALIZED: Train MSE 3.644, Test MSE 3.972\n",
      "Epoch 200, lr 3.3203125e-06\n",
      "Epoch 200: Train 0.171, Test 0.191\n",
      "MSE NON-NORMALIZED: Train MSE 3.657, Test MSE 4.121\n",
      "Epoch 225, lr 8.30078125e-07\n",
      "Epoch 225: Train 0.171, Test 0.191\n",
      "MSE NON-NORMALIZED: Train MSE 3.655, Test MSE 4.119\n",
      "TRAINING MODEL dt_norm_1_1\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.732, Test 0.791\n",
      "MSE NON-NORMALIZED: Train MSE 36.383, Test MSE 23.618\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.201, Test 0.214\n",
      "MSE NON-NORMALIZED: Train MSE 8.355, Test MSE 6.663\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 0.127, Test 0.145\n",
      "MSE NON-NORMALIZED: Train MSE 5.769, Test MSE 4.346\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 0.118, Test 0.134\n",
      "MSE NON-NORMALIZED: Train MSE 5.539, Test MSE 3.950\n",
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 0.117, Test 0.133\n",
      "MSE NON-NORMALIZED: Train MSE 5.541, Test MSE 4.018\n",
      "Epoch 125, lr 0.0002125\n",
      "Epoch 125: Train 0.100, Test 0.111\n",
      "MSE NON-NORMALIZED: Train MSE 4.685, Test MSE 3.335\n",
      "Epoch 150, lr 0.0002125\n",
      "Epoch 150: Train 0.099, Test 0.109\n",
      "MSE NON-NORMALIZED: Train MSE 4.716, Test MSE 3.336\n",
      "Epoch 175, lr 5.3125e-05\n",
      "Epoch 175: Train 0.092, Test 0.102\n",
      "MSE NON-NORMALIZED: Train MSE 4.228, Test MSE 3.181\n",
      "Epoch 200, lr 5.3125e-05\n",
      "Epoch 200: Train 0.092, Test 0.102\n",
      "MSE NON-NORMALIZED: Train MSE 4.243, Test MSE 3.243\n",
      "Epoch 225, lr 1.328125e-05\n",
      "Epoch 225: Train 0.090, Test 0.100\n",
      "MSE NON-NORMALIZED: Train MSE 4.130, Test MSE 3.194\n",
      "TRAINING MODEL dt_norm_1_3\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 4.359, Test 4.393\n",
      "MSE NON-NORMALIZED: Train MSE 141.623, Test MSE 127.650\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 3.424, Test 3.414\n",
      "MSE NON-NORMALIZED: Train MSE 102.357, Test MSE 95.091\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 3.934, Test 3.384\n",
      "MSE NON-NORMALIZED: Train MSE 99.357, Test MSE 96.232\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 3.051, Test 2.931\n",
      "MSE NON-NORMALIZED: Train MSE 85.558, Test MSE 79.189\n",
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 2.970, Test 2.835\n",
      "MSE NON-NORMALIZED: Train MSE 83.059, Test MSE 76.353\n",
      "Epoch 125, lr 0.0002125\n",
      "Epoch 125: Train 2.846, Test 2.717\n",
      "MSE NON-NORMALIZED: Train MSE 78.567, Test MSE 72.563\n",
      "Epoch 150, lr 0.0002125\n",
      "Epoch 150: Train 2.805, Test 2.678\n",
      "MSE NON-NORMALIZED: Train MSE 77.564, Test MSE 71.628\n",
      "Epoch 175, lr 0.0002125\n",
      "Epoch 175: Train 2.784, Test 2.645\n",
      "MSE NON-NORMALIZED: Train MSE 76.734, Test MSE 70.851\n",
      "Epoch 200, lr 0.0002125\n",
      "Epoch 200: Train 2.767, Test 2.625\n",
      "MSE NON-NORMALIZED: Train MSE 76.182, Test MSE 70.457\n",
      "Epoch 225, lr 0.0002125\n",
      "Epoch 225: Train 2.749, Test 2.603\n",
      "MSE NON-NORMALIZED: Train MSE 75.688, Test MSE 69.815\n",
      "TRAINING MODEL dt_norm_1_5\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 5.477, Test 5.346\n",
      "MSE NON-NORMALIZED: Train MSE 214.263, Test MSE 176.976\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 4.853, Test 4.474\n",
      "MSE NON-NORMALIZED: Train MSE 166.226, Test MSE 143.743\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 4.142, Test 3.659\n",
      "MSE NON-NORMALIZED: Train MSE 113.335, Test MSE 107.496\n",
      "Epoch 75, lr 0.0002125\n",
      "Epoch 75: Train 3.886, Test 3.350\n",
      "MSE NON-NORMALIZED: Train MSE 103.107, Test MSE 95.466\n",
      "Epoch 100, lr 0.0002125\n",
      "Epoch 100: Train 3.772, Test 3.253\n",
      "MSE NON-NORMALIZED: Train MSE 99.845, Test MSE 92.366\n",
      "Epoch 125, lr 0.0002125\n",
      "Epoch 125: Train 3.719, Test 3.177\n",
      "MSE NON-NORMALIZED: Train MSE 97.941, Test MSE 90.155\n",
      "Epoch 150, lr 0.00010625\n",
      "Epoch 150: Train 3.625, Test 3.065\n",
      "MSE NON-NORMALIZED: Train MSE 93.396, Test MSE 85.850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175, lr 0.00010625\n",
      "Epoch 175: Train 3.582, Test 3.036\n",
      "MSE NON-NORMALIZED: Train MSE 92.414, Test MSE 85.274\n",
      "Epoch 200, lr 0.00010625\n",
      "Epoch 200: Train 3.546, Test 3.001\n",
      "MSE NON-NORMALIZED: Train MSE 91.508, Test MSE 84.507\n",
      "Epoch 225, lr 0.00010625\n",
      "Epoch 225: Train 3.507, Test 2.960\n",
      "MSE NON-NORMALIZED: Train MSE 90.475, Test MSE 83.093\n",
      "TRAINING MODEL dt_norm_1_7\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 5.651, Test 4.962\n",
      "MSE NON-NORMALIZED: Train MSE 214.115, Test MSE 180.009\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 6.917, Test 6.977\n",
      "MSE NON-NORMALIZED: Train MSE 254.597, Test MSE 270.986\n",
      "Epoch 50, lr 0.0002125\n",
      "Epoch 50: Train 4.366, Test 3.988\n",
      "MSE NON-NORMALIZED: Train MSE 132.738, Test MSE 123.946\n",
      "Epoch 75, lr 0.00010625\n",
      "Epoch 75: Train 3.707, Test 3.350\n",
      "MSE NON-NORMALIZED: Train MSE 100.933, Test MSE 98.805\n",
      "Epoch 100, lr 5.3125e-05\n",
      "Epoch 100: Train 3.413, Test 3.000\n",
      "MSE NON-NORMALIZED: Train MSE 89.624, Test MSE 83.899\n",
      "Epoch 125, lr 2.65625e-05\n",
      "Epoch 125: Train 3.331, Test 2.922\n",
      "MSE NON-NORMALIZED: Train MSE 86.818, Test MSE 81.585\n",
      "Epoch 150, lr 1.328125e-05\n",
      "Epoch 150: Train 3.283, Test 2.866\n",
      "MSE NON-NORMALIZED: Train MSE 84.962, Test MSE 79.657\n",
      "Epoch 175, lr 1.328125e-05\n",
      "Epoch 175: Train 3.251, Test 2.834\n",
      "MSE NON-NORMALIZED: Train MSE 84.000, Test MSE 78.788\n",
      "Epoch 200, lr 1.328125e-05\n",
      "Epoch 200: Train 3.226, Test 2.807\n",
      "MSE NON-NORMALIZED: Train MSE 83.120, Test MSE 78.133\n",
      "Epoch 225, lr 1.328125e-05\n",
      "Epoch 225: Train 3.205, Test 2.781\n",
      "MSE NON-NORMALIZED: Train MSE 82.273, Test MSE 77.338\n",
      "TRAINING MODEL dt_norm_1_9\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 3.162, Test 3.639\n",
      "MSE NON-NORMALIZED: Train MSE 174.571, Test MSE 142.846\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 2.763, Test 3.052\n",
      "MSE NON-NORMALIZED: Train MSE 143.206, Test MSE 94.565\n",
      "Epoch 50, lr 0.0002125\n",
      "Epoch 50: Train 2.360, Test 2.462\n",
      "MSE NON-NORMALIZED: Train MSE 79.300, Test MSE 66.430\n",
      "Epoch 75, lr 0.00010625\n",
      "Epoch 75: Train 2.240, Test 2.291\n",
      "MSE NON-NORMALIZED: Train MSE 70.974, Test MSE 60.669\n",
      "Epoch 100, lr 5.3125e-05\n",
      "Epoch 100: Train 1.979, Test 2.142\n",
      "MSE NON-NORMALIZED: Train MSE 60.257, Test MSE 55.216\n",
      "Epoch 125, lr 5.3125e-05\n",
      "Epoch 125: Train 1.916, Test 2.072\n",
      "MSE NON-NORMALIZED: Train MSE 60.892, Test MSE 53.260\n",
      "Epoch 150, lr 2.65625e-05\n",
      "Epoch 150: Train 1.829, Test 2.010\n",
      "MSE NON-NORMALIZED: Train MSE 54.415, Test MSE 51.275\n",
      "Epoch 175, lr 2.65625e-05\n",
      "Epoch 175: Train 1.807, Test 1.982\n",
      "MSE NON-NORMALIZED: Train MSE 54.212, Test MSE 50.632\n",
      "Epoch 200, lr 2.65625e-05\n",
      "Epoch 200: Train 1.782, Test 1.958\n",
      "MSE NON-NORMALIZED: Train MSE 53.444, Test MSE 50.038\n",
      "Epoch 225, lr 2.65625e-05\n",
      "Epoch 225: Train 1.763, Test 1.935\n",
      "MSE NON-NORMALIZED: Train MSE 52.464, Test MSE 49.362\n",
      "TRAINING MODEL dt_norm_1_11\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 2.513, Test 2.745\n",
      "MSE NON-NORMALIZED: Train MSE 94.317, Test MSE 100.637\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 2.350, Test 2.304\n",
      "MSE NON-NORMALIZED: Train MSE 88.293, Test MSE 73.807\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 1.714, Test 1.655\n",
      "MSE NON-NORMALIZED: Train MSE 48.643, Test MSE 42.825\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 1.647, Test 1.619\n",
      "MSE NON-NORMALIZED: Train MSE 54.847, Test MSE 42.782\n",
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 1.611, Test 1.568\n",
      "MSE NON-NORMALIZED: Train MSE 46.924, Test MSE 41.428\n",
      "Epoch 125, lr 0.0002125\n",
      "Epoch 125: Train 1.481, Test 1.404\n",
      "MSE NON-NORMALIZED: Train MSE 36.448, Test MSE 34.454\n",
      "Epoch 150, lr 0.00010625\n",
      "Epoch 150: Train 1.436, Test 1.344\n",
      "MSE NON-NORMALIZED: Train MSE 33.658, Test MSE 31.971\n",
      "Epoch 175, lr 0.00010625\n",
      "Epoch 175: Train 1.411, Test 1.322\n",
      "MSE NON-NORMALIZED: Train MSE 33.056, Test MSE 31.487\n",
      "Epoch 200, lr 0.00010625\n",
      "Epoch 200: Train 1.398, Test 1.307\n",
      "MSE NON-NORMALIZED: Train MSE 32.895, Test MSE 31.165\n",
      "Epoch 225, lr 0.00010625\n",
      "Epoch 225: Train 1.394, Test 1.295\n",
      "MSE NON-NORMALIZED: Train MSE 32.692, Test MSE 30.801\n",
      "TRAINING MODEL dt_norm_1_13\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 1.552, Test 1.837\n",
      "MSE NON-NORMALIZED: Train MSE 66.714, Test MSE 69.505\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 1.230, Test 1.213\n",
      "MSE NON-NORMALIZED: Train MSE 49.619, Test MSE 30.653\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 1.140, Test 1.095\n",
      "MSE NON-NORMALIZED: Train MSE 31.646, Test MSE 25.962\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 1.096, Test 1.059\n",
      "MSE NON-NORMALIZED: Train MSE 29.934, Test MSE 24.910\n",
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 1.071, Test 1.033\n",
      "MSE NON-NORMALIZED: Train MSE 28.460, Test MSE 23.995\n",
      "Epoch 125, lr 0.0002125\n",
      "Epoch 125: Train 1.045, Test 0.991\n",
      "MSE NON-NORMALIZED: Train MSE 24.395, Test MSE 22.610\n",
      "Epoch 150, lr 0.0002125\n",
      "Epoch 150: Train 1.030, Test 0.977\n",
      "MSE NON-NORMALIZED: Train MSE 23.986, Test MSE 22.372\n",
      "Epoch 175, lr 0.0002125\n",
      "Epoch 175: Train 1.019, Test 0.965\n",
      "MSE NON-NORMALIZED: Train MSE 23.981, Test MSE 22.107\n",
      "Epoch 200, lr 0.0002125\n",
      "Epoch 200: Train 1.014, Test 0.959\n",
      "MSE NON-NORMALIZED: Train MSE 24.700, Test MSE 22.063\n",
      "Epoch 225, lr 0.0002125\n",
      "Epoch 225: Train 1.008, Test 0.958\n",
      "MSE NON-NORMALIZED: Train MSE 24.311, Test MSE 22.085\n",
      "TRAINING MODEL dt_norm_1_15\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 1.497, Test 1.529\n",
      "MSE NON-NORMALIZED: Train MSE 48.077, Test MSE 48.427\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 1.187, Test 1.104\n",
      "MSE NON-NORMALIZED: Train MSE 29.063, Test MSE 30.096\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 1.034, Test 0.934\n",
      "MSE NON-NORMALIZED: Train MSE 25.642, Test MSE 22.836\n",
      "Epoch 75, lr 0.0002125\n",
      "Epoch 75: Train 0.878, Test 0.805\n",
      "MSE NON-NORMALIZED: Train MSE 19.016, Test MSE 17.894\n",
      "Epoch 100, lr 0.0002125\n",
      "Epoch 100: Train 0.863, Test 0.790\n",
      "MSE NON-NORMALIZED: Train MSE 18.682, Test MSE 17.590\n",
      "Epoch 125, lr 0.00010625\n",
      "Epoch 125: Train 0.835, Test 0.771\n",
      "MSE NON-NORMALIZED: Train MSE 17.853, Test MSE 17.098\n",
      "Epoch 150, lr 0.00010625\n",
      "Epoch 150: Train 0.828, Test 0.763\n",
      "MSE NON-NORMALIZED: Train MSE 17.748, Test MSE 17.000\n",
      "Epoch 175, lr 0.00010625\n",
      "Epoch 175: Train 0.824, Test 0.759\n",
      "MSE NON-NORMALIZED: Train MSE 17.639, Test MSE 17.048\n",
      "Epoch 200, lr 5.3125e-05\n",
      "Epoch 200: Train 0.813, Test 0.751\n",
      "MSE NON-NORMALIZED: Train MSE 17.328, Test MSE 16.829\n",
      "Epoch 225, lr 5.3125e-05\n",
      "Epoch 225: Train 0.809, Test 0.748\n",
      "MSE NON-NORMALIZED: Train MSE 17.271, Test MSE 16.762\n",
      "TRAINING MODEL dt_norm_1_17\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 1.177, Test 1.078\n",
      "MSE NON-NORMALIZED: Train MSE 37.613, Test MSE 29.284\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 0.804, Test 0.744\n",
      "MSE NON-NORMALIZED: Train MSE 19.592, Test MSE 17.601\n",
      "Epoch 50, lr 0.0002125\n",
      "Epoch 50: Train 0.757, Test 0.680\n",
      "MSE NON-NORMALIZED: Train MSE 16.530, Test MSE 14.901\n",
      "Epoch 75, lr 0.0002125\n",
      "Epoch 75: Train 0.743, Test 0.667\n",
      "MSE NON-NORMALIZED: Train MSE 16.120, Test MSE 14.697\n",
      "Epoch 100, lr 0.0002125\n",
      "Epoch 100: Train 0.725, Test 0.652\n",
      "MSE NON-NORMALIZED: Train MSE 15.868, Test MSE 14.220\n",
      "Epoch 125, lr 0.0002125\n",
      "Epoch 125: Train 0.727, Test 0.655\n",
      "MSE NON-NORMALIZED: Train MSE 15.623, Test MSE 14.559\n",
      "Epoch 150, lr 0.00010625\n",
      "Epoch 150: Train 0.698, Test 0.627\n",
      "MSE NON-NORMALIZED: Train MSE 14.446, Test MSE 13.640\n",
      "Epoch 175, lr 0.00010625\n",
      "Epoch 175: Train 0.694, Test 0.624\n",
      "MSE NON-NORMALIZED: Train MSE 14.465, Test MSE 13.736\n",
      "Epoch 200, lr 0.00010625\n",
      "Epoch 200: Train 0.688, Test 0.618\n",
      "MSE NON-NORMALIZED: Train MSE 14.418, Test MSE 13.709\n",
      "Epoch 225, lr 0.00010625\n",
      "Epoch 225: Train 0.686, Test 0.617\n",
      "MSE NON-NORMALIZED: Train MSE 14.297, Test MSE 13.704\n",
      "TRAINING MODEL dt_norm_1_19\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.966, Test 0.956\n",
      "MSE NON-NORMALIZED: Train MSE 30.851, Test MSE 26.065\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.611, Test 0.642\n",
      "MSE NON-NORMALIZED: Train MSE 17.508, Test MSE 14.301\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 0.602, Test 0.643\n",
      "MSE NON-NORMALIZED: Train MSE 16.004, Test MSE 14.460\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 0.536, Test 0.566\n",
      "MSE NON-NORMALIZED: Train MSE 13.276, Test MSE 12.011\n",
      "Epoch 100, lr 0.00010625\n",
      "Epoch 100: Train 0.508, Test 0.533\n",
      "MSE NON-NORMALIZED: Train MSE 11.871, Test MSE 10.919\n",
      "Epoch 225, lr 2.0751953125e-07\n",
      "Epoch 225: Train 0.499, Test 0.523\n",
      "MSE NON-NORMALIZED: Train MSE 11.571, Test MSE 11.137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL dt_norm_1_21\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.625, Test 0.719\n",
      "MSE NON-NORMALIZED: Train MSE 19.817, Test MSE 16.754\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.557, Test 0.503\n",
      "MSE NON-NORMALIZED: Train MSE 11.360, Test MSE 10.718\n",
      "Epoch 50, lr 0.00010625\n",
      "Epoch 50: Train 0.522, Test 0.464\n",
      "MSE NON-NORMALIZED: Train MSE 10.197, Test MSE 9.543\n",
      "Epoch 75, lr 0.00010625\n",
      "Epoch 75: Train 0.517, Test 0.460\n",
      "MSE NON-NORMALIZED: Train MSE 10.123, Test MSE 9.448\n",
      "Epoch 100, lr 5.3125e-05\n",
      "Epoch 100: Train 0.511, Test 0.452\n",
      "MSE NON-NORMALIZED: Train MSE 9.923, Test MSE 9.239\n",
      "Epoch 125, lr 5.3125e-05\n",
      "Epoch 125: Train 0.510, Test 0.452\n",
      "MSE NON-NORMALIZED: Train MSE 9.916, Test MSE 9.357\n",
      "Epoch 150, lr 2.65625e-05\n",
      "Epoch 150: Train 0.506, Test 0.449\n",
      "MSE NON-NORMALIZED: Train MSE 9.853, Test MSE 9.394\n",
      "Epoch 175, lr 2.65625e-05\n",
      "Epoch 175: Train 0.505, Test 0.448\n",
      "MSE NON-NORMALIZED: Train MSE 9.861, Test MSE 9.503\n",
      "Epoch 200, lr 1.328125e-05\n",
      "Epoch 200: Train 0.504, Test 0.447\n",
      "MSE NON-NORMALIZED: Train MSE 9.837, Test MSE 9.582\n",
      "Epoch 225, lr 1.328125e-05\n",
      "Epoch 225: Train 0.503, Test 0.447\n",
      "MSE NON-NORMALIZED: Train MSE 9.833, Test MSE 9.578\n",
      "TRAINING MODEL dt_norm_1_23\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.547, Test 0.586\n",
      "MSE NON-NORMALIZED: Train MSE 14.074, Test MSE 11.982\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 0.406, Test 0.458\n",
      "MSE NON-NORMALIZED: Train MSE 9.604, Test MSE 8.960\n",
      "Epoch 50, lr 0.00010625\n",
      "Epoch 50: Train 0.388, Test 0.438\n",
      "MSE NON-NORMALIZED: Train MSE 8.997, Test MSE 8.475\n",
      "Epoch 75, lr 0.00010625\n",
      "Epoch 75: Train 0.379, Test 0.428\n",
      "MSE NON-NORMALIZED: Train MSE 8.763, Test MSE 8.215\n",
      "Epoch 100, lr 5.3125e-05\n",
      "Epoch 100: Train 0.379, Test 0.424\n",
      "MSE NON-NORMALIZED: Train MSE 8.655, Test MSE 8.123\n",
      "Epoch 125, lr 1.328125e-05\n",
      "Epoch 125: Train 0.375, Test 0.419\n",
      "MSE NON-NORMALIZED: Train MSE 8.587, Test MSE 8.142\n",
      "Epoch 150, lr 3.3203125e-06\n",
      "Epoch 150: Train 0.375, Test 0.418\n",
      "MSE NON-NORMALIZED: Train MSE 8.582, Test MSE 8.247\n",
      "Epoch 175, lr 4.150390625e-07\n",
      "Epoch 175: Train 0.375, Test 0.418\n",
      "MSE NON-NORMALIZED: Train MSE 8.591, Test MSE 8.365\n",
      "Epoch 200, lr 1.03759765625e-07\n",
      "Epoch 200: Train 0.375, Test 0.418\n",
      "MSE NON-NORMALIZED: Train MSE 8.607, Test MSE 8.485\n",
      "Epoch 225, lr 2.593994140625e-08\n",
      "Epoch 225: Train 0.375, Test 0.418\n",
      "MSE NON-NORMALIZED: Train MSE 8.606, Test MSE 8.484\n",
      "TRAINING MODEL dt_norm_1_25\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.650, Test 0.552\n",
      "MSE NON-NORMALIZED: Train MSE 14.379, Test MSE 11.759\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.516, Test 0.496\n",
      "MSE NON-NORMALIZED: Train MSE 10.957, Test MSE 10.326\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 0.465, Test 0.439\n",
      "MSE NON-NORMALIZED: Train MSE 9.619, Test MSE 8.884\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 0.454, Test 0.433\n",
      "MSE NON-NORMALIZED: Train MSE 9.497, Test MSE 8.677\n",
      "Epoch 100, lr 0.0002125\n",
      "Epoch 100: Train 0.444, Test 0.421\n",
      "MSE NON-NORMALIZED: Train MSE 9.013, Test MSE 8.349\n",
      "Epoch 125, lr 0.00010625\n",
      "Epoch 125: Train 0.435, Test 0.414\n",
      "MSE NON-NORMALIZED: Train MSE 8.817, Test MSE 8.338\n",
      "Epoch 150, lr 2.65625e-05\n",
      "Epoch 150: Train 0.426, Test 0.409\n",
      "MSE NON-NORMALIZED: Train MSE 8.695, Test MSE 8.371\n",
      "Epoch 175, lr 6.640625e-06\n",
      "Epoch 175: Train 0.424, Test 0.408\n",
      "MSE NON-NORMALIZED: Train MSE 8.679, Test MSE 8.512\n",
      "Epoch 200, lr 1.66015625e-06\n",
      "Epoch 200: Train 0.424, Test 0.407\n",
      "MSE NON-NORMALIZED: Train MSE 8.691, Test MSE 8.664\n",
      "Epoch 225, lr 4.150390625e-07\n",
      "Epoch 225: Train 0.424, Test 0.407\n",
      "MSE NON-NORMALIZED: Train MSE 8.689, Test MSE 8.660\n",
      "TRAINING MODEL dt_norm_1_27\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.317, Test 0.350\n",
      "MSE NON-NORMALIZED: Train MSE 7.811, Test MSE 6.587\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 0.306, Test 0.336\n",
      "MSE NON-NORMALIZED: Train MSE 7.005, Test MSE 6.165\n",
      "Epoch 50, lr 0.0002125\n",
      "Epoch 50: Train 0.296, Test 0.328\n",
      "MSE NON-NORMALIZED: Train MSE 6.742, Test MSE 5.985\n",
      "Epoch 75, lr 0.0002125\n",
      "Epoch 75: Train 0.293, Test 0.325\n",
      "MSE NON-NORMALIZED: Train MSE 6.682, Test MSE 5.927\n",
      "Epoch 100, lr 0.0002125\n",
      "Epoch 100: Train 0.292, Test 0.323\n",
      "MSE NON-NORMALIZED: Train MSE 6.636, Test MSE 5.887\n",
      "Epoch 125, lr 5.3125e-05\n",
      "Epoch 125: Train 0.287, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 6.537, Test MSE 6.020\n",
      "Epoch 150, lr 1.328125e-05\n",
      "Epoch 150: Train 0.284, Test 0.315\n",
      "MSE NON-NORMALIZED: Train MSE 6.467, Test MSE 6.174\n",
      "Epoch 175, lr 3.3203125e-06\n",
      "Epoch 175: Train 0.284, Test 0.315\n",
      "MSE NON-NORMALIZED: Train MSE 6.483, Test MSE 6.390\n",
      "Epoch 200, lr 8.30078125e-07\n",
      "Epoch 200: Train 0.284, Test 0.315\n",
      "MSE NON-NORMALIZED: Train MSE 6.509, Test MSE 6.607\n",
      "Epoch 225, lr 2.0751953125e-07\n",
      "Epoch 225: Train 0.284, Test 0.315\n",
      "MSE NON-NORMALIZED: Train MSE 6.508, Test MSE 6.606\n",
      "TRAINING MODEL dt_norm_1_29\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.379, Test 0.384\n",
      "MSE NON-NORMALIZED: Train MSE 9.121, Test MSE 7.355\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.463, Test 0.449\n",
      "MSE NON-NORMALIZED: Train MSE 9.108, Test MSE 7.970\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.450, Test 0.434\n",
      "MSE NON-NORMALIZED: Train MSE 8.498, Test MSE 7.637\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.450, Test 0.432\n",
      "MSE NON-NORMALIZED: Train MSE 8.414, Test MSE 7.592\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.449, Test 0.431\n",
      "MSE NON-NORMALIZED: Train MSE 8.391, Test MSE 7.585\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.449, Test 0.431\n",
      "MSE NON-NORMALIZED: Train MSE 8.430, Test MSE 7.893\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.449, Test 0.431\n",
      "MSE NON-NORMALIZED: Train MSE 8.470, Test MSE 8.200\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.449, Test 0.431\n",
      "MSE NON-NORMALIZED: Train MSE 8.510, Test MSE 8.505\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.449, Test 0.431\n",
      "MSE NON-NORMALIZED: Train MSE 8.550, Test MSE 8.810\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.449, Test 0.431\n",
      "MSE NON-NORMALIZED: Train MSE 8.550, Test MSE 8.808\n",
      "TRAINING MODEL dt_norm_1_30\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.411, Test 0.348\n",
      "MSE NON-NORMALIZED: Train MSE 8.285, Test MSE 6.070\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.490, Test 0.431\n",
      "MSE NON-NORMALIZED: Train MSE 8.331, Test MSE 7.442\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.484, Test 0.427\n",
      "MSE NON-NORMALIZED: Train MSE 8.113, Test MSE 7.338\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.482, Test 0.425\n",
      "MSE NON-NORMALIZED: Train MSE 8.058, Test MSE 7.317\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.481, Test 0.425\n",
      "MSE NON-NORMALIZED: Train MSE 8.044, Test MSE 7.311\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.481, Test 0.425\n",
      "MSE NON-NORMALIZED: Train MSE 8.081, Test MSE 7.603\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.481, Test 0.425\n",
      "MSE NON-NORMALIZED: Train MSE 8.119, Test MSE 7.894\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.481, Test 0.425\n",
      "MSE NON-NORMALIZED: Train MSE 8.157, Test MSE 8.184\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.481, Test 0.425\n",
      "MSE NON-NORMALIZED: Train MSE 8.195, Test MSE 8.474\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.481, Test 0.425\n",
      "MSE NON-NORMALIZED: Train MSE 8.195, Test MSE 8.473\n",
      "TRAINING MODEL dt_norm_1_31\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 1.521, Test 0.470\n",
      "MSE NON-NORMALIZED: Train MSE 9.473, Test MSE 23.146\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.316, Test 0.356\n",
      "MSE NON-NORMALIZED: Train MSE 7.142, Test MSE 6.581\n",
      "Epoch 50, lr 0.00010625\n",
      "Epoch 50: Train 0.316, Test 0.355\n",
      "MSE NON-NORMALIZED: Train MSE 6.930, Test MSE 6.492\n",
      "Epoch 75, lr 2.65625e-05\n",
      "Epoch 75: Train 0.311, Test 0.350\n",
      "MSE NON-NORMALIZED: Train MSE 6.803, Test MSE 6.344\n",
      "Epoch 100, lr 6.640625e-06\n",
      "Epoch 100: Train 0.311, Test 0.350\n",
      "MSE NON-NORMALIZED: Train MSE 6.779, Test MSE 6.334\n",
      "Epoch 125, lr 1.66015625e-06\n",
      "Epoch 125: Train 0.311, Test 0.350\n",
      "MSE NON-NORMALIZED: Train MSE 6.808, Test MSE 6.597\n",
      "Epoch 150, lr 2.0751953125e-07\n",
      "Epoch 150: Train 0.310, Test 0.350\n",
      "MSE NON-NORMALIZED: Train MSE 6.841, Test MSE 6.858\n",
      "Epoch 175, lr 5.18798828125e-08\n",
      "Epoch 175: Train 0.310, Test 0.350\n",
      "MSE NON-NORMALIZED: Train MSE 6.876, Test MSE 7.117\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.310, Test 0.350\n",
      "MSE NON-NORMALIZED: Train MSE 6.910, Test MSE 7.377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.310, Test 0.350\n",
      "MSE NON-NORMALIZED: Train MSE 6.909, Test MSE 7.376\n",
      "TRAINING MODEL dt_norm_1_32\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.361, Test 0.319\n",
      "MSE NON-NORMALIZED: Train MSE 7.710, Test MSE 6.129\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.469, Test 0.407\n",
      "MSE NON-NORMALIZED: Train MSE 7.537, Test MSE 7.036\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.460, Test 0.401\n",
      "MSE NON-NORMALIZED: Train MSE 7.353, Test MSE 6.905\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.459, Test 0.401\n",
      "MSE NON-NORMALIZED: Train MSE 7.311, Test MSE 6.882\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.458, Test 0.401\n",
      "MSE NON-NORMALIZED: Train MSE 7.299, Test MSE 6.879\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.458, Test 0.400\n",
      "MSE NON-NORMALIZED: Train MSE 7.330, Test MSE 7.123\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.458, Test 0.400\n",
      "MSE NON-NORMALIZED: Train MSE 7.362, Test MSE 7.365\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.458, Test 0.400\n",
      "MSE NON-NORMALIZED: Train MSE 7.394, Test MSE 7.606\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.458, Test 0.400\n",
      "MSE NON-NORMALIZED: Train MSE 7.425, Test MSE 7.847\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.458, Test 0.400\n",
      "MSE NON-NORMALIZED: Train MSE 7.425, Test MSE 7.846\n",
      "TRAINING MODEL dt_norm_1_33\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.347, Test 0.328\n",
      "MSE NON-NORMALIZED: Train MSE 8.497, Test MSE 6.109\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.420, Test 0.470\n",
      "MSE NON-NORMALIZED: Train MSE 8.967, Test MSE 7.951\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 0.414, Test 0.469\n",
      "MSE NON-NORMALIZED: Train MSE 8.620, Test MSE 7.947\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 0.402, Test 0.456\n",
      "MSE NON-NORMALIZED: Train MSE 8.211, Test MSE 7.666\n",
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 0.392, Test 0.442\n",
      "MSE NON-NORMALIZED: Train MSE 8.177, Test MSE 7.437\n",
      "Epoch 125, lr 0.000425\n",
      "Epoch 125: Train 0.383, Test 0.433\n",
      "MSE NON-NORMALIZED: Train MSE 7.914, Test MSE 7.510\n",
      "Epoch 150, lr 0.0002125\n",
      "Epoch 150: Train 0.375, Test 0.425\n",
      "MSE NON-NORMALIZED: Train MSE 7.644, Test MSE 7.572\n",
      "Epoch 175, lr 0.00010625\n",
      "Epoch 175: Train 0.372, Test 0.421\n",
      "MSE NON-NORMALIZED: Train MSE 7.549, Test MSE 7.717\n",
      "Epoch 200, lr 2.65625e-05\n",
      "Epoch 200: Train 0.370, Test 0.419\n",
      "MSE NON-NORMALIZED: Train MSE 7.513, Test MSE 7.881\n",
      "Epoch 225, lr 2.65625e-05\n",
      "Epoch 225: Train 0.369, Test 0.418\n",
      "MSE NON-NORMALIZED: Train MSE 7.504, Test MSE 7.869\n",
      "TRAINING MODEL dt_norm_2_1\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 3972\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 2.299, Test 2.481\n",
      "MSE NON-NORMALIZED: Train MSE 73.309, Test MSE 69.970\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 1.063, Test 1.622\n",
      "MSE NON-NORMALIZED: Train MSE 49.583, Test MSE 49.001\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 0.824, Test 1.326\n",
      "MSE NON-NORMALIZED: Train MSE 42.950, Test MSE 42.254\n",
      "Epoch 75, lr 0.00085\n",
      "Epoch 75: Train 0.823, Test 1.001\n",
      "MSE NON-NORMALIZED: Train MSE 28.088, Test MSE 26.861\n",
      "Epoch 100, lr 0.00085\n",
      "Epoch 100: Train 0.440, Test 0.651\n",
      "MSE NON-NORMALIZED: Train MSE 20.089, Test MSE 18.957\n",
      "Epoch 125, lr 0.0002125\n",
      "Epoch 125: Train 0.437, Test 0.628\n",
      "MSE NON-NORMALIZED: Train MSE 19.262, Test MSE 18.124\n",
      "Epoch 150, lr 2.65625e-05\n",
      "Epoch 150: Train 0.437, Test 0.623\n",
      "MSE NON-NORMALIZED: Train MSE 19.031, Test MSE 17.999\n",
      "Epoch 175, lr 6.640625e-06\n",
      "Epoch 175: Train 0.437, Test 0.623\n",
      "MSE NON-NORMALIZED: Train MSE 19.070, Test MSE 18.144\n",
      "Epoch 200, lr 1.66015625e-06\n",
      "Epoch 200: Train 0.437, Test 0.623\n",
      "MSE NON-NORMALIZED: Train MSE 19.122, Test MSE 18.292\n",
      "Epoch 225, lr 4.150390625e-07\n",
      "Epoch 225: Train 0.437, Test 0.623\n",
      "MSE NON-NORMALIZED: Train MSE 19.122, Test MSE 18.292\n",
      "TRAINING MODEL dt_norm_2_3\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 4.038, Test 3.766\n",
      "MSE NON-NORMALIZED: Train MSE 145.178, Test MSE 113.341\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 3.898, Test 4.074\n",
      "MSE NON-NORMALIZED: Train MSE 121.283, Test MSE 122.478\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 3.198, Test 3.098\n",
      "MSE NON-NORMALIZED: Train MSE 100.268, Test MSE 92.754\n",
      "Epoch 75, lr 0.00085\n",
      "Epoch 75: Train 3.105, Test 2.978\n",
      "MSE NON-NORMALIZED: Train MSE 97.273, Test MSE 88.587\n",
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 3.262, Test 3.159\n",
      "MSE NON-NORMALIZED: Train MSE 109.820, Test MSE 92.825\n",
      "Epoch 125, lr 0.00010625\n",
      "Epoch 125: Train 2.818, Test 2.578\n",
      "MSE NON-NORMALIZED: Train MSE 78.509, Test MSE 78.213\n",
      "Epoch 150, lr 2.65625e-05\n",
      "Epoch 150: Train 2.802, Test 2.557\n",
      "MSE NON-NORMALIZED: Train MSE 78.072, Test MSE 78.698\n",
      "Epoch 175, lr 6.640625e-06\n",
      "Epoch 175: Train 2.799, Test 2.552\n",
      "MSE NON-NORMALIZED: Train MSE 78.094, Test MSE 79.618\n",
      "Epoch 200, lr 1.66015625e-06\n",
      "Epoch 200: Train 2.798, Test 2.551\n",
      "MSE NON-NORMALIZED: Train MSE 78.200, Test MSE 80.647\n",
      "Epoch 225, lr 2.0751953125e-07\n",
      "Epoch 225: Train 2.798, Test 2.551\n",
      "MSE NON-NORMALIZED: Train MSE 78.192, Test MSE 80.642\n",
      "TRAINING MODEL dt_norm_2_5\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 5.878, Test 4.252\n",
      "MSE NON-NORMALIZED: Train MSE 172.043, Test MSE 150.134\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 5.390, Test 3.963\n",
      "MSE NON-NORMALIZED: Train MSE 192.108, Test MSE 145.125\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 5.142, Test 3.699\n",
      "MSE NON-NORMALIZED: Train MSE 166.066, Test MSE 134.721\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 4.688, Test 3.349\n",
      "MSE NON-NORMALIZED: Train MSE 144.979, Test MSE 121.162\n",
      "Epoch 100, lr 0.0002125\n",
      "Epoch 100: Train 4.591, Test 3.223\n",
      "MSE NON-NORMALIZED: Train MSE 122.525, Test MSE 114.982\n",
      "Epoch 125, lr 0.00010625\n",
      "Epoch 125: Train 4.573, Test 3.194\n",
      "MSE NON-NORMALIZED: Train MSE 116.547, Test MSE 114.630\n",
      "Epoch 150, lr 2.65625e-05\n",
      "Epoch 150: Train 4.565, Test 3.185\n",
      "MSE NON-NORMALIZED: Train MSE 114.295, Test MSE 115.459\n",
      "Epoch 175, lr 6.640625e-06\n",
      "Epoch 175: Train 4.560, Test 3.181\n",
      "MSE NON-NORMALIZED: Train MSE 114.282, Test MSE 116.490\n",
      "Epoch 200, lr 1.66015625e-06\n",
      "Epoch 200: Train 4.559, Test 3.180\n",
      "MSE NON-NORMALIZED: Train MSE 114.400, Test MSE 117.597\n",
      "Epoch 225, lr 2.0751953125e-07\n",
      "Epoch 225: Train 4.559, Test 3.180\n",
      "MSE NON-NORMALIZED: Train MSE 114.392, Test MSE 117.589\n",
      "TRAINING MODEL dt_norm_2_7\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 4.209, Test 4.878\n",
      "MSE NON-NORMALIZED: Train MSE 221.124, Test MSE 275.450\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 6.396, Test 5.445\n",
      "MSE NON-NORMALIZED: Train MSE 411.346, Test MSE 258.058\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 6.043, Test 4.958\n",
      "MSE NON-NORMALIZED: Train MSE 393.003, Test MSE 239.675\n",
      "Epoch 75, lr 2.65625e-05\n",
      "Epoch 75: Train 3.924, Test 4.118\n",
      "MSE NON-NORMALIZED: Train MSE 329.137, Test MSE 199.868\n",
      "Epoch 100, lr 2.65625e-05\n",
      "Epoch 100: Train 3.320, Test 3.432\n",
      "MSE NON-NORMALIZED: Train MSE 238.238, Test MSE 177.230\n",
      "Epoch 125, lr 2.65625e-05\n",
      "Epoch 125: Train 3.257, Test 3.379\n",
      "MSE NON-NORMALIZED: Train MSE 174.294, Test MSE 176.606\n",
      "Epoch 150, lr 1.328125e-05\n",
      "Epoch 150: Train 3.240, Test 3.354\n",
      "MSE NON-NORMALIZED: Train MSE 173.511, Test MSE 177.219\n",
      "Epoch 175, lr 3.3203125e-06\n",
      "Epoch 175: Train 3.229, Test 3.344\n",
      "MSE NON-NORMALIZED: Train MSE 173.206, Test MSE 178.059\n",
      "Epoch 200, lr 4.150390625e-07\n",
      "Epoch 200: Train 3.228, Test 3.342\n",
      "MSE NON-NORMALIZED: Train MSE 173.268, Test MSE 179.212\n",
      "Epoch 225, lr 1.03759765625e-07\n",
      "Epoch 225: Train 3.228, Test 3.342\n",
      "MSE NON-NORMALIZED: Train MSE 173.264, Test MSE 179.206\n",
      "TRAINING MODEL dt_norm_2_9\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 2.084, Test 2.721\n",
      "MSE NON-NORMALIZED: Train MSE 135.939, Test MSE 121.932\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 7.977, Test 13.376\n",
      "MSE NON-NORMALIZED: Train MSE 1380.879, Test MSE 1091.209\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 7.828, Test 13.235\n",
      "MSE NON-NORMALIZED: Train MSE 1374.538, Test MSE 1083.545\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 7.742, Test 13.202\n",
      "MSE NON-NORMALIZED: Train MSE 1357.089, Test MSE 1082.461\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 7.738, Test 13.200\n",
      "MSE NON-NORMALIZED: Train MSE 1356.878, Test MSE 1082.398\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 7.740, Test 13.196\n",
      "MSE NON-NORMALIZED: Train MSE 1356.929, Test MSE 1083.913\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 7.740, Test 13.195\n",
      "MSE NON-NORMALIZED: Train MSE 1357.122, Test MSE 1085.564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 7.740, Test 13.195\n",
      "MSE NON-NORMALIZED: Train MSE 1357.336, Test MSE 1087.233\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 7.740, Test 13.195\n",
      "MSE NON-NORMALIZED: Train MSE 1357.551, Test MSE 1088.903\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 7.739, Test 13.195\n",
      "MSE NON-NORMALIZED: Train MSE 1357.550, Test MSE 1088.902\n",
      "TRAINING MODEL dt_norm_2_11\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 1.446, Test 1.849\n",
      "MSE NON-NORMALIZED: Train MSE 82.013, Test MSE 68.350\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 23.241, Test 14.669\n",
      "MSE NON-NORMALIZED: Train MSE 1508.969, Test MSE 1302.892\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 23.024, Test 14.157\n",
      "MSE NON-NORMALIZED: Train MSE 1482.114, Test MSE 1276.166\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 22.963, Test 14.100\n",
      "MSE NON-NORMALIZED: Train MSE 1480.003, Test MSE 1274.197\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 22.957, Test 14.095\n",
      "MSE NON-NORMALIZED: Train MSE 1479.879, Test MSE 1274.094\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 22.955, Test 14.094\n",
      "MSE NON-NORMALIZED: Train MSE 1480.039, Test MSE 1275.524\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 22.955, Test 14.094\n",
      "MSE NON-NORMALIZED: Train MSE 1480.225, Test MSE 1276.977\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 22.955, Test 14.094\n",
      "MSE NON-NORMALIZED: Train MSE 1480.413, Test MSE 1278.431\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 22.955, Test 14.094\n",
      "MSE NON-NORMALIZED: Train MSE 1480.603, Test MSE 1279.884\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 22.954, Test 14.094\n",
      "MSE NON-NORMALIZED: Train MSE 1480.602, Test MSE 1279.883\n",
      "TRAINING MODEL dt_norm_2_13\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 1.366, Test 1.441\n",
      "MSE NON-NORMALIZED: Train MSE 45.374, Test MSE 41.593\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 1.979, Test 2.899\n",
      "MSE NON-NORMALIZED: Train MSE 122.458, Test MSE 85.199\n",
      "Epoch 50, lr 0.00010625\n",
      "Epoch 50: Train 1.181, Test 1.796\n",
      "MSE NON-NORMALIZED: Train MSE 57.205, Test MSE 53.143\n",
      "Epoch 75, lr 5.3125e-05\n",
      "Epoch 75: Train 1.172, Test 1.630\n",
      "MSE NON-NORMALIZED: Train MSE 53.832, Test MSE 46.841\n",
      "Epoch 100, lr 5.3125e-05\n",
      "Epoch 100: Train 1.101, Test 1.118\n",
      "MSE NON-NORMALIZED: Train MSE 32.341, Test MSE 30.475\n",
      "Epoch 125, lr 5.3125e-05\n",
      "Epoch 125: Train 1.087, Test 1.089\n",
      "MSE NON-NORMALIZED: Train MSE 31.374, Test MSE 30.412\n",
      "Epoch 150, lr 2.65625e-05\n",
      "Epoch 150: Train 1.082, Test 1.075\n",
      "MSE NON-NORMALIZED: Train MSE 30.688, Test MSE 30.687\n",
      "Epoch 175, lr 6.640625e-06\n",
      "Epoch 175: Train 1.079, Test 1.070\n",
      "MSE NON-NORMALIZED: Train MSE 30.540, Test MSE 31.197\n",
      "Epoch 200, lr 1.66015625e-06\n",
      "Epoch 200: Train 1.079, Test 1.069\n",
      "MSE NON-NORMALIZED: Train MSE 30.587, Test MSE 31.782\n",
      "Epoch 225, lr 2.0751953125e-07\n",
      "Epoch 225: Train 1.079, Test 1.069\n",
      "MSE NON-NORMALIZED: Train MSE 30.579, Test MSE 31.776\n",
      "TRAINING MODEL dt_norm_2_15\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.802, Test 1.001\n",
      "MSE NON-NORMALIZED: Train MSE 30.916, Test MSE 26.826\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.668, Test 0.878\n",
      "MSE NON-NORMALIZED: Train MSE 25.871, Test MSE 23.565\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 0.648, Test 0.838\n",
      "MSE NON-NORMALIZED: Train MSE 24.598, Test MSE 22.470\n",
      "Epoch 75, lr 0.00085\n",
      "Epoch 75: Train 0.637, Test 0.827\n",
      "MSE NON-NORMALIZED: Train MSE 24.015, Test MSE 22.239\n",
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 0.615, Test 0.811\n",
      "MSE NON-NORMALIZED: Train MSE 23.156, Test MSE 21.800\n",
      "Epoch 125, lr 0.0002125\n",
      "Epoch 125: Train 0.611, Test 0.803\n",
      "MSE NON-NORMALIZED: Train MSE 22.735, Test MSE 22.087\n",
      "Epoch 150, lr 0.00010625\n",
      "Epoch 150: Train 0.605, Test 0.796\n",
      "MSE NON-NORMALIZED: Train MSE 22.656, Test MSE 22.430\n",
      "Epoch 175, lr 1.328125e-05\n",
      "Epoch 175: Train 0.602, Test 0.794\n",
      "MSE NON-NORMALIZED: Train MSE 22.626, Test MSE 22.880\n",
      "Epoch 200, lr 3.3203125e-06\n",
      "Epoch 200: Train 0.602, Test 0.794\n",
      "MSE NON-NORMALIZED: Train MSE 22.684, Test MSE 23.381\n",
      "Epoch 225, lr 8.30078125e-07\n",
      "Epoch 225: Train 0.602, Test 0.794\n",
      "MSE NON-NORMALIZED: Train MSE 22.681, Test MSE 23.380\n",
      "TRAINING MODEL dt_norm_2_17\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 1.066, Test 0.923\n",
      "MSE NON-NORMALIZED: Train MSE 29.834, Test MSE 24.193\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.581, Test 0.678\n",
      "MSE NON-NORMALIZED: Train MSE 17.759, Test MSE 17.001\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 0.549, Test 0.646\n",
      "MSE NON-NORMALIZED: Train MSE 16.985, Test MSE 16.200\n",
      "Epoch 75, lr 0.0002125\n",
      "Epoch 75: Train 0.531, Test 0.624\n",
      "MSE NON-NORMALIZED: Train MSE 15.923, Test MSE 15.424\n",
      "Epoch 100, lr 0.00010625\n",
      "Epoch 100: Train 0.525, Test 0.621\n",
      "MSE NON-NORMALIZED: Train MSE 15.711, Test MSE 15.240\n",
      "Epoch 125, lr 5.3125e-05\n",
      "Epoch 125: Train 0.523, Test 0.619\n",
      "MSE NON-NORMALIZED: Train MSE 15.681, Test MSE 15.639\n",
      "Epoch 150, lr 1.328125e-05\n",
      "Epoch 150: Train 0.523, Test 0.619\n",
      "MSE NON-NORMALIZED: Train MSE 15.705, Test MSE 16.066\n",
      "Epoch 175, lr 3.3203125e-06\n",
      "Epoch 175: Train 0.523, Test 0.619\n",
      "MSE NON-NORMALIZED: Train MSE 15.754, Test MSE 16.505\n",
      "Epoch 200, lr 4.150390625e-07\n",
      "Epoch 200: Train 0.523, Test 0.619\n",
      "MSE NON-NORMALIZED: Train MSE 15.809, Test MSE 16.941\n",
      "Epoch 225, lr 1.03759765625e-07\n",
      "Epoch 225: Train 0.523, Test 0.619\n",
      "MSE NON-NORMALIZED: Train MSE 15.808, Test MSE 16.941\n",
      "TRAINING MODEL dt_norm_2_19\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 1.051, Test 1.256\n",
      "MSE NON-NORMALIZED: Train MSE 45.084, Test MSE 47.403\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.928, Test 1.004\n",
      "MSE NON-NORMALIZED: Train MSE 37.561, Test MSE 37.377\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 0.816, Test 0.901\n",
      "MSE NON-NORMALIZED: Train MSE 31.628, Test MSE 31.451\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 0.767, Test 0.861\n",
      "MSE NON-NORMALIZED: Train MSE 30.522, Test MSE 30.198\n",
      "Epoch 100, lr 0.00010625\n",
      "Epoch 100: Train 0.754, Test 0.844\n",
      "MSE NON-NORMALIZED: Train MSE 29.812, Test MSE 29.516\n",
      "Epoch 125, lr 2.65625e-05\n",
      "Epoch 125: Train 0.751, Test 0.841\n",
      "MSE NON-NORMALIZED: Train MSE 29.797, Test MSE 29.884\n",
      "Epoch 150, lr 6.640625e-06\n",
      "Epoch 150: Train 0.750, Test 0.841\n",
      "MSE NON-NORMALIZED: Train MSE 29.843, Test MSE 30.338\n",
      "Epoch 175, lr 1.66015625e-06\n",
      "Epoch 175: Train 0.750, Test 0.840\n",
      "MSE NON-NORMALIZED: Train MSE 29.900, Test MSE 30.798\n",
      "Epoch 200, lr 2.0751953125e-07\n",
      "Epoch 200: Train 0.750, Test 0.840\n",
      "MSE NON-NORMALIZED: Train MSE 29.959, Test MSE 31.257\n",
      "Epoch 225, lr 5.18798828125e-08\n",
      "Epoch 225: Train 0.750, Test 0.840\n",
      "MSE NON-NORMALIZED: Train MSE 29.959, Test MSE 31.256\n",
      "TRAINING MODEL dt_norm_2_21\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.738, Test 0.696\n",
      "MSE NON-NORMALIZED: Train MSE 21.292, Test MSE 21.383\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.671, Test 0.588\n",
      "MSE NON-NORMALIZED: Train MSE 16.497, Test MSE 17.096\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 0.603, Test 0.538\n",
      "MSE NON-NORMALIZED: Train MSE 15.401, Test MSE 15.759\n",
      "Epoch 75, lr 0.0002125\n",
      "Epoch 75: Train 0.593, Test 0.510\n",
      "MSE NON-NORMALIZED: Train MSE 15.026, Test MSE 14.953\n",
      "Epoch 100, lr 0.0002125\n",
      "Epoch 100: Train 0.593, Test 0.507\n",
      "MSE NON-NORMALIZED: Train MSE 15.004, Test MSE 14.838\n",
      "Epoch 125, lr 5.3125e-05\n",
      "Epoch 125: Train 0.585, Test 0.496\n",
      "MSE NON-NORMALIZED: Train MSE 14.931, Test MSE 14.936\n",
      "Epoch 150, lr 6.640625e-06\n",
      "Epoch 150: Train 0.584, Test 0.493\n",
      "MSE NON-NORMALIZED: Train MSE 14.957, Test MSE 15.270\n",
      "Epoch 175, lr 1.66015625e-06\n",
      "Epoch 175: Train 0.583, Test 0.492\n",
      "MSE NON-NORMALIZED: Train MSE 15.002, Test MSE 15.660\n",
      "Epoch 200, lr 4.150390625e-07\n",
      "Epoch 200: Train 0.583, Test 0.492\n",
      "MSE NON-NORMALIZED: Train MSE 15.054, Test MSE 16.062\n",
      "Epoch 225, lr 1.03759765625e-07\n",
      "Epoch 225: Train 0.583, Test 0.492\n",
      "MSE NON-NORMALIZED: Train MSE 15.054, Test MSE 16.062\n",
      "TRAINING MODEL dt_norm_2_23\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.506, Test 0.692\n",
      "MSE NON-NORMALIZED: Train MSE 21.837, Test MSE 19.584\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.373, Test 0.594\n",
      "MSE NON-NORMALIZED: Train MSE 18.866, Test MSE 17.408\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 0.313, Test 0.506\n",
      "MSE NON-NORMALIZED: Train MSE 15.864, Test MSE 14.826\n",
      "Epoch 75, lr 0.00085\n",
      "Epoch 75: Train 0.294, Test 0.477\n",
      "MSE NON-NORMALIZED: Train MSE 13.690, Test MSE 12.803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 0.286, Test 0.466\n",
      "MSE NON-NORMALIZED: Train MSE 13.087, Test MSE 12.412\n",
      "Epoch 125, lr 5.3125e-05\n",
      "Epoch 125: Train 0.281, Test 0.461\n",
      "MSE NON-NORMALIZED: Train MSE 12.852, Test MSE 12.616\n",
      "Epoch 150, lr 1.328125e-05\n",
      "Epoch 150: Train 0.280, Test 0.460\n",
      "MSE NON-NORMALIZED: Train MSE 12.821, Test MSE 12.931\n",
      "Epoch 175, lr 3.3203125e-06\n",
      "Epoch 175: Train 0.280, Test 0.460\n",
      "MSE NON-NORMALIZED: Train MSE 12.858, Test MSE 13.269\n",
      "Epoch 200, lr 8.30078125e-07\n",
      "Epoch 200: Train 0.280, Test 0.460\n",
      "MSE NON-NORMALIZED: Train MSE 12.901, Test MSE 13.606\n",
      "Epoch 225, lr 1.03759765625e-07\n",
      "Epoch 225: Train 0.280, Test 0.460\n",
      "MSE NON-NORMALIZED: Train MSE 12.900, Test MSE 13.605\n",
      "TRAINING MODEL dt_norm_2_25\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 21845\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.412, Test 0.511\n",
      "MSE NON-NORMALIZED: Train MSE 12.229, Test MSE 10.660\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.276, Test 0.375\n",
      "MSE NON-NORMALIZED: Train MSE 8.905, Test MSE 7.726\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 0.242, Test 0.346\n",
      "MSE NON-NORMALIZED: Train MSE 8.384, Test MSE 7.237\n",
      "Epoch 75, lr 0.00085\n",
      "Epoch 75: Train 0.233, Test 0.334\n",
      "MSE NON-NORMALIZED: Train MSE 8.146, Test MSE 6.974\n",
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 0.184, Test 0.303\n",
      "MSE NON-NORMALIZED: Train MSE 7.460, Test MSE 6.323\n",
      "Epoch 125, lr 0.0002125\n",
      "Epoch 125: Train 0.179, Test 0.296\n",
      "MSE NON-NORMALIZED: Train MSE 7.204, Test MSE 6.423\n",
      "Epoch 150, lr 0.00010625\n",
      "Epoch 150: Train 0.178, Test 0.294\n",
      "MSE NON-NORMALIZED: Train MSE 7.161, Test MSE 6.604\n",
      "Epoch 175, lr 2.65625e-05\n",
      "Epoch 175: Train 0.176, Test 0.293\n",
      "MSE NON-NORMALIZED: Train MSE 7.150, Test MSE 6.804\n",
      "Epoch 200, lr 6.640625e-06\n",
      "Epoch 200: Train 0.176, Test 0.292\n",
      "MSE NON-NORMALIZED: Train MSE 7.172, Test MSE 7.017\n",
      "Epoch 225, lr 1.66015625e-06\n",
      "Epoch 225: Train 0.175, Test 0.292\n",
      "MSE NON-NORMALIZED: Train MSE 7.168, Test MSE 7.013\n",
      "TRAINING MODEL dt_norm_2_27\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 19047\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.237, Test 0.232\n",
      "MSE NON-NORMALIZED: Train MSE 5.868, Test MSE 5.066\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.188, Test 0.192\n",
      "MSE NON-NORMALIZED: Train MSE 4.299, Test MSE 4.119\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 0.148, Test 0.142\n",
      "MSE NON-NORMALIZED: Train MSE 3.385, Test MSE 2.950\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 0.140, Test 0.134\n",
      "MSE NON-NORMALIZED: Train MSE 3.162, Test MSE 2.744\n",
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 0.137, Test 0.129\n",
      "MSE NON-NORMALIZED: Train MSE 3.076, Test MSE 2.662\n",
      "Epoch 125, lr 0.00010625\n",
      "Epoch 125: Train 0.134, Test 0.126\n",
      "MSE NON-NORMALIZED: Train MSE 2.998, Test MSE 2.717\n",
      "Epoch 150, lr 2.65625e-05\n",
      "Epoch 150: Train 0.133, Test 0.125\n",
      "MSE NON-NORMALIZED: Train MSE 3.007, Test MSE 2.840\n",
      "Epoch 175, lr 6.640625e-06\n",
      "Epoch 175: Train 0.133, Test 0.125\n",
      "MSE NON-NORMALIZED: Train MSE 3.024, Test MSE 2.961\n",
      "Epoch 200, lr 8.30078125e-07\n",
      "Epoch 200: Train 0.133, Test 0.125\n",
      "MSE NON-NORMALIZED: Train MSE 3.044, Test MSE 3.084\n",
      "Epoch 225, lr 2.0751953125e-07\n",
      "Epoch 225: Train 0.133, Test 0.125\n",
      "MSE NON-NORMALIZED: Train MSE 3.044, Test MSE 3.082\n",
      "TRAINING MODEL dt_norm_2_29\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.294, Test 0.315\n",
      "MSE NON-NORMALIZED: Train MSE 7.397, Test MSE 5.573\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.331, Test 0.336\n",
      "MSE NON-NORMALIZED: Train MSE 6.130, Test MSE 5.487\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.330, Test 0.337\n",
      "MSE NON-NORMALIZED: Train MSE 6.051, Test MSE 5.455\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.334, Test 0.341\n",
      "MSE NON-NORMALIZED: Train MSE 6.032, Test MSE 5.522\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.334, Test 0.341\n",
      "MSE NON-NORMALIZED: Train MSE 6.019, Test MSE 5.526\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.334, Test 0.341\n",
      "MSE NON-NORMALIZED: Train MSE 6.043, Test MSE 5.687\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.334, Test 0.341\n",
      "MSE NON-NORMALIZED: Train MSE 6.064, Test MSE 5.843\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.334, Test 0.341\n",
      "MSE NON-NORMALIZED: Train MSE 6.084, Test MSE 5.998\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.334, Test 0.341\n",
      "MSE NON-NORMALIZED: Train MSE 6.105, Test MSE 6.153\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.334, Test 0.341\n",
      "MSE NON-NORMALIZED: Train MSE 6.104, Test MSE 6.151\n",
      "TRAINING MODEL dt_norm_2_30\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 24996\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.223, Test 0.247\n",
      "MSE NON-NORMALIZED: Train MSE 5.292, Test MSE 5.689\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.232, Test 0.236\n",
      "MSE NON-NORMALIZED: Train MSE 4.685, Test MSE 4.450\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.237, Test 0.241\n",
      "MSE NON-NORMALIZED: Train MSE 4.735, Test MSE 4.508\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.241, Test 0.244\n",
      "MSE NON-NORMALIZED: Train MSE 4.766, Test MSE 4.544\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.230, Test 0.235\n",
      "MSE NON-NORMALIZED: Train MSE 4.452, Test MSE 4.234\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.230, Test 0.236\n",
      "MSE NON-NORMALIZED: Train MSE 4.476, Test MSE 4.399\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.230, Test 0.235\n",
      "MSE NON-NORMALIZED: Train MSE 4.491, Test MSE 4.549\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.230, Test 0.235\n",
      "MSE NON-NORMALIZED: Train MSE 4.513, Test MSE 4.707\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.230, Test 0.235\n",
      "MSE NON-NORMALIZED: Train MSE 4.536, Test MSE 4.864\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.230, Test 0.235\n",
      "MSE NON-NORMALIZED: Train MSE 4.535, Test MSE 4.861\n",
      "TRAINING MODEL dt_norm_2_31\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 9924\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.161, Test 0.182\n",
      "MSE NON-NORMALIZED: Train MSE 3.637, Test MSE 3.144\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.185, Test 0.202\n",
      "MSE NON-NORMALIZED: Train MSE 3.512, Test MSE 3.250\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.192, Test 0.206\n",
      "MSE NON-NORMALIZED: Train MSE 3.550, Test MSE 3.300\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.194, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.560, Test MSE 3.315\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.194, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.562, Test MSE 3.320\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.194, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.575, Test MSE 3.397\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.194, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.594, Test MSE 3.479\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.194, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.613, Test MSE 3.560\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.194, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.631, Test MSE 3.641\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.194, Test 0.207\n",
      "MSE NON-NORMALIZED: Train MSE 3.631, Test MSE 3.641\n",
      "TRAINING MODEL dt_norm_2_32\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 8327\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.220, Test 0.256\n",
      "MSE NON-NORMALIZED: Train MSE 3.966, Test MSE 4.203\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 0.234, Test 0.211\n",
      "MSE NON-NORMALIZED: Train MSE 3.314, Test MSE 3.134\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 0.225, Test 0.196\n",
      "MSE NON-NORMALIZED: Train MSE 3.077, Test MSE 2.904\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 0.223, Test 0.191\n",
      "MSE NON-NORMALIZED: Train MSE 3.015, Test MSE 2.837\n",
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 0.221, Test 0.190\n",
      "MSE NON-NORMALIZED: Train MSE 2.989, Test MSE 2.812\n",
      "Epoch 125, lr 0.000425\n",
      "Epoch 125: Train 0.220, Test 0.189\n",
      "MSE NON-NORMALIZED: Train MSE 2.985, Test MSE 2.840\n",
      "Epoch 150, lr 0.00010625\n",
      "Epoch 150: Train 0.220, Test 0.185\n",
      "MSE NON-NORMALIZED: Train MSE 2.954, Test MSE 2.827\n",
      "Epoch 175, lr 2.65625e-05\n",
      "Epoch 175: Train 0.220, Test 0.184\n",
      "MSE NON-NORMALIZED: Train MSE 2.957, Test MSE 2.854\n",
      "Epoch 200, lr 6.640625e-06\n",
      "Epoch 200: Train 0.220, Test 0.184\n",
      "MSE NON-NORMALIZED: Train MSE 2.966, Test MSE 2.890\n",
      "Epoch 225, lr 8.30078125e-07\n",
      "Epoch 225: Train 0.220, Test 0.184\n",
      "MSE NON-NORMALIZED: Train MSE 2.965, Test MSE 2.889\n",
      "TRAINING MODEL dt_norm_2_34\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.290, Test 0.272\n",
      "MSE NON-NORMALIZED: Train MSE 5.292, Test MSE 4.944\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.408, Test 0.353\n",
      "MSE NON-NORMALIZED: Train MSE 6.031, Test MSE 5.817\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.398, Test 0.342\n",
      "MSE NON-NORMALIZED: Train MSE 5.806, Test MSE 5.607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.394, Test 0.338\n",
      "MSE NON-NORMALIZED: Train MSE 5.729, Test MSE 5.527\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.393, Test 0.338\n",
      "MSE NON-NORMALIZED: Train MSE 5.721, Test MSE 5.519\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.393, Test 0.338\n",
      "MSE NON-NORMALIZED: Train MSE 5.742, Test MSE 5.693\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.393, Test 0.338\n",
      "MSE NON-NORMALIZED: Train MSE 5.765, Test MSE 5.867\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.393, Test 0.338\n",
      "MSE NON-NORMALIZED: Train MSE 5.787, Test MSE 6.041\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.393, Test 0.338\n",
      "MSE NON-NORMALIZED: Train MSE 5.810, Test MSE 6.214\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.393, Test 0.338\n",
      "MSE NON-NORMALIZED: Train MSE 5.810, Test MSE 6.213\n",
      "TRAINING MODEL dt_norm_2_35\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.312, Test 0.301\n",
      "MSE NON-NORMALIZED: Train MSE 3.861, Test MSE 4.785\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.411, Test 0.392\n",
      "MSE NON-NORMALIZED: Train MSE 6.559, Test MSE 6.120\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.412, Test 0.392\n",
      "MSE NON-NORMALIZED: Train MSE 6.531, Test MSE 6.122\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.412, Test 0.393\n",
      "MSE NON-NORMALIZED: Train MSE 6.524, Test MSE 6.132\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.413, Test 0.393\n",
      "MSE NON-NORMALIZED: Train MSE 6.521, Test MSE 6.137\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.413, Test 0.393\n",
      "MSE NON-NORMALIZED: Train MSE 6.543, Test MSE 6.299\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.413, Test 0.393\n",
      "MSE NON-NORMALIZED: Train MSE 6.564, Test MSE 6.460\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.413, Test 0.393\n",
      "MSE NON-NORMALIZED: Train MSE 6.585, Test MSE 6.619\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.413, Test 0.393\n",
      "MSE NON-NORMALIZED: Train MSE 6.607, Test MSE 6.779\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.412, Test 0.393\n",
      "MSE NON-NORMALIZED: Train MSE 6.607, Test MSE 6.778\n",
      "TRAINING MODEL dt_norm_2_36\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.228, Test 0.214\n",
      "MSE NON-NORMALIZED: Train MSE 3.682, Test MSE 3.501\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.363, Test 0.338\n",
      "MSE NON-NORMALIZED: Train MSE 5.618, Test MSE 5.426\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.360, Test 0.337\n",
      "MSE NON-NORMALIZED: Train MSE 5.553, Test MSE 5.398\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.357, Test 0.336\n",
      "MSE NON-NORMALIZED: Train MSE 5.509, Test MSE 5.369\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.357, Test 0.336\n",
      "MSE NON-NORMALIZED: Train MSE 5.501, Test MSE 5.375\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.357, Test 0.336\n",
      "MSE NON-NORMALIZED: Train MSE 5.523, Test MSE 5.536\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.357, Test 0.336\n",
      "MSE NON-NORMALIZED: Train MSE 5.543, Test MSE 5.694\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.357, Test 0.336\n",
      "MSE NON-NORMALIZED: Train MSE 5.564, Test MSE 5.851\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.357, Test 0.336\n",
      "MSE NON-NORMALIZED: Train MSE 5.584, Test MSE 6.007\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.357, Test 0.336\n",
      "MSE NON-NORMALIZED: Train MSE 5.584, Test MSE 6.006\n",
      "TRAINING MODEL dt_norm_2_37\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.283, Test 0.264\n",
      "MSE NON-NORMALIZED: Train MSE 4.348, Test MSE 4.757\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.349, Test 0.326\n",
      "MSE NON-NORMALIZED: Train MSE 5.747, Test MSE 5.546\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.342, Test 0.320\n",
      "MSE NON-NORMALIZED: Train MSE 5.611, Test MSE 5.421\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.341, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 5.579, Test MSE 5.395\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.340, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 5.570, Test MSE 5.395\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.340, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 5.592, Test MSE 5.566\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.340, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 5.614, Test MSE 5.735\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.340, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 5.637, Test MSE 5.903\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.340, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 5.659, Test MSE 6.071\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.340, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 5.659, Test MSE 6.070\n",
      "TRAINING MODEL dt_norm_2_38\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 13487\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.140, Test 0.132\n",
      "MSE NON-NORMALIZED: Train MSE 1.752, Test MSE 2.055\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.245, Test 0.218\n",
      "MSE NON-NORMALIZED: Train MSE 3.425, Test MSE 3.288\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.243, Test 0.217\n",
      "MSE NON-NORMALIZED: Train MSE 3.401, Test MSE 3.272\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.242, Test 0.216\n",
      "MSE NON-NORMALIZED: Train MSE 3.391, Test MSE 3.260\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.242, Test 0.216\n",
      "MSE NON-NORMALIZED: Train MSE 3.378, Test MSE 3.252\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.241, Test 0.215\n",
      "MSE NON-NORMALIZED: Train MSE 3.386, Test MSE 3.313\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.241, Test 0.215\n",
      "MSE NON-NORMALIZED: Train MSE 3.399, Test MSE 3.377\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.241, Test 0.215\n",
      "MSE NON-NORMALIZED: Train MSE 3.412, Test MSE 3.442\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.241, Test 0.215\n",
      "MSE NON-NORMALIZED: Train MSE 3.425, Test MSE 3.506\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.241, Test 0.215\n",
      "MSE NON-NORMALIZED: Train MSE 3.425, Test MSE 3.505\n",
      "TRAINING MODEL dt_norm_2_39\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 8335\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.084, Test 0.082\n",
      "MSE NON-NORMALIZED: Train MSE 1.147, Test MSE 1.224\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.127, Test 0.116\n",
      "MSE NON-NORMALIZED: Train MSE 1.948, Test MSE 1.699\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.131, Test 0.119\n",
      "MSE NON-NORMALIZED: Train MSE 2.003, Test MSE 1.745\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.131, Test 0.120\n",
      "MSE NON-NORMALIZED: Train MSE 2.013, Test MSE 1.755\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.131, Test 0.120\n",
      "MSE NON-NORMALIZED: Train MSE 2.015, Test MSE 1.756\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.131, Test 0.120\n",
      "MSE NON-NORMALIZED: Train MSE 2.023, Test MSE 1.804\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.131, Test 0.120\n",
      "MSE NON-NORMALIZED: Train MSE 2.036, Test MSE 1.856\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.131, Test 0.120\n",
      "MSE NON-NORMALIZED: Train MSE 2.049, Test MSE 1.908\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.131, Test 0.120\n",
      "MSE NON-NORMALIZED: Train MSE 2.062, Test MSE 1.960\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.131, Test 0.120\n",
      "MSE NON-NORMALIZED: Train MSE 2.061, Test MSE 1.959\n",
      "TRAINING MODEL dt_norm_2_40\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 11106\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.191, Test 0.159\n",
      "MSE NON-NORMALIZED: Train MSE 1.507, Test MSE 2.323\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.267, Test 0.205\n",
      "MSE NON-NORMALIZED: Train MSE 3.017, Test MSE 2.986\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.265, Test 0.204\n",
      "MSE NON-NORMALIZED: Train MSE 3.002, Test MSE 2.973\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.265, Test 0.204\n",
      "MSE NON-NORMALIZED: Train MSE 2.999, Test MSE 2.964\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.264, Test 0.204\n",
      "MSE NON-NORMALIZED: Train MSE 2.997, Test MSE 2.961\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.264, Test 0.203\n",
      "MSE NON-NORMALIZED: Train MSE 3.003, Test MSE 3.000\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.264, Test 0.203\n",
      "MSE NON-NORMALIZED: Train MSE 3.013, Test MSE 3.043\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.264, Test 0.203\n",
      "MSE NON-NORMALIZED: Train MSE 3.022, Test MSE 3.086\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.264, Test 0.203\n",
      "MSE NON-NORMALIZED: Train MSE 3.031, Test MSE 3.128\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.264, Test 0.203\n",
      "MSE NON-NORMALIZED: Train MSE 3.032, Test MSE 3.128\n",
      "TRAINING MODEL dt_norm_2_41\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 12696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.131, Test 0.120\n",
      "MSE NON-NORMALIZED: Train MSE 1.245, Test MSE 1.762\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.143, Test 0.148\n",
      "MSE NON-NORMALIZED: Train MSE 2.218, Test MSE 2.143\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.141, Test 0.147\n",
      "MSE NON-NORMALIZED: Train MSE 2.201, Test MSE 2.128\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.141, Test 0.147\n",
      "MSE NON-NORMALIZED: Train MSE 2.190, Test MSE 2.132\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.141, Test 0.147\n",
      "MSE NON-NORMALIZED: Train MSE 2.185, Test MSE 2.134\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.141, Test 0.147\n",
      "MSE NON-NORMALIZED: Train MSE 2.191, Test MSE 2.169\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.141, Test 0.147\n",
      "MSE NON-NORMALIZED: Train MSE 2.199, Test MSE 2.204\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.141, Test 0.147\n",
      "MSE NON-NORMALIZED: Train MSE 2.206, Test MSE 2.239\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.141, Test 0.147\n",
      "MSE NON-NORMALIZED: Train MSE 2.214, Test MSE 2.274\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.141, Test 0.147\n",
      "MSE NON-NORMALIZED: Train MSE 2.214, Test MSE 2.273\n",
      "TRAINING MODEL dt_norm_2_42\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 5153\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.090, Test 0.076\n",
      "MSE NON-NORMALIZED: Train MSE 0.764, Test MSE 1.088\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.198, Test 0.157\n",
      "MSE NON-NORMALIZED: Train MSE 2.264, Test MSE 2.219\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.154, Test 0.136\n",
      "MSE NON-NORMALIZED: Train MSE 1.945, Test MSE 1.913\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.151, Test 0.135\n",
      "MSE NON-NORMALIZED: Train MSE 1.924, Test MSE 1.894\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.150, Test 0.135\n",
      "MSE NON-NORMALIZED: Train MSE 1.920, Test MSE 1.892\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.150, Test 0.134\n",
      "MSE NON-NORMALIZED: Train MSE 1.926, Test MSE 1.919\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.150, Test 0.134\n",
      "MSE NON-NORMALIZED: Train MSE 1.936, Test MSE 1.950\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.150, Test 0.134\n",
      "MSE NON-NORMALIZED: Train MSE 1.945, Test MSE 1.980\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.150, Test 0.134\n",
      "MSE NON-NORMALIZED: Train MSE 1.955, Test MSE 2.011\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.150, Test 0.134\n",
      "MSE NON-NORMALIZED: Train MSE 1.955, Test MSE 2.011\n",
      "TRAINING MODEL dt_norm_2_43\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 3968\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.033, Test 0.041\n",
      "MSE NON-NORMALIZED: Train MSE 0.436, Test MSE 0.564\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.046, Test 0.070\n",
      "MSE NON-NORMALIZED: Train MSE 0.977, Test MSE 0.942\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.046, Test 0.069\n",
      "MSE NON-NORMALIZED: Train MSE 0.976, Test MSE 0.939\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.046, Test 0.069\n",
      "MSE NON-NORMALIZED: Train MSE 0.976, Test MSE 0.938\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.046, Test 0.069\n",
      "MSE NON-NORMALIZED: Train MSE 0.976, Test MSE 0.938\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.045, Test 0.069\n",
      "MSE NON-NORMALIZED: Train MSE 0.979, Test MSE 0.952\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.045, Test 0.069\n",
      "MSE NON-NORMALIZED: Train MSE 0.985, Test MSE 0.969\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.045, Test 0.069\n",
      "MSE NON-NORMALIZED: Train MSE 0.991, Test MSE 0.986\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.045, Test 0.069\n",
      "MSE NON-NORMALIZED: Train MSE 0.998, Test MSE 1.004\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.045, Test 0.069\n",
      "MSE NON-NORMALIZED: Train MSE 0.998, Test MSE 1.003\n",
      "TRAINING MODEL dt_norm_2_44\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 2380\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.011, Test 0.014\n",
      "MSE NON-NORMALIZED: Train MSE 0.170, Test MSE 0.190\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.072, Test 0.092\n",
      "MSE NON-NORMALIZED: Train MSE 1.266, Test MSE 1.250\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.072, Test 0.092\n",
      "MSE NON-NORMALIZED: Train MSE 1.267, Test MSE 1.252\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.073, Test 0.092\n",
      "MSE NON-NORMALIZED: Train MSE 1.267, Test MSE 1.253\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.073, Test 0.092\n",
      "MSE NON-NORMALIZED: Train MSE 1.268, Test MSE 1.253\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.072, Test 0.092\n",
      "MSE NON-NORMALIZED: Train MSE 1.271, Test MSE 1.261\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.072, Test 0.092\n",
      "MSE NON-NORMALIZED: Train MSE 1.274, Test MSE 1.269\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.072, Test 0.092\n",
      "MSE NON-NORMALIZED: Train MSE 1.278, Test MSE 1.277\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.072, Test 0.092\n",
      "MSE NON-NORMALIZED: Train MSE 1.282, Test MSE 1.285\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.072, Test 0.092\n",
      "MSE NON-NORMALIZED: Train MSE 1.282, Test MSE 1.285\n",
      "TRAINING MODEL dt_norm_2_45\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 3969\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.047, Test 0.040\n",
      "MSE NON-NORMALIZED: Train MSE 0.506, Test MSE 0.562\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.112, Test 0.122\n",
      "MSE NON-NORMALIZED: Train MSE 1.763, Test MSE 1.681\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.113, Test 0.124\n",
      "MSE NON-NORMALIZED: Train MSE 1.783, Test MSE 1.705\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.112, Test 0.124\n",
      "MSE NON-NORMALIZED: Train MSE 1.788, Test MSE 1.708\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.112, Test 0.124\n",
      "MSE NON-NORMALIZED: Train MSE 1.789, Test MSE 1.708\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.112, Test 0.124\n",
      "MSE NON-NORMALIZED: Train MSE 1.793, Test MSE 1.723\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.112, Test 0.124\n",
      "MSE NON-NORMALIZED: Train MSE 1.799, Test MSE 1.740\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.112, Test 0.124\n",
      "MSE NON-NORMALIZED: Train MSE 1.805, Test MSE 1.756\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.112, Test 0.124\n",
      "MSE NON-NORMALIZED: Train MSE 1.811, Test MSE 1.773\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.112, Test 0.124\n",
      "MSE NON-NORMALIZED: Train MSE 1.811, Test MSE 1.773\n",
      "TRAINING MODEL dt_norm_3_1\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 21828\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 2.516, Test 2.784\n",
      "MSE NON-NORMALIZED: Train MSE 127.460, Test MSE 110.226\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 2.103, Test 2.376\n",
      "MSE NON-NORMALIZED: Train MSE 98.008, Test MSE 96.162\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 2.057, Test 2.345\n",
      "MSE NON-NORMALIZED: Train MSE 96.047, Test MSE 94.684\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 1.947, Test 2.248\n",
      "MSE NON-NORMALIZED: Train MSE 93.010, Test MSE 91.259\n",
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 1.873, Test 2.207\n",
      "MSE NON-NORMALIZED: Train MSE 93.364, Test MSE 90.866\n",
      "Epoch 125, lr 0.000425\n",
      "Epoch 125: Train 1.826, Test 2.168\n",
      "MSE NON-NORMALIZED: Train MSE 90.007, Test MSE 88.958\n",
      "Epoch 150, lr 0.0002125\n",
      "Epoch 150: Train 1.824, Test 2.163\n",
      "MSE NON-NORMALIZED: Train MSE 88.959, Test MSE 89.426\n",
      "Epoch 175, lr 5.3125e-05\n",
      "Epoch 175: Train 1.800, Test 2.151\n",
      "MSE NON-NORMALIZED: Train MSE 87.925, Test MSE 88.890\n",
      "Epoch 200, lr 1.328125e-05\n",
      "Epoch 200: Train 1.799, Test 2.150\n",
      "MSE NON-NORMALIZED: Train MSE 87.756, Test MSE 89.440\n",
      "Epoch 225, lr 3.3203125e-06\n",
      "Epoch 225: Train 1.798, Test 2.149\n",
      "MSE NON-NORMALIZED: Train MSE 87.724, Test MSE 89.413\n",
      "TRAINING MODEL dt_norm_3_3\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 3.789, Test 3.820\n",
      "MSE NON-NORMALIZED: Train MSE 170.717, Test MSE 155.833\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 2.748, Test 2.944\n",
      "MSE NON-NORMALIZED: Train MSE 128.211, Test MSE 115.836\n",
      "Epoch 50, lr 0.0002125\n",
      "Epoch 50: Train 2.574, Test 2.790\n",
      "MSE NON-NORMALIZED: Train MSE 111.596, Test MSE 109.014\n",
      "Epoch 75, lr 0.0002125\n",
      "Epoch 75: Train 2.466, Test 2.772\n",
      "MSE NON-NORMALIZED: Train MSE 109.877, Test MSE 106.920\n",
      "Epoch 100, lr 0.00010625\n",
      "Epoch 100: Train 2.376, Test 2.711\n",
      "MSE NON-NORMALIZED: Train MSE 106.716, Test MSE 104.380\n",
      "Epoch 125, lr 5.3125e-05\n",
      "Epoch 125: Train 2.361, Test 2.701\n",
      "MSE NON-NORMALIZED: Train MSE 106.277, Test MSE 104.927\n",
      "Epoch 150, lr 5.3125e-05\n",
      "Epoch 150: Train 2.327, Test 2.691\n",
      "MSE NON-NORMALIZED: Train MSE 105.490, Test MSE 104.913\n",
      "Epoch 175, lr 6.640625e-06\n",
      "Epoch 175: Train 2.322, Test 2.687\n",
      "MSE NON-NORMALIZED: Train MSE 105.394, Test MSE 105.700\n",
      "Epoch 200, lr 1.66015625e-06\n",
      "Epoch 200: Train 2.321, Test 2.686\n",
      "MSE NON-NORMALIZED: Train MSE 105.499, Test MSE 106.657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225, lr 4.150390625e-07\n",
      "Epoch 225: Train 2.321, Test 2.686\n",
      "MSE NON-NORMALIZED: Train MSE 105.493, Test MSE 106.654\n",
      "TRAINING MODEL dt_norm_3_5\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 3.124, Test 5.416\n",
      "MSE NON-NORMALIZED: Train MSE 327.885, Test MSE 333.097\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 4.127, Test 7.425\n",
      "MSE NON-NORMALIZED: Train MSE 554.411, Test MSE 432.308\n",
      "Epoch 50, lr 0.0002125\n",
      "Epoch 50: Train 3.162, Test 5.502\n",
      "MSE NON-NORMALIZED: Train MSE 520.251, Test MSE 307.260\n",
      "Epoch 75, lr 0.0002125\n",
      "Epoch 75: Train 3.016, Test 4.668\n",
      "MSE NON-NORMALIZED: Train MSE 249.781, Test MSE 250.766\n",
      "Epoch 100, lr 0.00010625\n",
      "Epoch 100: Train 2.025, Test 3.833\n",
      "MSE NON-NORMALIZED: Train MSE 223.761, Test MSE 202.925\n",
      "Epoch 125, lr 5.3125e-05\n",
      "Epoch 125: Train 1.842, Test 3.297\n",
      "MSE NON-NORMALIZED: Train MSE 180.252, Test MSE 177.897\n",
      "Epoch 150, lr 2.65625e-05\n",
      "Epoch 150: Train 1.803, Test 3.218\n",
      "MSE NON-NORMALIZED: Train MSE 174.107, Test MSE 173.130\n",
      "Epoch 175, lr 1.328125e-05\n",
      "Epoch 175: Train 1.788, Test 3.197\n",
      "MSE NON-NORMALIZED: Train MSE 172.113, Test MSE 172.206\n",
      "Epoch 200, lr 3.3203125e-06\n",
      "Epoch 200: Train 1.783, Test 3.191\n",
      "MSE NON-NORMALIZED: Train MSE 171.390, Test MSE 173.093\n",
      "Epoch 225, lr 1.66015625e-06\n",
      "Epoch 225: Train 1.782, Test 3.189\n",
      "MSE NON-NORMALIZED: Train MSE 171.224, Test MSE 173.036\n",
      "TRAINING MODEL dt_norm_3_7\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 3.415, Test 4.190\n",
      "MSE NON-NORMALIZED: Train MSE 338.418, Test MSE 332.484\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 7.850, Test 9.099\n",
      "MSE NON-NORMALIZED: Train MSE 1260.334, Test MSE 624.520\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 5.875, Test 7.641\n",
      "MSE NON-NORMALIZED: Train MSE 1108.176, Test MSE 524.574\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 3.936, Test 4.813\n",
      "MSE NON-NORMALIZED: Train MSE 722.901, Test MSE 311.558\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 3.923, Test 4.801\n",
      "MSE NON-NORMALIZED: Train MSE 722.463, Test MSE 311.266\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 3.920, Test 4.794\n",
      "MSE NON-NORMALIZED: Train MSE 722.224, Test MSE 312.085\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 3.920, Test 4.794\n",
      "MSE NON-NORMALIZED: Train MSE 722.350, Test MSE 313.250\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 3.920, Test 4.794\n",
      "MSE NON-NORMALIZED: Train MSE 722.501, Test MSE 314.427\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 3.920, Test 4.794\n",
      "MSE NON-NORMALIZED: Train MSE 722.657, Test MSE 315.606\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 3.919, Test 4.794\n",
      "MSE NON-NORMALIZED: Train MSE 722.655, Test MSE 315.604\n",
      "TRAINING MODEL dt_norm_3_9\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 2.061, Test 3.238\n",
      "MSE NON-NORMALIZED: Train MSE 331.748, Test MSE 274.309\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 2.796, Test 3.867\n",
      "MSE NON-NORMALIZED: Train MSE 411.458, Test MSE 273.568\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 2.531, Test 3.542\n",
      "MSE NON-NORMALIZED: Train MSE 361.227, Test MSE 244.334\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 2.473, Test 3.460\n",
      "MSE NON-NORMALIZED: Train MSE 324.072, Test MSE 234.461\n",
      "Epoch 100, lr 3.3203125e-06\n",
      "Epoch 100: Train 2.460, Test 3.446\n",
      "MSE NON-NORMALIZED: Train MSE 323.396, Test MSE 233.855\n",
      "Epoch 125, lr 8.30078125e-07\n",
      "Epoch 125: Train 1.803, Test 3.261\n",
      "MSE NON-NORMALIZED: Train MSE 286.174, Test MSE 196.711\n",
      "Epoch 150, lr 4.150390625e-07\n",
      "Epoch 150: Train 1.800, Test 3.258\n",
      "MSE NON-NORMALIZED: Train MSE 286.189, Test MSE 197.593\n",
      "Epoch 175, lr 5.18798828125e-08\n",
      "Epoch 175: Train 1.799, Test 3.258\n",
      "MSE NON-NORMALIZED: Train MSE 286.302, Test MSE 198.556\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 1.799, Test 3.257\n",
      "MSE NON-NORMALIZED: Train MSE 286.428, Test MSE 199.528\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 1.799, Test 3.257\n",
      "MSE NON-NORMALIZED: Train MSE 286.427, Test MSE 199.527\n",
      "TRAINING MODEL dt_norm_3_11\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 3.415, Test 5.866\n",
      "MSE NON-NORMALIZED: Train MSE 235.622, Test MSE 1217.411\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 2.532, Test 3.423\n",
      "MSE NON-NORMALIZED: Train MSE 305.161, Test MSE 655.946\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 2.200, Test 3.324\n",
      "MSE NON-NORMALIZED: Train MSE 167.529, Test MSE 669.020\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 1.965, Test 1.479\n",
      "MSE NON-NORMALIZED: Train MSE 111.763, Test MSE 88.144\n",
      "Epoch 100, lr 0.0002125\n",
      "Epoch 100: Train 1.945, Test 1.383\n",
      "MSE NON-NORMALIZED: Train MSE 83.916, Test MSE 76.142\n",
      "Epoch 125, lr 0.00010625\n",
      "Epoch 125: Train 1.906, Test 1.360\n",
      "MSE NON-NORMALIZED: Train MSE 79.994, Test MSE 77.012\n",
      "Epoch 150, lr 0.00010625\n",
      "Epoch 150: Train 1.915, Test 1.452\n",
      "MSE NON-NORMALIZED: Train MSE 76.599, Test MSE 105.885\n",
      "Epoch 175, lr 2.65625e-05\n",
      "Epoch 175: Train 1.880, Test 1.317\n",
      "MSE NON-NORMALIZED: Train MSE 71.690, Test MSE 71.072\n",
      "Epoch 200, lr 6.640625e-06\n",
      "Epoch 200: Train 1.878, Test 1.314\n",
      "MSE NON-NORMALIZED: Train MSE 71.435, Test MSE 71.214\n",
      "Epoch 225, lr 8.30078125e-07\n",
      "Epoch 225: Train 1.878, Test 1.314\n",
      "MSE NON-NORMALIZED: Train MSE 71.400, Test MSE 71.195\n",
      "TRAINING MODEL dt_norm_3_13\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 1.860, Test 1.697\n",
      "MSE NON-NORMALIZED: Train MSE 126.691, Test MSE 96.783\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 1.406, Test 1.326\n",
      "MSE NON-NORMALIZED: Train MSE 82.740, Test MSE 79.300\n",
      "Epoch 50, lr 0.0002125\n",
      "Epoch 50: Train 1.364, Test 1.284\n",
      "MSE NON-NORMALIZED: Train MSE 79.712, Test MSE 78.064\n",
      "Epoch 75, lr 0.00010625\n",
      "Epoch 75: Train 1.352, Test 1.270\n",
      "MSE NON-NORMALIZED: Train MSE 77.782, Test MSE 77.357\n",
      "Epoch 100, lr 5.3125e-05\n",
      "Epoch 100: Train 1.312, Test 1.245\n",
      "MSE NON-NORMALIZED: Train MSE 75.379, Test MSE 74.136\n",
      "Epoch 125, lr 2.65625e-05\n",
      "Epoch 125: Train 1.253, Test 1.215\n",
      "MSE NON-NORMALIZED: Train MSE 68.677, Test MSE 67.973\n",
      "Epoch 150, lr 6.640625e-06\n",
      "Epoch 150: Train 1.252, Test 1.214\n",
      "MSE NON-NORMALIZED: Train MSE 68.690, Test MSE 68.555\n",
      "Epoch 175, lr 8.30078125e-07\n",
      "Epoch 175: Train 1.252, Test 1.214\n",
      "MSE NON-NORMALIZED: Train MSE 68.757, Test MSE 69.165\n",
      "Epoch 200, lr 2.0751953125e-07\n",
      "Epoch 200: Train 1.251, Test 1.214\n",
      "MSE NON-NORMALIZED: Train MSE 68.834, Test MSE 69.778\n",
      "Epoch 225, lr 5.18798828125e-08\n",
      "Epoch 225: Train 1.251, Test 1.214\n",
      "MSE NON-NORMALIZED: Train MSE 68.833, Test MSE 69.778\n",
      "TRAINING MODEL dt_norm_3_15\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 1.029, Test 1.107\n",
      "MSE NON-NORMALIZED: Train MSE 58.636, Test MSE 47.759\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.953, Test 0.980\n",
      "MSE NON-NORMALIZED: Train MSE 38.760, Test MSE 38.857\n",
      "Epoch 50, lr 0.0002125\n",
      "Epoch 50: Train 0.913, Test 0.868\n",
      "MSE NON-NORMALIZED: Train MSE 31.622, Test MSE 30.279\n",
      "Epoch 75, lr 5.3125e-05\n",
      "Epoch 75: Train 0.908, Test 0.853\n",
      "MSE NON-NORMALIZED: Train MSE 31.038, Test MSE 29.571\n",
      "Epoch 100, lr 5.3125e-05\n",
      "Epoch 100: Train 0.907, Test 0.852\n",
      "MSE NON-NORMALIZED: Train MSE 31.023, Test MSE 29.555\n",
      "Epoch 125, lr 1.328125e-05\n",
      "Epoch 125: Train 0.906, Test 0.851\n",
      "MSE NON-NORMALIZED: Train MSE 30.985, Test MSE 30.015\n",
      "Epoch 150, lr 3.3203125e-06\n",
      "Epoch 150: Train 0.905, Test 0.850\n",
      "MSE NON-NORMALIZED: Train MSE 31.033, Test MSE 30.507\n",
      "Epoch 175, lr 4.150390625e-07\n",
      "Epoch 175: Train 0.905, Test 0.850\n",
      "MSE NON-NORMALIZED: Train MSE 31.096, Test MSE 31.014\n",
      "Epoch 200, lr 1.03759765625e-07\n",
      "Epoch 200: Train 0.905, Test 0.850\n",
      "MSE NON-NORMALIZED: Train MSE 31.162, Test MSE 31.520\n",
      "Epoch 225, lr 2.593994140625e-08\n",
      "Epoch 225: Train 0.905, Test 0.850\n",
      "MSE NON-NORMALIZED: Train MSE 31.161, Test MSE 31.520\n",
      "TRAINING MODEL dt_norm_3_17\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 1.292, Test 1.051\n",
      "MSE NON-NORMALIZED: Train MSE 43.325, Test MSE 36.979\n",
      "Epoch 25, lr 0.000425\n",
      "Epoch 25: Train 0.984, Test 0.825\n",
      "MSE NON-NORMALIZED: Train MSE 29.492, Test MSE 29.388\n",
      "Epoch 50, lr 0.0002125\n",
      "Epoch 50: Train 0.935, Test 0.781\n",
      "MSE NON-NORMALIZED: Train MSE 28.074, Test MSE 27.508\n",
      "Epoch 75, lr 0.00010625\n",
      "Epoch 75: Train 0.902, Test 0.762\n",
      "MSE NON-NORMALIZED: Train MSE 27.522, Test MSE 26.824\n",
      "Epoch 100, lr 2.65625e-05\n",
      "Epoch 100: Train 0.897, Test 0.759\n",
      "MSE NON-NORMALIZED: Train MSE 27.361, Test MSE 26.697\n",
      "Epoch 125, lr 3.3203125e-06\n",
      "Epoch 125: Train 0.897, Test 0.758\n",
      "MSE NON-NORMALIZED: Train MSE 27.401, Test MSE 27.200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, lr 8.30078125e-07\n",
      "Epoch 150: Train 0.897, Test 0.758\n",
      "MSE NON-NORMALIZED: Train MSE 27.459, Test MSE 27.712\n",
      "Epoch 175, lr 2.0751953125e-07\n",
      "Epoch 175: Train 0.897, Test 0.758\n",
      "MSE NON-NORMALIZED: Train MSE 27.526, Test MSE 28.226\n",
      "Epoch 200, lr 5.18798828125e-08\n",
      "Epoch 200: Train 0.897, Test 0.758\n",
      "MSE NON-NORMALIZED: Train MSE 27.593, Test MSE 28.739\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.897, Test 0.758\n",
      "MSE NON-NORMALIZED: Train MSE 27.592, Test MSE 28.738\n",
      "TRAINING MODEL dt_norm_3_19\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.860, Test 0.886\n",
      "MSE NON-NORMALIZED: Train MSE 30.141, Test MSE 26.469\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.771, Test 0.767\n",
      "MSE NON-NORMALIZED: Train MSE 24.949, Test MSE 23.161\n",
      "Epoch 50, lr 0.000425\n",
      "Epoch 50: Train 0.721, Test 0.724\n",
      "MSE NON-NORMALIZED: Train MSE 23.244, Test MSE 21.753\n",
      "Epoch 75, lr 0.0002125\n",
      "Epoch 75: Train 0.706, Test 0.708\n",
      "MSE NON-NORMALIZED: Train MSE 22.702, Test MSE 21.257\n",
      "Epoch 100, lr 5.3125e-05\n",
      "Epoch 100: Train 0.702, Test 0.702\n",
      "MSE NON-NORMALIZED: Train MSE 22.456, Test MSE 21.086\n",
      "Epoch 125, lr 1.328125e-05\n",
      "Epoch 125: Train 0.700, Test 0.700\n",
      "MSE NON-NORMALIZED: Train MSE 22.462, Test MSE 21.514\n",
      "Epoch 150, lr 3.3203125e-06\n",
      "Epoch 150: Train 0.700, Test 0.700\n",
      "MSE NON-NORMALIZED: Train MSE 22.510, Test MSE 21.978\n",
      "Epoch 175, lr 4.150390625e-07\n",
      "Epoch 175: Train 0.700, Test 0.700\n",
      "MSE NON-NORMALIZED: Train MSE 22.566, Test MSE 22.443\n",
      "Epoch 200, lr 1.03759765625e-07\n",
      "Epoch 200: Train 0.700, Test 0.700\n",
      "MSE NON-NORMALIZED: Train MSE 22.627, Test MSE 22.908\n",
      "Epoch 225, lr 2.593994140625e-08\n",
      "Epoch 225: Train 0.700, Test 0.700\n",
      "MSE NON-NORMALIZED: Train MSE 22.627, Test MSE 22.907\n",
      "TRAINING MODEL dt_norm_3_21\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 1.426, Test 1.490\n",
      "MSE NON-NORMALIZED: Train MSE 49.067, Test MSE 55.629\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 1.423, Test 1.666\n",
      "MSE NON-NORMALIZED: Train MSE 52.512, Test MSE 63.131\n",
      "Epoch 50, lr 0.0002125\n",
      "Epoch 50: Train 1.005, Test 1.169\n",
      "MSE NON-NORMALIZED: Train MSE 44.658, Test MSE 46.742\n",
      "Epoch 75, lr 5.3125e-05\n",
      "Epoch 75: Train 0.909, Test 1.063\n",
      "MSE NON-NORMALIZED: Train MSE 44.224, Test MSE 43.733\n",
      "Epoch 100, lr 2.65625e-05\n",
      "Epoch 100: Train 0.908, Test 1.060\n",
      "MSE NON-NORMALIZED: Train MSE 44.188, Test MSE 43.654\n",
      "Epoch 125, lr 6.640625e-06\n",
      "Epoch 125: Train 0.906, Test 1.058\n",
      "MSE NON-NORMALIZED: Train MSE 44.216, Test MSE 44.118\n",
      "Epoch 150, lr 8.30078125e-07\n",
      "Epoch 150: Train 0.906, Test 1.058\n",
      "MSE NON-NORMALIZED: Train MSE 44.274, Test MSE 44.617\n",
      "Epoch 175, lr 2.0751953125e-07\n",
      "Epoch 175: Train 0.906, Test 1.058\n",
      "MSE NON-NORMALIZED: Train MSE 44.338, Test MSE 45.122\n",
      "Epoch 200, lr 5.18798828125e-08\n",
      "Epoch 200: Train 0.906, Test 1.058\n",
      "MSE NON-NORMALIZED: Train MSE 44.401, Test MSE 45.626\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.906, Test 1.058\n",
      "MSE NON-NORMALIZED: Train MSE 44.401, Test MSE 45.625\n",
      "TRAINING MODEL dt_norm_3_23\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.732, Test 0.853\n",
      "MSE NON-NORMALIZED: Train MSE 26.403, Test MSE 25.332\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.494, Test 0.643\n",
      "MSE NON-NORMALIZED: Train MSE 17.094, Test MSE 16.824\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 0.474, Test 0.619\n",
      "MSE NON-NORMALIZED: Train MSE 16.899, Test MSE 15.973\n",
      "Epoch 75, lr 0.000425\n",
      "Epoch 75: Train 0.424, Test 0.564\n",
      "MSE NON-NORMALIZED: Train MSE 15.014, Test MSE 14.574\n",
      "Epoch 100, lr 0.000425\n",
      "Epoch 100: Train 0.422, Test 0.560\n",
      "MSE NON-NORMALIZED: Train MSE 14.925, Test MSE 14.449\n",
      "Epoch 125, lr 0.00010625\n",
      "Epoch 125: Train 0.414, Test 0.551\n",
      "MSE NON-NORMALIZED: Train MSE 14.560, Test MSE 14.518\n",
      "Epoch 150, lr 2.65625e-05\n",
      "Epoch 150: Train 0.412, Test 0.549\n",
      "MSE NON-NORMALIZED: Train MSE 14.555, Test MSE 14.858\n",
      "Epoch 175, lr 3.3203125e-06\n",
      "Epoch 175: Train 0.412, Test 0.549\n",
      "MSE NON-NORMALIZED: Train MSE 14.587, Test MSE 15.222\n",
      "Epoch 200, lr 8.30078125e-07\n",
      "Epoch 200: Train 0.411, Test 0.549\n",
      "MSE NON-NORMALIZED: Train MSE 14.636, Test MSE 15.601\n",
      "Epoch 225, lr 2.0751953125e-07\n",
      "Epoch 225: Train 0.411, Test 0.549\n",
      "MSE NON-NORMALIZED: Train MSE 14.635, Test MSE 15.600\n",
      "TRAINING MODEL dt_norm_3_25\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.674, Test 0.762\n",
      "MSE NON-NORMALIZED: Train MSE 20.675, Test MSE 19.419\n",
      "Epoch 25, lr 0.00085\n",
      "Epoch 25: Train 0.565, Test 0.634\n",
      "MSE NON-NORMALIZED: Train MSE 16.717, Test MSE 15.660\n",
      "Epoch 50, lr 0.00085\n",
      "Epoch 50: Train 0.517, Test 0.542\n",
      "MSE NON-NORMALIZED: Train MSE 14.220, Test MSE 13.313\n",
      "Epoch 75, lr 0.00085\n",
      "Epoch 75: Train 0.490, Test 0.526\n",
      "MSE NON-NORMALIZED: Train MSE 13.893, Test MSE 12.859\n",
      "Epoch 100, lr 0.0002125\n",
      "Epoch 100: Train 0.478, Test 0.515\n",
      "MSE NON-NORMALIZED: Train MSE 13.087, Test MSE 12.493\n",
      "Epoch 125, lr 0.0002125\n",
      "Epoch 125: Train 0.475, Test 0.515\n",
      "MSE NON-NORMALIZED: Train MSE 13.123, Test MSE 12.846\n",
      "Epoch 150, lr 0.0002125\n",
      "Epoch 150: Train 0.476, Test 0.514\n",
      "MSE NON-NORMALIZED: Train MSE 13.166, Test MSE 13.181\n",
      "Epoch 175, lr 5.3125e-05\n",
      "Epoch 175: Train 0.471, Test 0.511\n",
      "MSE NON-NORMALIZED: Train MSE 13.068, Test MSE 13.434\n",
      "Epoch 200, lr 1.328125e-05\n",
      "Epoch 200: Train 0.470, Test 0.510\n",
      "MSE NON-NORMALIZED: Train MSE 13.083, Test MSE 13.749\n",
      "Epoch 225, lr 1.66015625e-06\n",
      "Epoch 225: Train 0.469, Test 0.510\n",
      "MSE NON-NORMALIZED: Train MSE 13.073, Test MSE 13.744\n",
      "TRAINING MODEL dt_norm_3_39\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 28168\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.217, Test 0.211\n",
      "MSE NON-NORMALIZED: Train MSE 3.202, Test MSE 3.488\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.240, Test 0.214\n",
      "MSE NON-NORMALIZED: Train MSE 3.499, Test MSE 3.348\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.238, Test 0.211\n",
      "MSE NON-NORMALIZED: Train MSE 3.463, Test MSE 3.299\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.237, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 3.440, Test MSE 3.283\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.237, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 3.435, Test MSE 3.279\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.237, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 3.450, Test MSE 3.397\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.237, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 3.466, Test MSE 3.514\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.236, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 3.482, Test MSE 3.631\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.236, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 3.497, Test MSE 3.748\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.236, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 3.497, Test MSE 3.747\n",
      "TRAINING MODEL dt_norm_3_40\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 29700\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.417, Test 0.395\n",
      "MSE NON-NORMALIZED: Train MSE 4.161, Test MSE 6.032\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.553, Test 0.505\n",
      "MSE NON-NORMALIZED: Train MSE 7.817, Test MSE 7.724\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.553, Test 0.504\n",
      "MSE NON-NORMALIZED: Train MSE 7.795, Test MSE 7.705\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.553, Test 0.504\n",
      "MSE NON-NORMALIZED: Train MSE 7.788, Test MSE 7.704\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.552, Test 0.503\n",
      "MSE NON-NORMALIZED: Train MSE 7.787, Test MSE 7.694\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.552, Test 0.503\n",
      "MSE NON-NORMALIZED: Train MSE 7.802, Test MSE 7.814\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.552, Test 0.503\n",
      "MSE NON-NORMALIZED: Train MSE 7.818, Test MSE 7.934\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.552, Test 0.503\n",
      "MSE NON-NORMALIZED: Train MSE 7.834, Test MSE 8.055\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.552, Test 0.503\n",
      "MSE NON-NORMALIZED: Train MSE 7.850, Test MSE 8.175\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.552, Test 0.503\n",
      "MSE NON-NORMALIZED: Train MSE 7.850, Test MSE 8.174\n",
      "TRAINING MODEL dt_norm_3_41\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 26195\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.289, Test 0.253\n",
      "MSE NON-NORMALIZED: Train MSE 2.823, Test MSE 3.821\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.392, Test 0.323\n",
      "MSE NON-NORMALIZED: Train MSE 4.974, Test MSE 4.888\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.393, Test 0.322\n",
      "MSE NON-NORMALIZED: Train MSE 4.953, Test MSE 4.890\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.393, Test 0.323\n",
      "MSE NON-NORMALIZED: Train MSE 4.945, Test MSE 4.896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.393, Test 0.323\n",
      "MSE NON-NORMALIZED: Train MSE 4.942, Test MSE 4.901\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.393, Test 0.323\n",
      "MSE NON-NORMALIZED: Train MSE 4.955, Test MSE 4.995\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.393, Test 0.323\n",
      "MSE NON-NORMALIZED: Train MSE 4.969, Test MSE 5.088\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.393, Test 0.323\n",
      "MSE NON-NORMALIZED: Train MSE 4.981, Test MSE 5.180\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.393, Test 0.323\n",
      "MSE NON-NORMALIZED: Train MSE 4.994, Test MSE 5.272\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.393, Test 0.323\n",
      "MSE NON-NORMALIZED: Train MSE 4.994, Test MSE 5.271\n",
      "TRAINING MODEL dt_norm_3_42\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 27786\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.377, Test 0.289\n",
      "MSE NON-NORMALIZED: Train MSE 3.175, Test MSE 4.364\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.434, Test 0.315\n",
      "MSE NON-NORMALIZED: Train MSE 4.918, Test MSE 4.753\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.436, Test 0.317\n",
      "MSE NON-NORMALIZED: Train MSE 4.922, Test MSE 4.784\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.437, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 4.921, Test MSE 4.793\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.437, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 4.921, Test MSE 4.791\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.437, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 4.931, Test MSE 4.869\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.437, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 4.942, Test MSE 4.947\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.437, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 4.952, Test MSE 5.026\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.437, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 4.963, Test MSE 5.104\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.437, Test 0.318\n",
      "MSE NON-NORMALIZED: Train MSE 4.963, Test MSE 5.104\n",
      "TRAINING MODEL dt_norm_3_43\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 23805\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.237, Test 0.255\n",
      "MSE NON-NORMALIZED: Train MSE 3.492, Test MSE 3.861\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.237, Test 0.267\n",
      "MSE NON-NORMALIZED: Train MSE 4.351, Test MSE 4.026\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.237, Test 0.265\n",
      "MSE NON-NORMALIZED: Train MSE 4.216, Test MSE 3.995\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.236, Test 0.265\n",
      "MSE NON-NORMALIZED: Train MSE 4.193, Test MSE 3.987\n",
      "Epoch 100, lr 3.3203125e-06\n",
      "Epoch 100: Train 0.236, Test 0.265\n",
      "MSE NON-NORMALIZED: Train MSE 4.189, Test MSE 3.986\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.236, Test 0.265\n",
      "MSE NON-NORMALIZED: Train MSE 4.199, Test MSE 4.063\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.236, Test 0.265\n",
      "MSE NON-NORMALIZED: Train MSE 4.211, Test MSE 4.138\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.236, Test 0.265\n",
      "MSE NON-NORMALIZED: Train MSE 4.221, Test MSE 4.212\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.236, Test 0.265\n",
      "MSE NON-NORMALIZED: Train MSE 4.232, Test MSE 4.287\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.236, Test 0.265\n",
      "MSE NON-NORMALIZED: Train MSE 4.232, Test MSE 4.287\n",
      "TRAINING MODEL dt_norm_3_44\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 24190\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.314, Test 0.307\n",
      "MSE NON-NORMALIZED: Train MSE 3.271, Test MSE 4.613\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.379, Test 0.385\n",
      "MSE NON-NORMALIZED: Train MSE 5.825, Test MSE 5.817\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.367, Test 0.374\n",
      "MSE NON-NORMALIZED: Train MSE 5.651, Test MSE 5.645\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.364, Test 0.371\n",
      "MSE NON-NORMALIZED: Train MSE 5.603, Test MSE 5.596\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.364, Test 0.371\n",
      "MSE NON-NORMALIZED: Train MSE 5.593, Test MSE 5.588\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.364, Test 0.370\n",
      "MSE NON-NORMALIZED: Train MSE 5.603, Test MSE 5.669\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.364, Test 0.370\n",
      "MSE NON-NORMALIZED: Train MSE 5.615, Test MSE 5.750\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.364, Test 0.370\n",
      "MSE NON-NORMALIZED: Train MSE 5.626, Test MSE 5.831\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.364, Test 0.370\n",
      "MSE NON-NORMALIZED: Train MSE 5.638, Test MSE 5.913\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.364, Test 0.370\n",
      "MSE NON-NORMALIZED: Train MSE 5.638, Test MSE 5.913\n",
      "TRAINING MODEL dt_norm_3_45\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 18646\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.186, Test 0.190\n",
      "MSE NON-NORMALIZED: Train MSE 1.974, Test MSE 2.863\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.192, Test 0.197\n",
      "MSE NON-NORMALIZED: Train MSE 2.972, Test MSE 2.922\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.189, Test 0.195\n",
      "MSE NON-NORMALIZED: Train MSE 2.971, Test MSE 2.888\n",
      "Epoch 75, lr 5.3125e-05\n",
      "Epoch 75: Train 0.187, Test 0.194\n",
      "MSE NON-NORMALIZED: Train MSE 2.942, Test MSE 2.861\n",
      "Epoch 100, lr 5.3125e-05\n",
      "Epoch 100: Train 0.186, Test 0.193\n",
      "MSE NON-NORMALIZED: Train MSE 2.926, Test MSE 2.845\n",
      "Epoch 125, lr 5.3125e-05\n",
      "Epoch 125: Train 0.185, Test 0.192\n",
      "MSE NON-NORMALIZED: Train MSE 2.927, Test MSE 2.909\n",
      "Epoch 150, lr 2.65625e-05\n",
      "Epoch 150: Train 0.184, Test 0.191\n",
      "MSE NON-NORMALIZED: Train MSE 2.926, Test MSE 2.964\n",
      "Epoch 175, lr 6.640625e-06\n",
      "Epoch 175: Train 0.184, Test 0.191\n",
      "MSE NON-NORMALIZED: Train MSE 2.933, Test MSE 3.033\n",
      "Epoch 200, lr 1.66015625e-06\n",
      "Epoch 200: Train 0.184, Test 0.191\n",
      "MSE NON-NORMALIZED: Train MSE 2.943, Test MSE 3.103\n",
      "Epoch 225, lr 4.150390625e-07\n",
      "Epoch 225: Train 0.184, Test 0.191\n",
      "MSE NON-NORMALIZED: Train MSE 2.943, Test MSE 3.103\n",
      "TRAINING MODEL dt_norm_3_46\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 19839\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.212, Test 0.217\n",
      "MSE NON-NORMALIZED: Train MSE 2.257, Test MSE 3.234\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.284, Test 0.246\n",
      "MSE NON-NORMALIZED: Train MSE 3.696, Test MSE 3.614\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.288, Test 0.246\n",
      "MSE NON-NORMALIZED: Train MSE 3.683, Test MSE 3.622\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.289, Test 0.247\n",
      "MSE NON-NORMALIZED: Train MSE 3.710, Test MSE 3.845\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.289, Test 0.247\n",
      "MSE NON-NORMALIZED: Train MSE 3.722, Test MSE 3.915\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.289, Test 0.247\n",
      "MSE NON-NORMALIZED: Train MSE 3.722, Test MSE 3.914\n",
      "TRAINING MODEL dt_norm_3_47\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 17061\n",
      "Epoch 0, lr 0.00085\n",
      "Epoch 0: Train 0.211, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 2.103, Test MSE 3.114\n",
      "Epoch 25, lr 0.0002125\n",
      "Epoch 25: Train 0.288, Test 0.294\n",
      "MSE NON-NORMALIZED: Train MSE 4.458, Test MSE 4.376\n",
      "Epoch 50, lr 5.3125e-05\n",
      "Epoch 50: Train 0.279, Test 0.290\n",
      "MSE NON-NORMALIZED: Train MSE 4.373, Test MSE 4.302\n",
      "Epoch 75, lr 1.328125e-05\n",
      "Epoch 75: Train 0.278, Test 0.289\n",
      "MSE NON-NORMALIZED: Train MSE 4.357, Test MSE 4.292\n",
      "Epoch 100, lr 1.66015625e-06\n",
      "Epoch 100: Train 0.277, Test 0.289\n",
      "MSE NON-NORMALIZED: Train MSE 4.354, Test MSE 4.291\n",
      "Epoch 125, lr 4.150390625e-07\n",
      "Epoch 125: Train 0.277, Test 0.289\n",
      "MSE NON-NORMALIZED: Train MSE 4.366, Test MSE 4.359\n",
      "Epoch 150, lr 1.03759765625e-07\n",
      "Epoch 150: Train 0.277, Test 0.289\n",
      "MSE NON-NORMALIZED: Train MSE 4.377, Test MSE 4.426\n",
      "Epoch 175, lr 2.593994140625e-08\n",
      "Epoch 175: Train 0.277, Test 0.289\n",
      "MSE NON-NORMALIZED: Train MSE 4.389, Test MSE 4.493\n",
      "Epoch 200, lr 1.2969970703125e-08\n",
      "Epoch 200: Train 0.277, Test 0.289\n",
      "MSE NON-NORMALIZED: Train MSE 4.400, Test MSE 4.560\n",
      "Epoch 225, lr 1.2969970703125e-08\n",
      "Epoch 225: Train 0.277, Test 0.289\n",
      "MSE NON-NORMALIZED: Train MSE 4.400, Test MSE 4.560\n"
     ]
    }
   ],
   "source": [
    "#17.735867005586623\n",
    "ae_train.train_models(data,\n",
    "            override = False,\n",
    "            path_1 = 'models/dt_1_greater_0_450_250_100_dif_2',\n",
    "            path_2 = 'models/dt_2_greater_0_450_250_100_dif_2',\n",
    "            path_3 = 'models/dt_3_greater_0_450_250_100_dif_2',\n",
    "            append_ReLU = True,\n",
    "            model_params = [],\n",
    "            epochs = 250, \n",
    "            lr = 8.5e-4,\n",
    "            max_dt_size = 30000, \n",
    "            dir_label = 'wafer_layer_split_mip_std_1_mean_nonzero_all_old_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15ae9c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dt_norm_3_36: 1.342146213912964\n",
      "model dt_norm_3_30: 2.3785711654415134\n",
      "model dt_norm_3_31: 2.3912372020196915\n",
      "model dt_norm_3_33: 2.1584973193073274\n",
      "model dt_norm_3_35: 1.4936802599530221\n",
      "model dt_norm_3_37: 1.7090111352653505\n",
      "model dt_norm_3_27: 0.6380477672753334\n",
      "model dt_norm_3_29: 3.3379846263198854\n",
      "model dt_norm_3_32: 1.789178053135872\n",
      "model dt_norm_3_34: 2.144266644862175\n",
      "model dt_norm_3_38: 3.568048340257645\n",
      "model dt_norm_1_1: 2.203444120090485\n",
      "model dt_norm_1_3: 6.757240653499604\n",
      "model dt_norm_1_5: 11.628114871364595\n",
      "model dt_norm_1_7: 12.782202593582154\n",
      "model dt_norm_1_9: 8.152471788196564\n",
      "model dt_norm_1_11: 6.860296798942566\n",
      "model dt_norm_1_13: 5.8860671299839025\n",
      "model dt_norm_1_15: 6.361683285724641\n",
      "model dt_norm_1_17: 4.370698663381577\n",
      "model dt_norm_1_19: 3.5581871896991735\n",
      "model dt_norm_1_21: 3.1832320000019076\n",
      "model dt_norm_1_23: 1.854214574146271\n",
      "model dt_norm_1_25: 2.114545573307991\n",
      "model dt_norm_1_27: 0.7965548011350633\n",
      "model dt_norm_1_29: 2.930598625946045\n",
      "model dt_norm_1_30: 1.8159282416467668\n",
      "model dt_norm_1_31: 2.0858399584064484\n",
      "model dt_norm_1_32: 1.7095057878484727\n",
      "model dt_norm_1_33: 1.461720268767357\n",
      "model dt_norm_2_1: 0.16583390136766435\n",
      "model dt_norm_2_3: 1.2380890785970688\n",
      "model dt_norm_2_5: 1.5061786302638056\n",
      "model dt_norm_2_7: 2.2955427927331926\n",
      "model dt_norm_2_9: 1.5345793299622537\n",
      "model dt_norm_2_11: 4.9790011550674445\n",
      "model dt_norm_2_13: 4.5728259128723145\n",
      "model dt_norm_2_15: 1.716671295121193\n",
      "model dt_norm_2_17: 2.4554633978948597\n",
      "model dt_norm_2_19: 2.6237177955265047\n",
      "model dt_norm_2_21: 1.7827080641183854\n",
      "model dt_norm_2_23: 1.8503953443031314\n",
      "model dt_norm_2_25: 0.8373636392426491\n",
      "model dt_norm_2_27: 5.0625501463737494\n",
      "model dt_norm_2_29: 2.3477342971343997\n",
      "model dt_norm_2_30: 1.8052478633193971\n",
      "model dt_norm_2_31: 2.4546423154106143\n",
      "model dt_norm_2_32: 0.9198227998108864\n",
      "model dt_norm_2_34: 2.244308506922722\n",
      "model dt_norm_2_35: 1.2625037168068887\n",
      "model dt_norm_2_36: 1.075659414513588\n",
      "model dt_norm_2_37: 2.192768564023018\n",
      "model dt_norm_2_38: 0.287470816999197\n",
      "model dt_norm_2_39: 0.5132690102133751\n",
      "model dt_norm_2_40: 0.09967546304368974\n",
      "model dt_norm_2_41: 0.08925870352301002\n",
      "model dt_norm_2_42: 0.09262661736631395\n",
      "model dt_norm_2_43: 0.040536435484930876\n",
      "model dt_norm_2_44: 0.015235727303892376\n",
      "model dt_norm_2_45: 0.05433375858718157\n",
      "model dt_norm_3_1: 0.10010779719114304\n",
      "model dt_norm_3_3: 15.350984833351136\n",
      "model dt_norm_3_5: 28.50386193360901\n",
      "model dt_norm_3_7: 439.1102268215332\n",
      "model dt_norm_3_9: 395.0401484992676\n",
      "model dt_norm_3_11: 252.59103016259766\n",
      "model dt_norm_3_13: 198.72606061669924\n",
      "model dt_norm_3_15: 187.85143424157715\n",
      "model dt_norm_3_17: 86.62532604537965\n",
      "model dt_norm_3_19: 76.56563488595582\n",
      "model dt_norm_3_21: 90.82333921069336\n",
      "model dt_norm_3_23: 51.91899033334351\n",
      "model dt_norm_3_25: 19.689478590385438\n",
      "model dt_norm_3_39: 1.2174134537916184\n",
      "model dt_norm_3_40: 0.6070453656234742\n",
      "model dt_norm_3_41: 0.30780605517053605\n",
      "model dt_norm_3_42: 0.3431310332268477\n",
      "model dt_norm_3_43: 0.4494787188127041\n",
      "model dt_norm_3_44: 0.41288597326469423\n",
      "model dt_norm_3_45: 0.2322927108421326\n",
      "model dt_norm_3_46: 0.3416976628385783\n",
      "model dt_norm_3_47: 0.1601297590929866\n"
     ]
    }
   ],
   "source": [
    "stats_per_tele = []\n",
    "for i in range(len(pred_set)):\n",
    "    stats_per_tele.append(torch.mean(telescopeMSE2(pred_set[i],test_set[i][:,0:48])).item()*3.5280**2)\n",
    "    print(f'model {models[i]}: {stats_per_tele[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "878de945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL dt_norm_2_13\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 19800\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 1.541, Test 1.427\n",
      "MSE NON-NORMALIZED: Train MSE 56.081, Test MSE 38.290\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 0.768, Test 0.551\n",
      "MSE NON-NORMALIZED: Train MSE 17.097, Test MSE 15.203\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 0.694, Test 0.491\n",
      "MSE NON-NORMALIZED: Train MSE 15.714, Test MSE 13.923\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 0.650, Test 0.452\n",
      "MSE NON-NORMALIZED: Train MSE 14.501, Test MSE 13.082\n",
      "Epoch 100, lr 8.5e-05\n",
      "Epoch 100: Train 0.626, Test 0.440\n",
      "MSE NON-NORMALIZED: Train MSE 14.334, Test MSE 12.851\n",
      "Epoch 125, lr 8.5e-05\n",
      "Epoch 125: Train 0.610, Test 0.426\n",
      "MSE NON-NORMALIZED: Train MSE 14.409, Test MSE 12.764\n",
      "Epoch 150, lr 8.5e-05\n",
      "Epoch 150: Train 0.594, Test 0.414\n",
      "MSE NON-NORMALIZED: Train MSE 13.706, Test MSE 12.612\n",
      "Epoch 175, lr 4.25e-05\n",
      "Epoch 175: Train 0.581, Test 0.402\n",
      "MSE NON-NORMALIZED: Train MSE 12.822, Test MSE 12.523\n",
      "Epoch 200, lr 2.125e-05\n",
      "Epoch 200: Train 0.578, Test 0.399\n",
      "MSE NON-NORMALIZED: Train MSE 12.754, Test MSE 12.623\n",
      "Epoch 225, lr 2.125e-05\n",
      "Epoch 225: Train 0.575, Test 0.397\n",
      "MSE NON-NORMALIZED: Train MSE 12.739, Test MSE 12.590\n",
      "Epoch 250, lr 2.125e-05\n",
      "Epoch 250: Train 0.574, Test 0.396\n",
      "MSE NON-NORMALIZED: Train MSE 12.689, Test MSE 12.572\n",
      "Epoch 275, lr 2.125e-05\n",
      "Epoch 275: Train 0.573, Test 0.395\n",
      "MSE NON-NORMALIZED: Train MSE 12.683, Test MSE 12.549\n",
      "Epoch 300, lr 2.125e-05\n",
      "Epoch 300: Train 0.569, Test 0.393\n",
      "MSE NON-NORMALIZED: Train MSE 12.631, Test MSE 12.511\n",
      "Epoch 325, lr 2.125e-05\n",
      "Epoch 325: Train 0.568, Test 0.393\n",
      "MSE NON-NORMALIZED: Train MSE 12.611, Test MSE 12.493\n",
      "Epoch 350, lr 2.125e-05\n",
      "Epoch 350: Train 0.567, Test 0.392\n",
      "MSE NON-NORMALIZED: Train MSE 12.612, Test MSE 12.464\n",
      "Epoch 375, lr 2.125e-05\n",
      "Epoch 375: Train 0.565, Test 0.391\n",
      "MSE NON-NORMALIZED: Train MSE 12.601, Test MSE 12.449\n",
      "TRAINING MODEL dt_norm_2_15\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 19800\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 0.856, Test 0.918\n",
      "MSE NON-NORMALIZED: Train MSE 30.380, Test MSE 20.754\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 0.278, Test 0.305\n",
      "MSE NON-NORMALIZED: Train MSE 7.818, Test MSE 6.812\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 0.256, Test 0.277\n",
      "MSE NON-NORMALIZED: Train MSE 7.331, Test MSE 6.282\n",
      "Epoch 75, lr 8.5e-05\n",
      "Epoch 75: Train 0.245, Test 0.266\n",
      "MSE NON-NORMALIZED: Train MSE 7.135, Test MSE 6.065\n",
      "Epoch 100, lr 8.5e-05\n",
      "Epoch 100: Train 0.236, Test 0.259\n",
      "MSE NON-NORMALIZED: Train MSE 7.004, Test MSE 5.929\n",
      "Epoch 125, lr 8.5e-05\n",
      "Epoch 125: Train 0.233, Test 0.254\n",
      "MSE NON-NORMALIZED: Train MSE 6.939, Test MSE 5.985\n",
      "Epoch 150, lr 4.25e-05\n",
      "Epoch 150: Train 0.225, Test 0.248\n",
      "MSE NON-NORMALIZED: Train MSE 6.797, Test MSE 5.973\n",
      "Epoch 175, lr 2.125e-05\n",
      "Epoch 175: Train 0.221, Test 0.244\n",
      "MSE NON-NORMALIZED: Train MSE 6.737, Test MSE 6.034\n",
      "Epoch 200, lr 5.3125e-06\n",
      "Epoch 200: Train 0.220, Test 0.243\n",
      "MSE NON-NORMALIZED: Train MSE 6.712, Test MSE 6.125\n",
      "Epoch 225, lr 2.65625e-06\n",
      "Epoch 225: Train 0.219, Test 0.243\n",
      "MSE NON-NORMALIZED: Train MSE 6.704, Test MSE 6.119\n",
      "Epoch 250, lr 2.65625e-06\n",
      "Epoch 250: Train 0.219, Test 0.242\n",
      "MSE NON-NORMALIZED: Train MSE 6.703, Test MSE 6.117\n",
      "Epoch 275, lr 1.328125e-06\n",
      "Epoch 275: Train 0.219, Test 0.242\n",
      "MSE NON-NORMALIZED: Train MSE 6.699, Test MSE 6.114\n",
      "Epoch 300, lr 3.3203125e-07\n",
      "Epoch 300: Train 0.219, Test 0.242\n",
      "MSE NON-NORMALIZED: Train MSE 6.695, Test MSE 6.113\n",
      "Epoch 325, lr 8.30078125e-08\n",
      "Epoch 325: Train 0.219, Test 0.242\n",
      "MSE NON-NORMALIZED: Train MSE 6.695, Test MSE 6.113\n",
      "Epoch 350, lr 2.0751953125e-08\n",
      "Epoch 350: Train 0.219, Test 0.242\n",
      "MSE NON-NORMALIZED: Train MSE 6.694, Test MSE 6.112\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 0.219, Test 0.242\n",
      "MSE NON-NORMALIZED: Train MSE 6.694, Test MSE 6.112\n",
      "TRAINING MODEL dt_norm_2_17\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 19800\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 0.613, Test 0.625\n",
      "MSE NON-NORMALIZED: Train MSE 22.357, Test MSE 14.160\n",
      "Epoch 25, lr 8.5e-05\n",
      "Epoch 25: Train 0.226, Test 0.233\n",
      "MSE NON-NORMALIZED: Train MSE 5.853, Test MSE 5.282\n",
      "Epoch 50, lr 8.5e-05\n",
      "Epoch 50: Train 0.217, Test 0.220\n",
      "MSE NON-NORMALIZED: Train MSE 5.549, Test MSE 5.024\n",
      "Epoch 75, lr 2.125e-05\n",
      "Epoch 75: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.301, Test MSE 4.727\n",
      "Epoch 100, lr 5.3125e-06\n",
      "Epoch 100: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.292, Test MSE 4.725\n",
      "Epoch 125, lr 1.328125e-06\n",
      "Epoch 125: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.296, Test MSE 4.847\n",
      "Epoch 150, lr 3.3203125e-07\n",
      "Epoch 150: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.315, Test MSE 4.975\n",
      "Epoch 175, lr 8.30078125e-08\n",
      "Epoch 175: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.336, Test MSE 5.102\n",
      "Epoch 200, lr 1.03759765625e-08\n",
      "Epoch 200: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.356, Test MSE 5.228\n",
      "Epoch 225, lr 1.03759765625e-08\n",
      "Epoch 225: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.355, Test MSE 5.226\n",
      "Epoch 250, lr 1.03759765625e-08\n",
      "Epoch 250: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.355, Test MSE 5.225\n",
      "Epoch 275, lr 1.03759765625e-08\n",
      "Epoch 275: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.355, Test MSE 5.224\n",
      "Epoch 300, lr 1.03759765625e-08\n",
      "Epoch 300: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.354, Test MSE 5.223\n",
      "Epoch 325, lr 1.03759765625e-08\n",
      "Epoch 325: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.354, Test MSE 5.223\n",
      "Epoch 350, lr 1.03759765625e-08\n",
      "Epoch 350: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.353, Test MSE 5.222\n",
      "Epoch 375, lr 1.03759765625e-08\n",
      "Epoch 375: Train 0.208, Test 0.210\n",
      "MSE NON-NORMALIZED: Train MSE 5.353, Test MSE 5.222\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mae_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_models_telescope\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverride\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath_1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/dt_1_greater_0_450_250_100_dif_2_tele\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath_2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/dt_2_greater_0_450_250_100_dif_2_tele\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath_3\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/dt_3_greater_0_450_250_100_dif_2_tele\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8.5e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_dt_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdir_label\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwafer_layer_split_mip_std_1_mean_nonzero_telescope_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/Notebooks/AE_Dev/ae_train.py:729\u001b[0m, in \u001b[0;36mtrain_models_telescope\u001b[0;34m(data, batch_size, override, model_params, path_1, path_2, path_3, append_ReLU, max_dt_size, epochs, lr, dir_label, path)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAINING MODEL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m#Training model\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;66;03m#clear cuda after training each model\u001b[39;00m\n\u001b[1;32m    731\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/Notebooks/AE_Dev/ae_train.py:120\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dt, size_train, size_test, label, cur_directory, path, loss, num_epochs, lr, batch)\u001b[0m\n\u001b[1;32m    118\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    119\u001b[0m data \u001b[38;5;241m=\u001b[39m data_list[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 120\u001b[0m v_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m loss(data[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m48\u001b[39m], v_pred,epoch,mean,std)\n\u001b[1;32m    124\u001b[0m all_train_losses\u001b[38;5;241m.\u001b[39mappend(batch_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/Notebooks/AE_Dev/Naive_DAE.py:186\u001b[0m, in \u001b[0;36mNaive_DAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    173\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward step\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     x_encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     x_reconstructed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(x_encoded)\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_reconstructed\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/Notebooks/AE_Dev/Naive_DAE.py:208\u001b[0m, in \u001b[0;36mNaive_DAE.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    206\u001b[0m         x \u001b[38;5;241m=\u001b[39m enc(x)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43menc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ae_train.train_models_telescope(data,\n",
    "            \n",
    "            override = False,\n",
    "            path_1 = 'models/dt_1_greater_0_450_250_100_dif_2_tele',\n",
    "            path_2 = 'models/dt_2_greater_0_450_250_100_dif_2_tele',\n",
    "            path_3 = 'models/dt_3_greater_0_450_250_100_dif_2_tele',\n",
    "            model_params = [],\n",
    "            epochs = 400, \n",
    "            lr = 8.5e-5,\n",
    "            max_dt_size = 20000, \n",
    "            dir_label = 'wafer_layer_split_mip_std_1_mean_nonzero_telescope_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da0e4930",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodels\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42d221b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stat_per' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mstat_per\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stat_per' is not defined"
     ]
    }
   ],
   "source": [
    "len(stat_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ce79e7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dt_norm_1_3 has Telescope of 6.757240653499604 and is being retrained\n",
      "models/high_layer_tele\n",
      "Model dt_norm_1_5 has Telescope of 11.628114871364595 and is being retrained\n",
      "models/high_layer_tele\n",
      "Model dt_norm_1_7 has Telescope of 12.782202593582154 and is being retrained\n",
      "models/high_layer_tele\n",
      "Model dt_norm_1_9 has Telescope of 8.152471788196564 and is being retrained\n",
      "models/high_layer_tele\n",
      "Model dt_norm_1_11 has Telescope of 6.860296798942566 and is being retrained\n",
      "models/high_layer_tele\n",
      "Model dt_norm_1_13 has Telescope of 5.8860671299839025 and is being retrained\n",
      "models/high_layer_tele\n",
      "Model dt_norm_1_15 has Telescope of 6.361683285724641 and is being retrained\n",
      "models/high_layer_tele\n",
      "Model dt_norm_2_27 has Telescope of 5.0625501463737494 and is being retrained\n",
      "Model dt_norm_3_3 has Telescope of 15.350984833351136 and is being retrained\n",
      "Model dt_norm_3_5 has Telescope of 28.50386193360901 and is being retrained\n",
      "Model dt_norm_3_7 has Telescope of 439.1102268215332 and is being retrained\n",
      "Model dt_norm_3_9 has Telescope of 395.0401484992676 and is being retrained\n",
      "Model dt_norm_3_11 has Telescope of 252.59103016259766 and is being retrained\n",
      "Model dt_norm_3_13 has Telescope of 198.72606061669924 and is being retrained\n",
      "Model dt_norm_3_15 has Telescope of 187.85143424157715 and is being retrained\n",
      "Model dt_norm_3_17 has Telescope of 86.62532604537965 and is being retrained\n",
      "Model dt_norm_3_19 has Telescope of 76.56563488595582 and is being retrained\n",
      "Model dt_norm_3_21 has Telescope of 90.82333921069336 and is being retrained\n",
      "Model dt_norm_3_23 has Telescope of 51.91899033334351 and is being retrained\n",
      "Model dt_norm_3_25 has Telescope of 19.689478590385438 and is being retrained\n",
      "TRAINING MODEL dt_norm_1_3\n",
      "TRAINING INFO:\n",
      "Total Dataset Size: 19800\n",
      "Epoch 0, lr 8.5e-05\n",
      "Epoch 0: Train 31.193, Test 28.232\n",
      "MSE NON-NORMALIZED: Train MSE 462.902, Test MSE 346.082\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mae_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrain_models_telescope\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstats_per_tele\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverride\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8.5e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_dt_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdir_label\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwafer_layer_split_mip_std_1_mean_nonzero_telescope\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/Notebooks/AE_Dev/ae_train.py:793\u001b[0m, in \u001b[0;36mretrain_models_telescope\u001b[0;34m(data, mse, mse_threshold, batch, override, model_params, max_dt_size, epochs, lr, dir_label, path)\u001b[0m\n\u001b[1;32m    791\u001b[0m i\u001b[38;5;241m=\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m#Training mode\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m \u001b[43mretrain_model_telescope\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcur_mse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m              \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m              \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m              \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m              \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m#clear cuda after training each model\u001b[39;00m\n\u001b[1;32m    804\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/Notebooks/AE_Dev/ae_train.py:869\u001b[0m, in \u001b[0;36mretrain_model_telescope\u001b[0;34m(model, mse, dt, size_train, size_test, label, cur_directory, path, num_epochs, lr, batch)\u001b[0m\n\u001b[1;32m    867\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(batch_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    868\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 869\u001b[0m     \u001b[43mbatch_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    873\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep(batch_loss)\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/uscms_data/d3/nswood/mambaforge/envs/myenv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ae_train.retrain_models_telescope(data,\n",
    "            stats_per_tele,\n",
    "            override = False,\n",
    "            model_params = [],\n",
    "            epochs = 400, \n",
    "            lr = 8.5e-5,\n",
    "            max_dt_size = 20000, \n",
    "            dir_label = 'wafer_layer_split_mip_std_1_mean_nonzero_telescope')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
